<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>高明飞的博客</title>
  
  <subtitle>澹泊明志，宁静致远</subtitle>
  <link href="https://gaomf.cn/atom.xml" rel="self"/>
  
  <link href="https://gaomf.cn/"/>
  <updated>2022-05-10T14:12:39.826Z</updated>
  <id>https://gaomf.cn/</id>
  
  <author>
    <name>高明飞</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Gossip 协议总结</title>
    <link href="https://gaomf.cn/2022/05/10/Gossip/"/>
    <id>https://gaomf.cn/2022/05/10/Gossip/</id>
    <published>2022-05-10T14:00:00.000Z</published>
    <updated>2022-05-10T14:12:39.826Z</updated>
    
    <content type="html"><![CDATA[<p>Gossip 协议是一种弱最终一致性算法，主要用于解决大规模去中心化 P2P 网络中的数据一致性问题，其显著特点在于简单易于理解，并且不要求节点间均可以相互通信，只要一个节点能与部分节点通信，那它就可以把数据变更消息广播至整个联通网络中。</p><p>Gossip 协议最有名的应用包括 Redis-Cluster，Bitcoin，Cassandra 等。</p><span id="more"></span><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>Gossip 协议最早发布于 1989 年的 ACM 会议论文 <a target="_blank" rel="noopener" href="http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/CSL-89-1_Epidemic_Algorithms_for_Replicated_Database_Maintenance.pdf">Epidemic Algorithms for Replicated Database Maintenance</a> 中，论文中是用来解决分布式数据库多副本一致性问题的，这是一个最终一致性算法。</p><p>由于此算法仅能保证最终一致性而非强一致性，而且达到一致的时间不可控，因此目前更多的是被用于各种 P2P 应用中。</p><h2 id="设计哲学"><a href="#设计哲学" class="headerlink" title="设计哲学"></a>设计哲学</h2><p>如同其名字一样，消息的传播就像谣言的传播一样，一传十，十传百，百传千千万。</p><h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>若一个节点需要向其他节点广播发送消息，则：</p><ol><li>随机选择 N 个尚未发送过消息的邻接节点发送消息；</li><li>等待一段时间，再重复上述步骤；</li></ol><p>当一个节点收到其他节点的广播消息时，更新自己的数据，并向除源节点外其他节点广播数据。</p><p>网络上诸多文章对 Gossip 协议的介绍基本就到此为止了，基本还会配上这样一张传播示意图：</p><video controls autoplay>      <source id="mp4" src="https://img.gaomf.cn/gossip_demo.mp4" type="video/mp4"></video><p>然而根据上述如此抽象的描述可以说是没法搭建出实际有用的系统来的。粗略想想就会发现几个核心问题没有被解决：</p><ul><li>收到消息后该如何更新？直接无脑覆盖已有数据？那如果集群中有两个节点都在更新相同内容怎么处理？此时如何保证集群能达到最终一致性，而不会发生振荡？</li><li>上述广播的过程是一直循环进行的还是发送完一轮就会停止？</li></ul><p>其实在 Gossip 的原始论文中对这些问题是有更细致的讨论和处理的，Márk Jelasity 在 <a target="_blank" rel="noopener" href="http://publicatio.bibl.u-szeged.hu/1529/">Self-organising software. From natural to artificial adaptation</a> 一书中也有详细论述，二者基本是一致的。</p><h2 id="详细实现方法"><a href="#详细实现方法" class="headerlink" title="详细实现方法"></a>详细实现方法</h2><h3 id="消息或数据的抽象"><a href="#消息或数据的抽象" class="headerlink" title="消息或数据的抽象"></a>消息或数据的抽象</h3><p>实际的消息或数据的形式是由具体应用决定的，不过不妨将其抽象为 <code>K-V-T</code> 集合，即若干条 Key -&gt; Value + Time，这里的 Time 可以是实际的时间戳，也可以是其他类似 Version 的值。</p><p>更新数据时并不会直接无脑的去覆盖数据，而是会比较 Time：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Update</span>(k, v, t) &#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.t &lt; t) &#123;</span><br><span class="line">    <span class="keyword">this</span>.k.v = v;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Gossip 的论文中就是是用了时间戳来作为这个 Time，不过这感觉会存在一个问题：</p><p>如何保证全局时间戳的一致性呢？如果无法保证，那会不会造成节点间的不平等？即时间较晚那个节点相当于就被赋予了更高的优先级？</p><h3 id="算法基本策略"><a href="#算法基本策略" class="headerlink" title="算法基本策略"></a>算法基本策略</h3><p>Gossip 算法有三种基本策略：</p><ul><li>Direct mail，直接邮寄</li><li>Anti-entropy，反熵传播</li><li>Rumor mongering (Complex Epidemics)，谣言传播（复杂传染）</li></ul><p>在后两种策略中，消息的交互通信模式又可以分为三种：</p><ul><li>Push</li><li>Pull</li><li>Push/Pull</li></ul><p>在下文描述中，使用 S 表示某一节点的邻接节点集合。</p><h3 id="Direct-mail"><a href="#Direct-mail" class="headerlink" title="Direct mail"></a>Direct mail</h3><p>当某一节点有数据发生更新时，触发通知其他所有节点的流程：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(s : S) &#123;</span><br><span class="line">  s.<span class="built_in">Send</span>(k, v, t);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>收到数据的节点更新自己的数据，若成功更新继续重复上述流程通知自己的邻接节点。</p><p>此策略由于只发送一次数据，所以并不一定可靠。</p><h3 id="Anti-entropy"><a href="#Anti-entropy" class="headerlink" title="Anti-entropy"></a>Anti-entropy</h3><p>此策略在 Márk Jelasity 的书中被称为 SI 模型，其工作流程是每个节点均周期性的选择部分邻接节点同步更新数据：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">  <span class="keyword">for</span> (s : <span class="built_in">RandomChoice</span>(S)) &#123;</span><br><span class="line">    s.<span class="built_in">ResolveDifference</span>(k, v, t);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">delay</span>(...);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>三种消息交互模式的区别就在于 <code>ResolveDifference</code> 的实现方式不同：</p><ul><li>Push 模式下节点 A 将 <code>K-V-T</code> 数据发送给节点 B，节点 B 更新自己的数据；</li><li>Pull 模式下节点 A 发起请求，将自己已有的 <code>K-T</code> 数据发给节点 B，节点 B 收到后与自己的数据进行比较，将更新或节点 A 没有的 <code>K-V-T</code> 数据发送给节点 A，节点 A 更新自己的数据；</li><li>Push/Pull 模式即为上述两种模式的结合，节点 A 推送 <code>K-V-T</code> 至节点 B，节点 B 更新完后把需要节点 A 更新的 <code>K-V-T</code> 再推送回节点 A，节点 A 再更新自己的数据。</li></ul><blockquote><p>上述描述中 Push/Pull 模式的流程与大部分文章中写的有所区别，在大部分文章中，Push/Pull 模式就是简单的 Pull + Push，此时会存在 3 次网络交互，此处进行了一些优化，如果先做 Push 再做 Pull 则可以减少一次网络交互。</p></blockquote><p>在 Direct mail 形式下使用的就是 Push 通信模式，因此 Direct mail 策略可以视为是只执行一次的使用 Push 模式的 Anti-entropy 策略；</p><p>一般而言，显然是 Push/Pull 模式收敛得最快。</p><p>此方法中，发送的 <code>K-V-T</code> 根据论文的描述应该是数据全集，这就导致需要交互的数据量极大，甚至是完全不可行的。而且这个交互过程是一直都在进行永不停止的，这也会造成较大的带宽浪费。</p><h3 id="Rumor-mongering-Complex-Epidemics"><a href="#Rumor-mongering-Complex-Epidemics" class="headerlink" title="Rumor mongering (Complex Epidemics)"></a>Rumor mongering (Complex Epidemics)</h3><p>针对 Anti-entropy 策略做了些改进，每个节点加入一个状态，可能取值有：</p><ul><li><code>S</code>: Susceptible, 不存在数据更新</li><li><code>I</code>: Infective, 存在数据更新且需要广播</li><li><code>R</code>: Removed, 存在数据更新，然而不广播</li></ul><p>故此策略在 Márk Jelasity 的书中被称为 SIR 模型。</p><p>其中 <code>S</code> 状态是节点的初始值，仅当没有数据更新时才会处于此状态中，一旦发生了数据更新就永远也不可能回到此状态中。因此感觉此状态是为了理论的完美性才引入的，从实际实现的角度来看完全可以忽略此状态。</p><p>此外还需要再引入一条 Feedback 消息，当某个节点 B 收到节点 A 发来的 Push 消息后会回复节点 A 此消息。</p><p>此时状态迁移就会变得很简单，一旦发生数据更新（通过与其他节点交互或系统其他部分修改数据）就会成为 <code>I</code> 状态；一旦收到 Feedback 消息，则有<strong>一定概率</strong>会变成 <code>R</code> 状态；</p><p>当节点处于 <code>I</code> 状态时，行为与 Anti-entropy 策略相同；当节点处于 <code>R</code> 状态时，不进行周期性的节点同步更新。此策略的目的正是通过引入 <code>R</code> 状态来让节点间的交互可以在一段时间内停止。</p><p>上述变成 <code>R</code> 状态的<strong>一定概率</strong>在论文中用 $1/k$ 表示，此概率是怎么确定的呢？学术点搞是根据集群规模理论计算出来的，当然实际使用的时候一般都是试出来的，此概率越高则系统收敛速度越快，然而也越容易无法保证最终一致性。</p><h3 id="进一步优化与工程实践"><a href="#进一步优化与工程实践" class="headerlink" title="进一步优化与工程实践"></a>进一步优化与工程实践</h3><p>论文的内容就到此为止了，然而仔细揣摩下上述策略，其实有一些点是可以进一步优化的。</p><p>首先在消息的设计上，由于 Push/Pull 模式是最为完善的，可以均选用此策略，此时消息就可以简化为 <code>PushReq</code> &amp; <code>PullRes</code> 两条。</p><p>Rumor mongering 策略中引入的 Feedback 消息在此设计下其实是多余的，一旦收到 <code>PullRes</code> 即等同于收到了 Feedback 消息。</p><p>另一个可能的优化点在于，<code>PushReq</code> 中携带的 <code>K-V-T</code> 是否可能不是全量数据，只发送增量数据，这么做需要思考一下一些难点：</p><ul><li>需要在 <code>PushReq</code> 中加入特殊的字段表明此请求是增量单向 Push，<code>PullRes</code> 中不需要回复缺失 <code>K-V-T</code>。然而加入此字段后会不会让整个系统只有 Push 而没有 Pull 的能力呢？还是除了初始化时其他时候不需要 Pull 也可以正常工作呢？</li><li>如何记录哪些 <code>K-V</code> 是变化了的呢？一个想法是是否可以利用时间信息，比较上一次同步的时间与数据中的时间戳 T</li><li>在数据会持续更新的情况下，会不会由于节点被错误的置为 <code>R</code> 状态而导致数据不一致？</li></ul><p>新节点加入时，只需要发送空的 <code>PushReq</code> 即可，此时相当于 Pull 模式去主动拉数据。</p><h2 id="适用场景及优缺点"><a href="#适用场景及优缺点" class="headerlink" title="适用场景及优缺点"></a>适用场景及优缺点</h2><p>Gossip 协议的适用场景相对比较确定：</p><ol><li>集群没有中心节点，且各节点的地位是平等的；</li><li>集群拓扑结构是网状结构，且单个节点只能与部分邻接节点通信，不能与全部节点通信；</li><li>系统不要求强一致性，甚至最终一致性都不要求，只要求大部分节点能达到最终一致即可；</li></ol><p>第 2 点是 Gossip 协议最显著的优点，在这样的去中心化拓扑结构下，其他很多一致性算法都是没法正常工作的，因此在 P2P 网络中 Gossip 协议取得了广泛的应用；而第 3 点则是 Gossip 协议最大的局限性，即它不是强一致性协议。</p><p>如果系统具有特性 1 &amp; 2 而又要求强一致能否实现呢？好像还没有听过这样的算法……感觉可以搞个 Paxos + Gossip 的混合算法出来？这估计是个蛮有意思的东西吧……</p><p>Gossip 协议还有哪些显著优点呢：</p><ul><li>足够简单易于理解及实现；</li><li>扩展性及容错性极好，节点的加入和删除可以很平滑的处理；</li><li>对于大规模网络来说，传播速度足够快，且对集群规模的扩大不敏感，准确一点来说，消息传播所需次数是 $\log(N)$ 级别的。</li></ul><p>至于它的缺点，主要就是前文所述的，它不是强一致协议，甚至都不能保证最终一致性。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/41228196">P2P 网络核心技术：Gossip 协议</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/162970961">Gossip 协议详解</a><br><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000038373546">一万字详解 Redis Cluster Gossip 协议</a><br><a target="_blank" rel="noopener" href="https://juejin.cn/post/6930774718114955278">分布式系列 Gossip协议</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Gossip 协议是一种弱最终一致性算法，主要用于解决大规模去中心化 P2P 网络中的数据一致性问题，其显著特点在于简单易于理解，并且不要求节点间均可以相互通信，只要一个节点能与部分节点通信，那它就可以把数据变更消息广播至整个联通网络中。&lt;/p&gt;
&lt;p&gt;Gossip 协议最有名的应用包括 Redis-Cluster，Bitcoin，Cassandra 等。&lt;/p&gt;</summary>
    
    
    
    <category term="算法之美" scheme="https://gaomf.cn/categories/%E7%AE%97%E6%B3%95%E4%B9%8B%E7%BE%8E/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="P2P" scheme="https://gaomf.cn/tags/P2P/"/>
    
    <category term="Consensus" scheme="https://gaomf.cn/tags/Consensus/"/>
    
    <category term="Distributed-System" scheme="https://gaomf.cn/tags/Distributed-System/"/>
    
  </entry>
  
  <entry>
    <title>【读读论文】大规模真实线上环境下 SSD 寿命，写放大等特性研究</title>
    <link href="https://gaomf.cn/2022/04/07/Paper_NetApp_SSD_WAF/"/>
    <id>https://gaomf.cn/2022/04/07/Paper_NetApp_SSD_WAF/</id>
    <published>2022-04-07T11:47:00.000Z</published>
    <updated>2022-04-08T14:48:18.587Z</updated>
    
    <content type="html"><![CDATA[<p>Operational Characteristics of SSDs in Enterprise Storage Systems: A Large-Scale Field Study</p><p>此论文为多伦多大学与 NetApp 合作发表在 FAST’22 上的论文，统计分析了 NetApp 线上两百多万块 SSD 在过去 4 年内的运行数据，以此总结了 SSD 寿命，写放大这两个核心运维特性在大规模线上环境下的真实情况及其影响因素。</p><p>看完最大的感想是，SSD 间差异是巨大的，垃圾厂家的 SSD 真是不能用……</p><span id="more"></span><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>这篇论文作为一篇统计分析类文章之所以能发表在 FAST 上的重要原因在于其统计规模巨大且广泛，而且是真实线上环境，比之前同类研究中选取某个小范围特定场景来说有价值得多。NetApp 是一家美国的云存储公司，由于其客户的多样性，其底层存储系统同时提供了 NFS，iSCSI，NVMe_oF，S3 等多种接口，因此整体的应用负载特性相对较能反映各种不同应用的平均水平，而非某种特定场景。NetApp 使用的 SSD 规模也很大，总量约 200 万块，包括 3 个厂家，20 余个系列，同时存在 SAS &amp; NVME 接口的（以 SAS 居多），具体情况见下表：</p><p><img src="https://img.gaomf.cn/202204072036558.png?600x" alt="Table 1"></p><p>I,II,III 代表三家生产商，论文里面并没有披露具体是哪三家，然而根据某些型号不太常见的容量，如 I-D 的 3.8T，II-H 的 30T，可以推测出 I 是 Sandisk，II 是 Samsung，至于 III 由于只有一个 III-A 数量太少，就不知道是哪家了。上表除最后 II-X, II-Y, II-Z 为 NVME 接口外其余 SSD 均为 SAS 接口的，可以推测从数量上看 SAS SSD 也占了绝大部分。不过 SSD 的接口类型对其寿命，写放大应该是没有什么影响的，故尽管未来 NVME SSD 会越来越多，这篇论文依然会有参考价值。</p><p>上层应用从使用场景上来看可以分为两大类：</p><ul><li>作为 HDD 盘的高速缓存层使用，简称为 <strong>WBC</strong> 应用（Write-Back Cache）</li><li>直接构成全 SSD 阵列，简称为 <strong>AFF</strong> 应用（All Flash Fabric-attached-storage）</li></ul><p>这两类系统的读写特性差异较大，因此论文中基本都是将其分开进行讨论。</p><p>论文想要回答的核心问题包括：</p><ul><li>实际生产环境中的读写比例是怎样的？</li><li>实际生产环境中真实的写入速率到底有多快？SSD 的寿命能有多长？未来 QLC 寿命会更短，它能满足数据中心及企业级应用的需求么？</li><li>实际生产环境中的 SSD 写放大会有多严重？之前学术界的研究分析是否符合实际情况？</li><li>实际生产环境中 SSD 的损耗平均做得好不好？</li><li>SSD 的写放大从理论上分析会和很多因素有关，那在实际生产环境中，这些因素的影响到底有多大呢？哪些因素才是主要的呢？</li></ul><p>下面我们就跟随着作者的脚步来回答下这些问题吧。</p><h2 id="统计数据分析结果"><a href="#统计数据分析结果" class="headerlink" title="统计数据分析结果"></a>统计数据分析结果</h2><h3 id="读写比例分析"><a href="#读写比例分析" class="headerlink" title="读写比例分析"></a>读写比例分析</h3><p><img src="https://img.gaomf.cn/202204072123744.png?500x" alt="Figure 9"></p><ul><li>大部分盘读都比写多</li><li>AFF 应用中读写比中位数约为 3.6:1，95 分位值为 61:1</li><li>WBC 应用中读写比中位数约为 4.1:1，95 分位值为 150:1</li><li>可以看到 WBC 应用的读写比例比 AFF 应用更高，且 95 分位值差距很大；对于 WBC 应用来说，更高的读写比是期望中的，这也就意味着更高的 Cache 使用率</li></ul><p>Facebook，Microsoft，Alibaba 的统计数据中也是读比写多，不过 NetApp 这次公开的统计数据读写量远高于其余几家公开的统计数据：</p><p><img src="https://img.gaomf.cn/202204072132446.png?500x" alt="Figure 11"></p><h3 id="应用写入速度分析"><a href="#应用写入速度分析" class="headerlink" title="应用写入速度分析"></a>应用写入速度分析</h3><p>SSD 的寿命和写入量有密切关系，DWPD 这一指标就是厂家给出的推荐写入速度上限，其含义为每天可以写入 SSD 容量几倍的数据（Drive Writes Per Day），大部分企业级 SSD 的 DWPD 值为 1 或 3，部分使用 MLC 颗粒的 SSD 会更高，可达到 10 以上。未来使用 QLC 颗粒的 SSD DWPD 大概率会下降到 1 以下。那实际生产环境中 DWPD 会到多少呢？来看看数据吧。</p><p><img src="https://img.gaomf.cn/202204072141261.png?1200x" alt="Figure 1"></p><ul><li>不同盘的 DWPD 值分布很广，且长尾比较明显。整体来看中位数只有 0.36 左右，小于目前大部分 SSD 的 DWPD 值上限；然而也有 7% 左右的 SSD DWPD 超过了 3；2% 左右的超过了 10</li><li>WBC 应用比 AFF 应用写入量更高，中位数 WBC 是 AFF 的 3.4 倍，99 分位值更是达到了 10.6 倍</li><li>WBC 应用中 DWPD 值的分布也更宽广，这也就意味着其运维会更有挑战性</li><li>再来看下容量和产品型号的问题，这里其实评估的并不是容量和产品型号本身，而是负载类型的影响。由于 NetApp 会使用不同容量的和型号的 SSD 去搭建不同的产品，为不同的客户提供服务，因此型号的差异就可以视为不同应用负载的差异。可以看到不同应用负载下 DWPD 值差异也很大</li></ul><blockquote><p>以上两部分内容其实并没有太多干货。读多写少是大部分互联网业务的典型场景；不同负载的写入量差异很大也是很正常的。</p></blockquote><h3 id="NAND-使用损耗分析"><a href="#NAND-使用损耗分析" class="headerlink" title="NAND 使用损耗分析"></a>NAND 使用损耗分析</h3><p>SSD 除了 DWPD 外还有个重要指标是 PE Cycle Limit，即最大擦写循环次数（Program-Erase Cycle），这是决定 SSD 寿命的根本性因素，SSD 寿命预测基本就是根据当前 PE Cycle 与最大 PE Cycle Limit 的比值得出的。因此作者引入了一个年损耗率的概念：</p><p><img src="https://img.gaomf.cn/202204072200661.png?500x" alt="NAND Usage Rate per Year"></p><p>显而易见，此值的含义就是每年会用去 SSD 总寿命的百分比。实际统计结果如下：</p><p><img src="https://img.gaomf.cn/202204072207243.png?700x" alt="Figure 2"></p><ul><li>绝大部分 SSD 年损耗率其实是非常低的，<strong>AFF 应用中 60% 的 SSD 年损耗率小于 1%，也就是这部分 SSD 用 100 年才会报废</strong></li><li>尽管 WBC 应用的写入量比 AFF 应用要高不少，然而二者的年损耗率其实是差不多的，原因是 WBC 应用的写放大系数要低于 AFF 应用，这抵消了其写入量更高的影响</li><li><strong>上图中可以很明显的看到几条极为不和谐的曲线，即 I-C，I-D，I-E，I-B 这几个型号的 SSD 有着远超其他 SSD 的年损耗率，然而其写入特性并没有和其他 SSD 有明显区别。这 4 个极为垃圾的 SSD 型号都是来自 Sandisk 的，而且 Sandisk 一共也就 5 个型号……</strong>😂 造成这一现象的原因是 Sandisk 的 SSD 有着远超其他厂商 SSD 的写放大系数，这一点下面再来具体分析</li></ul><p>根据以上数据我们可以来评估下未来 QLC 的寿命是否能满足数据中心及企业级应用的需求了，这在论文作者的 PPT 里面有计算结果：</p><p><img src="https://img.gaomf.cn/202204072221591.png?500x" alt="QLC Projection"></p><ul><li>未来 QLC SSD 的 PE Cycle Limit 预计在 1k ~ 3k 之间</li><li>如果按 5 年寿命计算，约有 86% ~ 95% 的盘可以用 QLC 替代</li><li>如果按 7 年寿命计算，约有 82% ~ 92% 的盘可以用 QLC 替代</li><li>最终结论：<strong>系统可以整体迁移至 QLC 上</strong></li></ul><h3 id="写放大系数分析"><a href="#写放大系数分析" class="headerlink" title="写放大系数分析"></a>写放大系数分析</h3><p>写放大系数（Write Amplification Factor, <strong>WAF</strong>）是影响 SSD 寿命及性能的关键指标，SSD 存在写放大的原因是其内部存在诸多背景任务（housekeeping tasks），如垃圾回收（GC），损耗平均（Wear Leveling）等。学术界和产业界对于如何控制写放大这一问题都做了很多工作，然而实际 SSD 产品这一点做得究竟如何呢？已有的统计研究都不够广泛，规模也相对较小，因此这篇论文的研究就显得比较有价值了。下面就来看下作者的统计结果吧：</p><p><img src="https://img.gaomf.cn/202204081102721.png?1200x" alt="Figure 3"></p><ul><li>此研究中实际观察到的 WAF 比之前已有研究中观察到的（1.x 左右）要高得多，<strong>96% 的 SSD WAF 都超过了 1.5，中位数达到了 6 左右</strong></li><li>WAF 的分布范围很广，10% 分位值仅为 2，中位数 6，然而 99% 分位值达到了 480。这说明不同应用和设备的 WAF 差异性很大。WAF 的影响因素将在下文详细分析</li><li>这里又要把 Sandisk 几个型号的 SSD 拿出来重点讨论下了，可以看到它们的 WAF 远高于其他厂商的 SSD，中位数竟然就达到了 100 左右（已经超出上图的范围了，论文中直接给出了具体值）。从上文的应用写入速度分析中可以看到，Sandisk 的 SSD 写入量并没有更高，实际使用上也没有任何特殊的地方，所以不能用应用负载差异性来解释此问题，这是 Sandisk SSD 自己的锅跑不掉了</li><li><strong>作者对这一明显异常的问题进行深入研究后发现，Sandisk 的 SSD 之所以有这么高 WAF 的原因在于其背景任务执行得极为频繁，可以说是一有空就开始做背景任务了。然后，最搞笑的来了，这些背景任务是在干嘛呢？既不是在做 GC 也不是在进行损耗平均（绝大部分情况下这两部分是 WAF 的主要来源），而是在极为激进的重写 Block。那为什么要重写呢？因为频繁检测到 Block ECC 错误了！此时不得不重写整个 Block 来避免数据丢失……</strong>🤣 </li></ul><blockquote><p>这感觉是全文最大的亮点啊，看到这简直是惊呆了，消费级不知名小厂做的 SSD 很垃圾不能用也就罢了，Sandisk 好歹也是个国际大厂了，做的企业级 SSD 也能这么垃圾简直是万万没想到啊……这些 SSD 还都是 MLC 颗粒的，这么糟糕的表现是 Flash 颗粒用得太差还是 FTL 固件写得水平太差就不得而知了……</p></blockquote><hr><p>最后来看下应用负载特性与 WAF 的关系：</p><ul><li>同一个型号的 SSD 也表现出了很大的 WAF 差异，其 95% 分位值是中位数的 9 倍以上。同一型号的盘会被用在不同应用上，因此合理的解释就是不同应用负载情况下 WAF 会表现出很大的差异性</li><li> WBC 应用的 WAF 比 AFF 应用要小 ，这也就是前文观察到的，尽管 WBC 写入量要高更多，然而二者实际 SSD 损耗速度差不多的原因了。因此可以说 WBC 应用在某种程度上对 SSD 更为友好</li></ul><hr><p>学术界由于没有那么多真实 SSD 可以用，因此在研究 SSD WAF 时往往使用仿真的方法，然而根据本文的结论，这些仿真得到的 WAF 都太小了，绝大部分已有理论研究论文中 WAF 最高也就 10 左右，这仅仅只是 NetApp 真实环境中的 60% 分位值。作者认为造成这一差异的主要原因有：</p><ul><li>理论研究所使用的 IO Trace 数据太古老了，已经没法反映当今实际运行在 SSD 上的应用负载。此外古老的 IO Trace 数据很多是基于 HDD 盘抓取的，不会存在 TRIM 等 SSD 特有命令</li><li>SSD 仿真软件（如 FEMU）对 FTL 固件的行为仿真存在很大困难，很有可能使用的只是理想模型，这与实际行为差异会很大，且 FTL 固件每家厂商，甚至是不同型号都是有区别的，这让仿真的准确度变得更低了</li></ul><h3 id="损耗平均效果分析"><a href="#损耗平均效果分析" class="headerlink" title="损耗平均效果分析"></a>损耗平均效果分析</h3><p>损耗平均（Wear Leveling）就是把写入尽量平均的打散到所有 Block 上，以此避免某些 Block 被频繁的擦写，造成其寿命下降及性能降低。损耗平均技术是以整体的 PE Cycle 增加来换取长尾减少的，因此实际实现上需要做一个平衡——太过激进的损耗平均会导致 SSD 整体寿命衰减得太快。为了衡量损耗平均的效果，作者引入了擦除率（Erase Ratio）及擦除均匀度（Erase Difference）这两个指标：</p><p><img src="https://img.gaomf.cn/202204081437256.png?500x" alt="Erase Ratio &amp; Erase Difference"></p><p>Erase Ratio 的理想值是 1，对应的 Erase Difference 的理想值是 0。实际当然不会这么理想：</p><p><img src="https://img.gaomf.cn/202204081441488.png?800x" alt="Figure 4"></p><ul><li><strong>Erase Ratio 的中位数是 1.55，意味着写入量最多的 Block 比平均值多写入了 55% 的数据</strong></li><li>5% 的设备 Erase Ratio 大于 6 了，这意味着部分 Block 可能会在全盘只用了 16% PE Cycle 的时候就报废了，这会对 SSD 的整体性能，特别是长尾表现造成明显影响</li><li>部分型号的 SSD 损耗平均做得很好，十分接近理论值，说明这个要做好是可以做好的</li><li>然而，<strong>这时候又要把 Sandisk 的 SSD 拿出来批判一番了，从图中可以很明显的看到 Sandisk 那几款 SSD 损耗平均做得相当之差，尽管这几款 SSD 有着异常高的 WAF，这么高的 WAF 还做出了这么糟糕的损耗平均效果，实在是让人震惊啊……</strong></li></ul><h3 id="空间使用率分析"><a href="#空间使用率分析" class="headerlink" title="空间使用率分析"></a>空间使用率分析</h3><p>这一部分没太大意思，作者分析了一下不同使用年限，不同大小的 SSD 在 AFF 应用场景下空间使用率有啥区别（WBC 应用空间使用率无意义，基本都是 100%）：</p><p><img src="https://img.gaomf.cn/202204081452546.png?800x" alt="Figure 5"></p><ul><li>大部分 SSD 处于半满状态</li><li>空间使用率在用了 1～2 年后就基本稳定了</li><li>越大空间的 SSD 空间使用率越高，原因是购买大空间需要更多的钱，因此用户会对自己需要多少空间做出更细致准确的评估</li></ul><h2 id="写放大系数的影响因素"><a href="#写放大系数的影响因素" class="headerlink" title="写放大系数的影响因素"></a>写放大系数的影响因素</h2><p>直接给出作者在 PPT 中的总结表格吧：</p><p><img src="https://img.gaomf.cn/202204081457878.png?800x" alt="Which factors impact WAF?"></p><p>结论很简单，<strong>FTL 固件算法做得如何是决定性因素；写入负载也有明显影响；其余因素基本没影响。</strong></p><h3 id="FTL-固件实现"><a href="#FTL-固件实现" class="headerlink" title="FTL 固件实现"></a>FTL 固件实现</h3><p>作者此处选用了 III-A 这款 SSD 为例进行分析，这款 SSD 最初的固件版本是 FV2，后面升级到了 FV3：</p><p><img src="https://img.gaomf.cn/202204081510216.png?500x" alt="Figure 6"></p><p>可以看到这次纯软件固件升级有显著优化作用，明显改善了其 WAF；更不要说前面分析过的 Sandisk 产品和 Samsung 产品的差距了。由此可见，SSD 远远不只是搞一些 Flash 颗粒芯片来组装下就好了的，主控软件算法的水平同样是决定性的；甚至可以说，主控的影响有时候比颗粒类型更重要——Samsung 用消费级 TLC 颗粒做出来的 SSD 整体寿命比 Sandisk 用企业级 MLC 颗粒做出来的 SSD 还要好。</p><h3 id="负载特性"><a href="#负载特性" class="headerlink" title="负载特性"></a>负载特性</h3><p>直接进行 IO Trace 是记录负载特性最有效的方法，然而对于大规模系统来说这是基本不可行的。因此作者用 DWPD，SSD 容量，SSD 接口类型这几个指标来对负载类型进行了一个简单分类。SSD 容量和接口类型能用于区分负载类型同样是由于不同容量和接口类型的 SSD 被用于了不同产品和客户上。</p><p>这部分的图不是那么直观就不放了，直接给结论吧：</p><ul><li><strong>越高的 DWPD 会对应越低的 WAF。</strong>这个结论前文也提到了，可能的原因是，很多 FTL 固件实现上是以固定的频率在进行背景任务的，没有与当前的写入量耦合起来，因此较高的 DWPD 减少了背景任务的占比，进而提高了 WAF</li><li>较大容量的 SSD WAF 相对也较小一些，不过这个影响不大</li><li>NVME 接口的 WAF 要小于 SAS，这个更有可能的原因是，NVME 接口更新，使用 NVME 的业务也会更新一些，也就会更多的考虑 SSD 的特性进行优化</li></ul><h3 id="空间使用率"><a href="#空间使用率" class="headerlink" title="空间使用率"></a>空间使用率</h3><p>作者的结论是没有明显影响</p><h3 id="预留空间大小"><a href="#预留空间大小" class="headerlink" title="预留空间大小"></a>预留空间大小</h3><p>这是指 SSD 厂商在内部预留的空间（Over-Provisioning，OP），通常认为这会对 WAF 有明显影响。然而实际看下来影响不大，甚至是有轻微的负相关关系，即预留空间越大的 SSD 反而 WAF 也越大。比如 Sandisk 的那几款 SSD，预留空间达到了惊人的 44%，然而还是被 Samsung 预留空间只有 7% 的 SSD 吊打。</p><blockquote><p>这仔细一想其实也很好理解，预留多少空间当然是根据 FTL 固件的需求决定的，写得越差的 FTL 固件很有可能就需要越多的预留空间……</p></blockquote><h3 id="多流写技术"><a href="#多流写技术" class="headerlink" title="多流写技术"></a>多流写技术</h3><p>多流写（Multi-stream Writes, MSW）技术需要主机端在写入的时候指定一个 Stream ID，支持此特性的 SSD 会根据此 Stream ID 将具有相同或相似生命周期的数据写入到相同的 Block 中去，以此实现冷热数据分离，预期可以大幅提高 GC 时的效率，减少 WAF。此技术的详细介绍可参考文末参考资料中的几篇文章。</p><p>论文中对于多流写技术的影响结论是不确定，原因是缺乏足够的数据进行判断。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>看完全文主要收获有：</p><ul><li>SSD 容量真是越来越大了，30T 的都有了</li><li>大部分 SSD 没想象的那么脆弱的，好点的 SSD 一天好几 T 的写入量也可以用 10 多年，将来用上 QLC 也没有什么问题</li><li>SSD WAF 是很大的，在真实场景下可能会到 10 以上，然而不用太过于担心这个问题，厂商是考虑过这个问题的，给出的寿命及性能指标是考虑了这些的</li><li>多流写听起来很厉害的样子</li><li>SSD 固件差异那是真的大啊</li><li>Sandisk 就是垃圾…… Samsung 还真不错</li></ul><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://www.usenix.org/conference/fast22/presentation/maneas">论文原文及 Presentation</a></p><p><a target="_blank" rel="noopener" href="https://its401.com/article/zhuzongpeng/77571537">浅析企业级SSD Multi-Stream Write技术</a></p><p><a target="_blank" rel="noopener" href="https://www.flashmemorysummit.com/English/Collaterals/Proceedings/2016/20160809_FC12_Choi.pdf">Increasing SSD Performance and Lifetime with Multi-Stream Write Technology</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Operational Characteristics of SSDs in Enterprise Storage Systems: A Large-Scale Field Study&lt;/p&gt;
&lt;p&gt;此论文为多伦多大学与 NetApp 合作发表在 FAST’22 上的论文，统计分析了 NetApp 线上两百多万块 SSD 在过去 4 年内的运行数据，以此总结了 SSD 寿命，写放大这两个核心运维特性在大规模线上环境下的真实情况及其影响因素。&lt;/p&gt;
&lt;p&gt;看完最大的感想是，SSD 间差异是巨大的，垃圾厂家的 SSD 真是不能用……&lt;/p&gt;</summary>
    
    
    
    <category term="科研之路" scheme="https://gaomf.cn/categories/%E7%A7%91%E7%A0%94%E4%B9%8B%E8%B7%AF/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="Storage" scheme="https://gaomf.cn/tags/Storage/"/>
    
    <category term="Flash" scheme="https://gaomf.cn/tags/Flash/"/>
    
    <category term="Paper" scheme="https://gaomf.cn/tags/Paper/"/>
    
    <category term="SSD" scheme="https://gaomf.cn/tags/SSD/"/>
    
  </entry>
  
  <entry>
    <title>【读读论文】RocksDB 发展回顾及展望</title>
    <link href="https://gaomf.cn/2021/11/28/Paper_RocksDB_Developemnt/"/>
    <id>https://gaomf.cn/2021/11/28/Paper_RocksDB_Developemnt/</id>
    <published>2021-11-28T12:39:00.000Z</published>
    <updated>2022-04-08T12:34:26.855Z</updated>
    
    <content type="html"><![CDATA[<p>Evolution of Development Priorities in Key-value Stores Serving Large-scale Applications: The RocksDB Experience</p><p>此论文为 Facebook 发表在 FAST’21 上的论文，回顾了 RocksDB 在过去 8 年的演进中设计上核心关注点的变化及相应的优化措施，以及在性能，功能，易用性上所做的探索工作；此外还总结了将 RocksDB 应用于大规模分布式系统及系统错误处理上需要考虑的一些问题及经验教训。论文中没有论述具体的技术细节，更多的是从宏观的面上讨论了核心设计思想及工程实现上的各种权衡。</p><p>下面就来看下此论文具体讲了些什么，引用部分为我自己的笔记。</p><span id="more"></span><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a>1 引言</h2><p>RocksDB 是 Facebook 基于 Google 的 LevelDB 于 2012 年开发的一款高性能 KV 存储引擎，在设计之初 RocksDB 就是针对 SSD 来进行设计及优化的，且 RocksDB 的定位一直都很清晰——只做一个核心存储引擎而不是完整的应用，作为一个嵌入式的库集成到更大的系统中去。</p><p>RocksDB 是高度可定制的，因此它作为一个核心 KV 存储引擎能适应各种工作负载，用户可以根据自己的需要对它进行针对性调优，如为读性能优化，为写性能优化，为空间使用率优化，或它们之间的某个平衡点。正是因为如此灵活的可配置性，RocksDB 可以作为很多不同数据库的存储引擎使用，如 MySQL，CockroachDB，MongoDB，TiDB 等，也可以满足流式计算（Stream processing），日志服务（Logging/queuing services），索引服务（Index services），缓存服务（Caching on SSD）等多种特性完全不同的业务需求。这些不同业务场景特性总结如下：</p><p><img src="https://img.gaomf.cn/202111232051352.png?500x" alt="不同 RocksDB 负载特性"></p><p>这么多不同应用共用一个相同的存储引擎与每个应用都去搭一套自己的存储子系统相比有很多优势：</p><ul><li>无论是多简单的存储相关应用都要处理数据损坏，异常恢复，文件系统错误处理等问题，一个统一的存储引擎可以把这些都处理了，避免重复造轮子；</li><li>由于使用了同一套存储引擎，不同系统间可以共用一套统一的基础设施，如一致的监控系统，运维工具，调试工具等；</li><li>由于底层都是一样的，各种调试经验等在不同应用间都是可以复用的。</li></ul><blockquote><p>文中说这些基本就是用一个统一轮子的好处了，其实对于个人来说还有些其他额外好处，由于不同公司不同 Team 都选用了同样的底层引擎，人员流动就会变得更方便了：）</p></blockquote><p>引言最后照例介绍了下文章结构：</p><ul><li>第 2 章主要介绍了 RocksDB 之所以选择 LSM-tree 作为其核心数据结构的考虑。作者认为 LSM-tree 至今都很好，选用 LSM-tree 也是 RocksDB 能适应各种不同工作负载的关键所在；</li><li>第 3 章主要介绍了 RosksDB 的核心优化目标的变化，由最小化写放大到最小化空间放大；由性能优化到效率优化；</li><li>第 4 章主要介绍了使用 RocksDB 搭建大规模分布式系统时的一些经验教训；</li><li>第 5 章主要介绍了 RocksDB 在错误处理方面的一些考虑；</li><li>第 6 章主要介绍了 RocksDB 对于 KV 接口演化的一些思考；</li><li>第 7，8，9 章则分别是相关工作介绍，未来发展方向展望及结论。</li></ul><h2 id="2-背景"><a href="#2-背景" class="headerlink" title="2 背景"></a>2 背景</h2><h3 id="2-1-基于-SSD-的嵌入式存储引擎"><a href="#2-1-基于-SSD-的嵌入式存储引擎" class="headerlink" title="2.1 基于 SSD 的嵌入式存储引擎"></a>2.1 基于 SSD 的嵌入式存储引擎</h3><p>RocksDB 设计之初就是为 SSD 及现代硬件优化的。SSD 的 IOPS 及读写带宽都大幅优于传统机械硬盘，不过其寿命有限，且写入性能会由于擦除而恶化，因此设计一款针对 SSD 的嵌入式 KV 存储引擎就变得更有必要了，这就是 RocksDB 的设计初衷——设计一款极具灵活性可用于各类应用的，使用本地 SSD 并为其优化的 KV 存储引擎。</p><h3 id="2-2-RocksDB-架构"><a href="#2-2-RocksDB-架构" class="headerlink" title="2.2 RocksDB 架构"></a>2.2 RocksDB 架构</h3><p>RosksDB 的核心数据结构是 LSM-tree，其基本结构如下：</p><p><img src="https://img.gaomf.cn/202111241305118.png?600x" alt="LSM-tree"></p><p>几种基本操作的流程简述如下：</p><ol><li><p>写入（Writes）</p><p>先写 Memtable 及 WAL 文件（Write Ahead Log），Memtable 通常使用跳表（Skip List）作为其数据结构。Memtable 写满后转换为不可变的 Memtable（immutable Memtable），并同时生成一个新的 Memtable 供写入；随后 immutable Memtable 会被写入到磁盘上变成 SST 文件（Sorted String Table）。</p></li><li><p>压缩（Compaction）</p><p>Compaction 有多种不同算法，RocksDB 最古老的 Compaction 算法是源于 LevelDB 的 Leveled compaction。其基本原理如上图所示，Memtable dump 生成的 SST 文件位于 Level-0，当某个 Level 中所有 SST 大小超过阈值后选择其中的一部分文件 Merge 到下一个 Level 中。除 Level-0 外，其他 Level 内不同 SST 文件间 key 的范围没有重合。</p></li><li><p>读取（Reads）</p><p>读取时从小到大遍历所有 Level，直到读到为止。可使用布隆过滤器（Bloom filters）来避免不需要的 IO。Scan 时需要扫描所有 Level。</p></li></ol><p>RocksDB 支持多种不同的 Compaction 算法：</p><ul><li>Leveled compaction。源自 LevelDB，上文已经介绍了其原理，每一层的阈值是指数形式增加的。</li><li>Tiered compaction，RocksDB 中又叫 Universal Compaction，类似 Apache Cassandra 或 Hbase 中使用的方法，简单的把多个小的 SSTable 合并成一个大的 SSTable。</li><li>FIFO compaction，达到大小限制后直接把最老的 SSTable 丢掉，这种策略只适用于一些纯内存的 Cache 应用等。</li></ul><blockquote><p>Tiered compaction 与 Leveled compaction 的核心区别在于每个 Level 中不同 SSTable 间 Key 的范围是否有重叠（overlap），leveled compaction 策略下同一 Level 内 SSTable 间 Key 是不会有重叠的，因此读的时候只会读一个 SSTable，IO 放大是可控的。Tiered compaction 则没有此性质，不同 SSTable 间 Key 范围是有重叠的。这两种 compation 策略的选择其实也是读放大与写放大间的权衡。</p><p>可以进一步参考下此文：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/112574579">LSM Tree的Leveling 和 Tiering Compaction</a></p></blockquote><p>可以使用多种不同的 Compaction 策略使得 RocksDB 可以适用于广泛的应用场景，通过配置 RocksDB 可以变成为读优化，为写优化或极度为写优化（用于 Cache 等应用中）。不同的配置其实是读写放大间的平衡问题，一些实际的测试结果如下：</p><p><img src="https://img.gaomf.cn/202111241446703.png?500x" alt="image-20211124144605620"></p><p><img src="https://img.gaomf.cn/202111241446926.png?500x" alt="image-20211124144641862">   </p><h2 id="3-资源优化目标的演进"><a href="#3-资源优化目标的演进" class="headerlink" title="3 资源优化目标的演进"></a>3 资源优化目标的演进</h2><p>RocksDB 的优化目标最初是减少写放大，之后过渡到减少空间放大，目前重点则是优化 CPU 使用率。</p><h3 id="写放大"><a href="#写放大" class="headerlink" title="写放大"></a>写放大</h3><p>这是刚开始开发 RocksDB 时的重点优化目标，一个重要原因是为了减少 SSD 的写入量以延长其寿命，这对某些写入很多的应用来说至今仍然是首要优化目标。</p><p>Leveled compaction 的写放大系数一般在 10～30 左右，这在大部分情况下是优于 B-tree 的，与 MySQL 中使用的 InnoDB 引擎相比，RocksDB 的写数量仅为其的 5% 左右。然而对于某些写入量很大的应用来说，10～30 的写放大系数还是太大了，所以 RocksDB 引入了 Tiered compaction，其放大倍数通常在 4～10 左右。</p><h3 id="空间放大"><a href="#空间放大" class="headerlink" title="空间放大"></a>空间放大</h3><p>在经过若干年开发后，RocksDB 的开发者们观察到对于绝大多数应用来说，空间使用率比写放大要重要得多，此时 SSD 的寿命和写入开销都不是系统的瓶颈所在。实际上由于 SSD 的性能越来越好，基本没有应用能用满本地 SSD，因此 RocksDB 开发者们将其优化重心迁移到了提高磁盘空间使用率上。</p><p>RocksDB 开发者们引入了所谓的 Dynamic Leveled Compaction 策略，此策略下，每一层的大小是根据最后一层的大小来动态调整的。</p><blockquote><p>Tiered compaction 的空间放大和 Level compaction 根本没法比，极端情况下需要预留一半空间才能顺利进行完整的 compaction，因此这里就直接不讨论了。</p><p>Dynamic Leveled Compaction 的具体介绍可参考：</p><p><a target="_blank" rel="noopener" href="http://rocksdb.org/blog/2015/07/23/dynamic-level.html">Dynamic Level Size for Level-Based Compaction</a></p><p>核心思想就是让稳态情况下更多的做一些 compaction。</p></blockquote><p>此策略的效果如下：</p><p><img src="https://img.gaomf.cn/202111241534602.png?500x" alt="Dynamic Leveled Compaction Compare"></p><h3 id="CPU-使用率"><a href="#CPU-使用率" class="headerlink" title="CPU 使用率"></a>CPU 使用率</h3><p>随着 SSD 的速度越来越快，一种普遍的担心是，系统的瓶颈会不会由磁盘 IO 转移到 CPU 上呢？然而作者认为无需担心此问题，原因如下：</p><ul><li>真实场景中，只有极少数应用会受限于 SSD 能提供的 IOPS，绝大部分应用是受限于 SSD 的存储空间；</li><li>目前高端服务器 CPU 有足够多的计算资源来满足<strong>一块</strong>高端 SSD 的需求，当然如果一台机器上有多块 SSD，则 CPU 是有可能会成为瓶颈的，然而作者认为这是系统配置问题，完全可以通过调整 CPU 和 SSD 配比来解决此问题……</li><li>就算某些应用 CPU 真成瓶颈了，这意味着此时存在大量 SSD 写入，这也意味着这块 SSD 命不久矣……</li></ul><p>为了证明此观点是正确的，作者给出了若干个 ZippyDB &amp; MyRocks 的实际测试结果用以论证空间才是瓶颈所在：</p><p><img src="https://img.gaomf.cn/202111242103743.png?500x" alt="ZippyDB &amp; MyRocks"></p><p>虽然说了这么多无需太担心 CPU 成为瓶颈，作者认为我们还是要去优化 CPU 使用率，为什么呢？因为其他更重要的优化，如空间放大优化都做完了没有可做的了……（这段真不是我瞎写的，原文就是这么说的：Nevertheless, reducing CPU overheads has become an important optimization target, given that the low hanging fruit of reducing space amplification has been harvested.）此外，CPU 和内存还越来越贵了，优化 CPU 使用可以让我们用一些更便宜的 CPU……</p><p>一些有助于优化 CPU 使用率的早期尝试包括：前缀布隆过滤器（Prefix bloom filters），在查找索引前就先通过 bloom filter 进行过滤，还有其他一些 bloom filter 的优化。</p><blockquote><p>对于上述论述不甚赞同……</p><ol><li>作者这是假设这台机器上只跑 RocksDB，上层应用是很轻量级的，把全部 CPU 资源都给 RocksDB 用才没有瓶颈，这显然是很有问题的，有可能上层应用本身就需要很多 CPU 啊，而且作为一个 KV Engine 就把大部分 CPU 资源用完了不太合理吧。这还不要说在共有云等场景下大规模混部的情况了，此时所有空余的 CPU 都是可以用来干其他事的。</li><li>不知作者为什么认为一台机器上只配一块 SSD 才是最优搭配，根据我的经验这分明是不太好的搭配吧，正因为 SSD 少了存储空间才成瓶颈的，一台机器上使用 2～4 块 NVME SSD 才是目前更主流且合理的方案吧，要是机器上还有多个 RocksDB 实例在同时工作，此时 CPU 显然很容易成为瓶颈吧。</li></ol></blockquote><h3 id="适配新技术"><a href="#适配新技术" class="headerlink" title="适配新技术"></a>适配新技术</h3><p>作者列举了一些存储领域的新技术，如 open-channel SSD，mulit-stream SSD，ZNS（Zone namespace，类似抽象得更好的 open-channel SSD），这些都能降低 IO 延迟，然而作者又抛出了绝大部分应用都是受空间制约的这一论据，认为这些技术并没有什么实际用处……此外如果要让 RocksDB 这一层直接用上这些技术会破坏 RocksDB 统一一致的体验，因此更值得尝试的方向是下层文件系统去适配这些新技术，RocksDB 专注于 KV 引擎层该做的工作，而不是去做底层 FS 存储层该做的事。</p><blockquote><p>前面空间制约这一说法不敢苟同……后面的说法倒是的确很有道理，每一层就专注做这一层该做的事吧。</p></blockquote><p>存算一体（In-storage computing）也是个很有潜力的技术，然而尚不确定 RocksDB 要如何用它，以及能从中获得多大的收益，后续会继续关注研究此技术。</p><p>远端存储（Disaggregated/remote storage）是目前阶段更有意义的优化目标，上文也提到了 CPU 和本地 SSD 盘很难都同时用满，然而若用的是存算分离的架构则不存在此问题了。对于 RocksDB 来说，对远端存储的优化主要集中在聚合 IO 及并行化 IO 上，此外还有对瞬时网络错误的处理，将 QoS 需求下传至底层系统，提供 Profiling 信息等。</p><blockquote><p>资源使用率优化是存算分离架构最大的优点之一。</p></blockquote><p>持久性内存（Persistent Memory, PMem，又称 Storage Class Memor, SCM）是另一个极有前途的技术，对于 RocksDB 来说有以下这些值得尝试的方向：</p><ul><li>将 PMem 作为内存的扩展。这个尝试的挑战是在 DRAM 与 PMem 并存时如何优化内存数据结构（Block cache 及 Memtable），并且在尝试利用其非易失性时会有什么额外开销；</li><li>将 PMem 直接用作系统的主存储介质。SSD 性能作者都认为过剩了当然不会认为这是很好的优化方向；</li><li>使用 PMem 来保存 WAL 文件。这个想法的问题在于，数据只会在 WAL 文件中停留很短时间，用 PMem 来做是否值得，毕竟 PMem 还是比 SSD 贵很多的。</li></ul><h3 id="主要数据结构选择回顾"><a href="#主要数据结构选择回顾" class="headerlink" title="主要数据结构选择回顾"></a>主要数据结构选择回顾</h3><p>经过了这么多年的发展，LSM-tree 这一基本数据结构是否还合适呢？作者给出的答案是，Yes！LSM-tree 至今还很适合 RocksDB 使用。主要原因是 SSD 的价格还没有降到足够低的程度，即可以让大部分应用都不在意其寿命损耗的程度，此类应用只是很少一部分应用。然而，当 Value 很大时，分离 KV （如 <a target="_blank" rel="noopener" href="https://www.usenix.org/conference/fast16/technical-sessions/presentation/lu#:~:text=We%20present%20WiscKey%2C%20a%20persistent,performance%20characteristics%20of%20the%20device.">WiscKey</a>）可以显著降低系统写入放大，所以此功能也被加入到了 RocksDB 中（被称为 <a target="_blank" rel="noopener" href="http://rocksdb.org/blog/2021/05/26/integrated-blob-db.html">BlobDB</a>）。</p><h2 id="4-应用于大规模系统中的经验教训"><a href="#4-应用于大规模系统中的经验教训" class="headerlink" title="4 应用于大规模系统中的经验教训"></a>4 应用于大规模系统中的经验教训</h2><h3 id="资源管理"><a href="#资源管理" class="headerlink" title="资源管理"></a>资源管理</h3><p>在大规模分布式数据存储系统中，通常都会将数据分为若干个 Shard，再把不同 Shard 分配到不同存储节点上。单个 Shard 的大小通常是有上限的，原因是 Shard 是负载均衡和多副本的基本单位，需要能在不同节点间自动拷贝。每个服务节点上通常都会有数十个或数百个 Shard。在使用 RocksDB 的通常实践中，一个 RocksDB 实例只用于管理<strong>一个</strong> Shard，因此一个服务节点上也就会有很多 RocksDB 实例在同时运行，这些实例可以运行在同一地址空间下，也可运行在不同地址空间下。</p><blockquote><p>这里分别就是多线程和多进程模型吧。</p></blockquote><p>一台 Host 上会运行多个 RocksDB 实例的事实让资源管理变得更为复杂，因为资源需要同时在全局（整个 Host）和局部（单个 RocksDB 实例）两个维度上进行管理。</p><p>当不同实例运行在同一个进程内时资源管理相对较为简单，只要限制好各种全局资源，如内存，磁盘带宽等的使用即可。RocksDB 支持对每类资源都创建一个资源控制器（resources controller），并将其传递个各实例，以实现实例内的局部资源管理，这个资源管理还是支持优先级的，可以灵活的在不同实例间分配资源。</p><p>然而若不同实例时运行在不同进程上时，资源管理就会变得更有挑战性。解决此问题有两个思路：</p><ul><li>每个实例配置成保守的使用资源的模式，即先设置一个较低的限额，当出现瓶颈后再尝试去用更多的资源。此方案的缺点很明显，全局的资源使用率不是最优的。</li><li>实例间通过 ICP 或其他机制共享资源分配信息，以此实现一个更优的局部资源分配。这条路上 RocksDB 还有很多工作需要做。</li></ul><p>此外，另一个经验教训是，随意使用独立的线程会导致很多问题，这会使得总的线程数变得很多且不可控，进而导致线程切换开销增大及很痛苦的 debug 过程。一个更好的选择是使用线程池，这可以根据实际情况去控制总的线程数量。</p><h3 id="WAL-文件的处理"><a href="#WAL-文件的处理" class="headerlink" title="WAL 文件的处理"></a>WAL 文件的处理</h3><p>传统的数据库都是使用 WAL 文件来保证数据持久性的，然而大规模分布式存储系统更多的是依赖于不同节点上的多副本来保证这一点的，单节点的数据损坏可以通过其他节点来进行修复，对于这类系统来说，RocksDB 的 WAL 文件就没那么重要了。进一步，很多一致性协议（如 Paxos，Raft 等）有其自己的 Log，这种情况下 RocksDB 的 WAL 文件就完全没用了。</p><p>因此 RocksDB 提供了三种不同的 WAL 策略可供选择：</p><ul><li>同步 WAL 文件写入；</li><li>缓冲（buffered）WAL 文件写入，即在后台以低优先级异步刷 WAL 文件；</li><li>没有 WAL 文件。</li></ul><h3 id="删除文件限速"><a href="#删除文件限速" class="headerlink" title="删除文件限速"></a>删除文件限速</h3><p>RocksDB 底层的文件系统通常是选用 SSD-aware 的文件系统，如 XFS，此类文件系统在删除文件时可能会显式的向底层 SSD 固件发送 TRIM 命令。此行为通常有助于提高 SSD 的性能及寿命，然而某些时候也会导致一些性能问题。TRIM 命令其实是没那么轻量级的，SSD 固件在收到 TRIM 命令后会更新其地址映射关系，此行为有可能需要写入 FTL 日志（journal），而 FTL journal 是位于 Flash 上的，这又有可能会触发 SSD 内部的 GC，进而导致大量的数据迁移，此行为会干扰前台写入造成写入延迟的上升。为解决此问题，RocksDB 引入了一个速率限制器来限制 compaction 后并发删除的速度。</p><h3 id="数据格式兼容性"><a href="#数据格式兼容性" class="headerlink" title="数据格式兼容性"></a>数据格式兼容性</h3><p>大规模的分布式系统之所以叫大规模了，当然是因为整个系统中的机器数很多喽，此时升级肯定是增量式进行的，没有任何实际生产系统会对所有节点做同步升级。因此需要保证两种基本兼容性：</p><ul><li>新老版本间数据的兼容性，因为要考虑到回滚，向前兼容性和向后兼容性都是需要的；</li><li>不同版本运行在同一集群下数据的兼容性，因为分布式系统会在节点间搬移数据，要考虑二者并存的时候整个系统是正常的。</li></ul><p>如果不保证这些兼容性就会给运维带来极大的困难。对于向后兼容性（backward compatibility）来说，RocksDB 要能识别之前版本的数据，这的代价通常是软件复杂度；而向前兼容性（forward compatibility）通常是更难保证的，这要求老版本要能识别新版本的数据，RocksDB 通过 Protocol Buffer 等技术来一定程度的保证了<strong>至少一年</strong>的向前兼容。</p><blockquote><p>backward compatibility 相对比较好做，顶多就是代码写得复杂点；然而 forward compatibility 要困难的多，甚至是在很多时候根本就是不可行的，一个系统的 forward compatibility 如何很大程度上是取决于设计之初设计者的远见与前瞻性的。</p></blockquote><h3 id="配置方式管理"><a href="#配置方式管理" class="headerlink" title="配置方式管理"></a>配置方式管理</h3><p>RocksDB 的一大特色就是其高度可配置性，这也是它能用于满足各种工作负载需求的原因所在，然而此时配置管理也就变得很有挑战性了。最初 RocksDB 的配置方式类似于 LevelDB，有哪些配置项及其默认值等都是写死在代码中的，这种方式有两个问题：</p><ul><li>某些配置项是和磁盘上的数据密切相关的，如果数据是根据 A 配置生成的，而另一个实例使用 B 配置去读取就会发生问题；</li><li>RocksDB 版本升级有可能会修改代码中的默认值，这在某些时候会造成一些非预期的结果。</li></ul><p>为解决此问题，RocksDB 支持针对每个数据库使用不同的配置文件，而非一个 RocksDB 实例只能用一个统一的配置文件。此外还提供了一些辅助工具：</p><ul><li>检查配置文件和实际数据库数据间的兼容性工具；</li><li>数据库数据迁移工具，可以根据期望的配置文件来进行数据重写迁移。</li></ul><p>另一个更严峻的问题是 RocksDB 的配置项实在是太多了，这是 RocksDB 早期之所以能得到广泛应用的一个原因，然而过多的配置项也让配置的复杂性和混乱程度变得很高，要弄清楚每个配置项是干嘛的基本是不可能的。这些配置项如何配置才是最优的不仅取决于 RocksDB 的运行环境，还取决于其上层应用，还有上层应用更上层的负载情况等等，这些都会让调参变得极为困难。 </p><p>这些真实世界中遇到的问题让 RocksDB 的开发者们重新检视了其最初的配置支持策略，开始努力提高 RocksDB 开箱即用性能及简化配置项。目前开发的重点是在保持高度可配置性的基础上提供更强大的自适应性（automatic adaptivity），要同时做到这两点会显著增加代码维护的负担，然而开发者们认为这是值得的～</p><h3 id="多副本及数据备份支持"><a href="#多副本及数据备份支持" class="headerlink" title="多副本及数据备份支持"></a>多副本及数据备份支持</h3><p>RocksDB 本身是一个单节点的库，使用 RocksDB 的应用需要自己处理多副本及备份问题，不同应用的处理方法不尽相同，因此 RocksDB 需要对此提供恰当的支持。</p><p>在新节点上重新拉起一个副本有两种策略：</p><ul><li>逻辑拷贝（Logical copying），从源副本读数据再写到目标副本去。对于这种方式，RocksDB 提供了 Scan 接口支持，且提供了让这类 scan 尽量少影响在线服务的能力，如这类操作读到的数据不加到 Cache 里面；目标端提供 bulk loading 支持。</li><li>物理拷贝（Physical copying），直接把 SSTable 及其他文件拷贝过去。RocksDB 对这种方式的支持在于，可以提供当前数据库用到的 SSTable 及其他文件不会被删除或修改的能力。支持物理拷贝也是 RocksDB 选择将底层架在一个文件系统而非裸盘上的重要原因，这可以方便使用文件系统自己提供的工具来实现这一 Copy，开发者们认为，直接使用裸盘带来的性能收益并不比上述优势的收益更大。</li></ul><p>备份也是很多数据库或其他应用所需的一个重要功能。备份与多副本一样也有逻辑和物理两种方式，然而与多副本不同的是，应用通常需要管理多个版本的备份数据。尽管大部分应用都实现了其自己的备份策略，RocksDB 也提供了一个简单基本的备份引擎。</p><h2 id="5-错误处理的经验教训"><a href="#5-错误处理的经验教训" class="headerlink" title="5 错误处理的经验教训"></a>5 错误处理的经验教训</h2><h3 id="静默错误出现概率"><a href="#静默错误出现概率" class="headerlink" title="静默错误出现概率"></a>静默错误出现概率</h3><p>由于性能原因，RocksDB 一般不使用 DIF/DIX 等 SSD 提供的数据保护功能，而是使用最为通用的校验和策略。根据作者的观测，RocksDB 层面的错误在 100PB 规模下大概每 3 个月就会出现一次，更糟糕的是，大约 40% 的情况下，错误已经被扩散到多个副本里去了。</p><h3 id="多层次的数据保护"><a href="#多层次的数据保护" class="headerlink" title="多层次的数据保护"></a>多层次的数据保护</h3><p>数据损坏越早被检出系统的可用性及可靠性就会越好，大部分基于 RocksDB 的应用都使用不同机器上的多副本策略，此时检测到一个副本校验和错误后可以根据其他副本进行修复，前提是正确的副本还存在。</p><p>目前的 RocksDB 校验和保护机制可分为 4 层（含计划中的应用层校验和）：</p><p><img src="https://img.gaomf.cn/202111281738877.png?500x" alt="image-20211128173834771"></p><ul><li>Block checksum。源于 LevelDB，SSTable 中 Block 级别的校验，会在每次读取时进行检查，用于防止由于底层文件系统导致的数据损坏；</li><li>File checksum。在 2020 年加入，整个 SSTable 的校验，保存在 SSTable 的 meta 字段中，用于防止在传输整个 SSTable 过程中发生的数据损坏；</li><li>Handoff checksum。用于保护 WAL 文件的机制，核心思想是在写入时将数据及其对应的校验码一起发给底层文件系统，底层文件系统对每次的增量写入进行校验，以此避免写入 WAL 这一过程中发生的错误。然而不幸的是，绝大部分本地文件系统是不支持此类 API 接口的。不过对于远端文件系统来说，可以通过修改 API 接口来支持此类端到端的保护功能。</li><li>K/V checksum。计划中的功能，需要修改 RocksDB 的 API 接口并要上层应用配合实现，为每个 kv 都加入校验，这是最彻底的端到端的数据保护措施。</li></ul><h3 id="分级错误处理"><a href="#分级错误处理" class="headerlink" title="分级错误处理"></a>分级错误处理</h3><p>RocksDB 遇到的大部分错误都是底层文件系统返回的错误，最初 RocksDB 处理这些错误的方式就是不处理，即直接将这些错误抛给上层应用或永久停止写入。目前开发者们更倾向仅在 RocksDB 自身无法处理或恢复时才中断 RocksDB 的正常流程，实现这的基本方法就是对某些暂时性错误在 RocksDB 层面就进行重试。上层收到 RocksDB 的错误后一般处理方法都是进行实例迁移，RocksDB 自身进行了重试后上层因此造成的实例迁移就会少很多。</p><h2 id="6-KV-接口设计的经验教训"><a href="#6-KV-接口设计的经验教训" class="headerlink" title="6 KV 接口设计的经验教训"></a>6 KV 接口设计的经验教训</h2><h3 id="版本及时间戳"><a href="#版本及时间戳" class="headerlink" title="版本及时间戳"></a>版本及时间戳</h3><p>核心的 KV 接口是如此的通用，以至于基本所有的存储负载都可以被 KV 接口所满足，这就是 KV 存储这么流行的原因了。然而对某些应用来说，这么简单的接口可能会制约其性能。比如要想基于 KV 接口做 MVCC（Multiversion concurrency control，多版本并发控制）的开销就会很大。</p><p>RocksDB 内部是有一个 56-bit 的序列号用于区分不同版本的 KV 对的，也支持快照（Snapshot）功能，生成了一个 Snapshot 后此时的所有 KV 对都是不会被删除的，直到显式的释放了此快照，因此同一个 Key 是可以有多个序列号不同的 Value 的。</p><p>然而此种简单的多版本机制是没法完全满足很多应用需求的，原因在于此机制存在一些局限性：</p><ul><li>要读到历史数据的必要条件是历史数据的 Snapshot 已经存在了，RocksDB 是不支持对过去时间再进行快照的；</li><li>上述序列号是单个 RocksDB 实例自己生成并维护的，只保证其是一个递增的序列号，用户写入时也不能指定此序列号，因此基本是没法建立一个全局跨 Shard 的一致性读（由于不同实例间的序列号没有可比性）。</li></ul><p>应用想要绕开这些限制只能在 Key 或 Vaule 中自行编码加入时间戳，然而这会导致性能下降：</p><ul><li>在 Key 中编码时间戳会让查询变得低效，原因是之前的单次 Query 变成了范围 Scan；</li><li>在 Value 中编码时间戳会让写入变得低效，因为要更新 Vaule 必须要进行 RMW（Read-Modify-Write） 操作。</li></ul><p>因此在 KV 接口层面就支持指定时间戳会是一个更好的解决方案，目前 RocksDB 对此已经提供了基本的支持。以应用自行在 Key 中编码时间戳的性能为基准，原生带时间戳的 KV 接口性能如下：</p><p><img src="https://img.gaomf.cn/202111281827346.png?500x" alt="image-20211128182700205"></p><p>可以看到至少有 1.2 倍性能提升，原因在于查询操作可以使用正常 Query 接口而非 Scan 接口了，此时 Bloom Filter 等就都可以起作用了。此外 SSTable 包含的时间戳范围可以加入到其元信息中了，这就有助于在读的时候直接跳过不符合要求的 SSTable 文件。</p><p>开发者们认为，此功能有助于上层应用实现 MVCC 或其他分布式事务功能，然而并不考虑开发更复杂的多版本功能，原因是更复杂的多版本功能使用起来并不那么直观，也可能会被误用；且为了保存时间戳需要更多的磁盘空间，也使得接口上与其他 KV 系统间的可移植性变差。</p><h2 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7 相关工作"></a>7 相关工作</h2><p>这部分主要就是介绍在存储引擎库，基于 SSD 的 KV 存储系统，LSM-tree 优化，大规模存储系统这几方面上还有些什么研究，感兴趣的可以去看看原文。</p><h2 id="8-未来的工作及一些开放问题"><a href="#8-未来的工作及一些开放问题" class="headerlink" title="8 未来的工作及一些开放问题"></a>8 未来的工作及一些开放问题</h2><p>除了上文提及的支持远端存储，KV 分离，多层次校验和，应用指定时间戳外，还计划统一 Leveled 及 Tiered compaction 策略和增强自适应性，此外还有些开放问题：</p><ul><li>如何使用 SSD/HDD 混合存储来优化系统效率；</li><li>当存在很多删除时如何尽量保证此时的读性能；</li><li>如何优化写入限流算法；</li><li>如何高效的比较两个副本，以确定其包含相同的数据；</li><li>如何最好的使用 PMEM，此时还该继续使用 LSM-Tree 么？如何支持多存储层级；</li></ul><h2 id="附录-A-RocksDB-发展路线图"><a href="#附录-A-RocksDB-发展路线图" class="headerlink" title="附录 A. RocksDB 发展路线图"></a>附录 A. RocksDB 发展路线图</h2><p><img src="https://img.gaomf.cn/202111242257178.png?700x" alt="image-20211124225709050"></p><blockquote><p>很不错的图～可以看到 RocksDB 性能上的优化主要聚焦于 Compaction 及 Bloom Filter 展开～</p></blockquote><h2 id="附录-B-重要结论总结"><a href="#附录-B-重要结论总结" class="headerlink" title="附录 B. 重要结论总结"></a>附录 B. 重要结论总结</h2><ol><li>一个存储引擎能通过调参来适应不同工作负载是很重要的；</li><li>对于使用 SSD 的大部分应用来说，系统瓶颈是在 SSD 容量上；</li><li>降低 CPU 开销也变得越来越重要；</li><li>如果一台机器上运行了多个 RocksDB 实例，那全局的资源管理就会变得很必要；</li><li>提供不同的 WAL 文件处理方式可以给上层应用带来性能提升；</li><li>SSD TRIM 是个好命令，然而需要对文件删除操作进行限速以避免偶发性的性能问题；</li><li>RocksDB 需要同时具有向前及向后兼容性；</li><li>配置的自适应性对于简化配置管理来说很有帮助；</li><li>需要恰当的支持多副本及数据备份；</li><li>数据损坏发现的越早越好，而非最后用到时才发现；</li><li>CPU 及内存导致的数据损坏很罕见，然而是有可能发生的，此类数据损坏有时是不能被多副本所修复的；</li><li>数据完整性保护需要覆盖全系统；</li><li>用户通常是期望 RocksDB 能从暂时 IO 错误中自动恢复过来的；</li><li>错误需要根据其原因及后果不同而采用不同处理方式；</li><li>KV 接口是通用的，然而会有些性能局限性，增加一个时间戳可以很好的平衡性能和简单易用性。 </li></ol><h2 id="附录-C-设计之初一些不太合适的观点"><a href="#附录-C-设计之初一些不太合适的观点" class="headerlink" title="附录 C. 设计之初一些不太合适的观点"></a>附录 C. 设计之初一些不太合适的观点</h2><ol><li>对用户来说可自定义的程度越高越好；</li><li>RocksDB 无法处理类似 CPU 位反转这类错误；</li><li>一旦发生 IO 错误就直接停止工作是可以接受的。</li></ol><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://www.usenix.org/conference/fast21/presentation/dong">论文原文及 Presentation</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Evolution of Development Priorities in Key-value Stores Serving Large-scale Applications: The RocksDB Experience&lt;/p&gt;
&lt;p&gt;此论文为 Facebook 发表在 FAST’21 上的论文，回顾了 RocksDB 在过去 8 年的演进中设计上核心关注点的变化及相应的优化措施，以及在性能，功能，易用性上所做的探索工作；此外还总结了将 RocksDB 应用于大规模分布式系统及系统错误处理上需要考虑的一些问题及经验教训。论文中没有论述具体的技术细节，更多的是从宏观的面上讨论了核心设计思想及工程实现上的各种权衡。&lt;/p&gt;
&lt;p&gt;下面就来看下此论文具体讲了些什么，引用部分为我自己的笔记。&lt;/p&gt;</summary>
    
    
    
    <category term="科研之路" scheme="https://gaomf.cn/categories/%E7%A7%91%E7%A0%94%E4%B9%8B%E8%B7%AF/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="Storage" scheme="https://gaomf.cn/tags/Storage/"/>
    
    <category term="RocksDB" scheme="https://gaomf.cn/tags/RocksDB/"/>
    
    <category term="Distributed System" scheme="https://gaomf.cn/tags/Distributed-System/"/>
    
    <category term="System Design" scheme="https://gaomf.cn/tags/System-Design/"/>
    
    <category term="KV" scheme="https://gaomf.cn/tags/KV/"/>
    
    <category term="Paper" scheme="https://gaomf.cn/tags/Paper/"/>
    
  </entry>
  
  <entry>
    <title>TLA+ 形式化验证入门指南</title>
    <link href="https://gaomf.cn/2021/08/01/TLA_Tutorial/"/>
    <id>https://gaomf.cn/2021/08/01/TLA_Tutorial/</id>
    <published>2021-08-01T03:54:03.000Z</published>
    <updated>2021-08-01T04:04:33.580Z</updated>
    
    <content type="html"><![CDATA[<p>形式化验证（Formal Verification）指一类使用数理逻辑方法来证明软件设计是正确的技术，据称是由 Edsger Dijkstra 于 1972 年最早提出，此方法一直是一种比较小众冷门的技术。形式化验证技术想要解决的核心问题是：软件总是可能存在 Bug 的，而测试始终无法涵盖所有可能性，特别是对于并发系统及分布式系统来说，就算单元测试达到了 100% 分支覆盖率，也不能肯定的说这个系统在线程安全，一致性等方面不会出问题。那如何更好的来验证我们的程序是否符合预期呢？形式化验证就旨在使用严谨的数学证明方法来证明某一算法是正确的。这样我们就可以拍着胸脯说，我的算法肯定是正确的，都证明过了:)</p><span id="more"></span><p>听上去是不是很牛逼啊，感觉我们马上就要能写出 bug free 的程序来了呢～然而理想很丰满，现实很骨感，实际问题远远不会是这么简单的，要是形式化验证真这么好用那它就不至于至今还这么小众了，事实上形式化验证存在着很多局限性与不 work 的时候的，这个后面再来细说。</p><p>关于形式化方法的实际应用及其强大之处可以进一步读读下面这篇布道文：</p><p><a target="_blank" rel="noopener" href="https://secbit.io/blog/2018/10/24/formal-verification-background/">Don’t Test, Verify —— 哪个故事真正符合你对形式化验证的想象？</a></p><p>当初也是因为偶然看了此文章知道了形式化验证这个东西，后面也陆续去深入了解学习了下，最近也用它解决了一些实际工作中的问题。本文就打算分享下入门学习的一些心得体会。</p><h2 id="TLA-amp-PlusCal-简介及一些基本概念"><a href="#TLA-amp-PlusCal-简介及一些基本概念" class="headerlink" title="TLA+ &amp; PlusCal 简介及一些基本概念"></a>TLA+ &amp; PlusCal 简介及一些基本概念</h2><p>进行形式化验证的具体工具有很多，目前实际软件开发中最为常用的是由 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Leslie_Lamport" title="Leslie Lamport">Leslie Lamport</a> 开发的 TLA+，这是一种用于形式化验证的语言，主要用于验证并行及分布式系统的正确性。</p><p>由于 TLA+ 写的代码并不是用来实际运行的，故一般将其代码称为模型（Model）而非程序（Program）。</p><p>TLA+ 是基于数理逻辑而非经典的软件开发思想设计出来的，故其代码与其他编程语言有着显著区别，其中的基本元素是集合，逻辑运算，映射等东西，来个例子感受下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Next == \/ \E b \in Ballots : Phase1a(b) \/ Phase2a(b)</span><br><span class="line">        \/ \E a \in Acceptors : Phase1b(a) \/ Phase2b(a) </span><br></pre></td></tr></table></figure><p>这段代码看上去完全不像在编程，实际上写 TLA+ 代码的确也不是在编程而是在用数理逻辑定义一些东西。</p><p>这学习曲线对于大部分码农来说实在是太过于陡峭了，Programer 并不是数学家，Lamport 大神也知道这一点，于是他又搞了个叫 PlusCal 的东西出来。PlusCal 是一种类似 C/Pascal 的高级语言，其目的同样不是为了生成机器代码来运行，而是依靠 TLA+ 解释器来生成对应的 TLA+ 模型代码。</p><p>来一段实际的 PlusCal 代码感受下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(* --algorithm EuclidAlg &#123;</span><br><span class="line">variables alice_account = 10, bob_account = 10, money = 5;</span><br><span class="line"></span><br><span class="line">A: alice_account := alice_account - money;</span><br><span class="line">B: bob_account := bob_account + money;</span><br><span class="line"></span><br><span class="line">&#125; *)</span><br></pre></td></tr></table></figure><p>这看上去就很像经典编程语言了，因此对于程序员来说，可以使用 PlusCal 来快速进行形式化验证。不过 PlusCal 毕竟是 TLA+ 的上层高级语言，其能实现的功能只是 TLA+ 的一个子集，不过一般来说此问题不大，这个子集对于简单应用来说足够用了。</p><p>有了代码后如何运行 TLA+ 或 PlusCal 模型呢，Lamport 为此开发了一个 IDE，即 <a target="_blank" rel="noopener" href="https://lamport.azurewebsites.net/tla/toolbox.html">TLA Toolbox</a>. 然而此 IDE UI 界面并不是很好用，更建议使用 VSCode 中的 <a target="_blank" rel="noopener" href="https://marketplace.visualstudio.com/items?itemName=alygin.vscode-tlaplus">TLA 插件</a> 来进行开发。</p><h2 id="入门学习路径及资料"><a href="#入门学习路径及资料" class="headerlink" title="入门学习路径及资料"></a>入门学习路径及资料</h2><p>入门学习建议从下面这个教程开始：</p><blockquote><p><a target="_blank" rel="noopener" href="https://learntla.com/">Learn TLA+</a></p></blockquote><p>此教程完全从实用角度出发，立足点是如何用 PlusCal 来解决日常编程中需要关注的并发，一致性等问题，因此十分简单易学，也比较短，看完后基本就能实际上手做些事情了。</p><p>在实际写 PlusCal 代码的时候需要参考下其语法手册，PlusCal 有两种语法风格，类似 Pascal 的 P-Syntax 及类似 C 语言的 C-Syntax，语法手册分别如下：</p><blockquote><p><a target="_blank" rel="noopener" href="https://lamport.azurewebsites.net/tla/c-manual.pdf">A PlusCal User’s Manual C-Syntax Version 1.8</a><br><a target="_blank" rel="noopener" href="https://lamport.azurewebsites.net/tla/p-manual.pdf">A PlusCal User’s Manual P-Syntax Version 1.8</a></p></blockquote><p>网上的例子中使用 P-Syntax 的居多，不过我个人更喜欢 C-Syntax 一些。</p><p>如果看完上述简单教程后还想进一步系统的学习一下，那建议从 Lamport 的 TLA+ 项目主页开始：</p><blockquote><p><a target="_blank" rel="noopener" href="https://lamport.azurewebsites.net/tla/tla.html">The TLA+ Home Page</a></p></blockquote><p>此外 Lamport 还有一本系统的讲形式化验证的书：</p><blockquote><p><a target="_blank" rel="noopener" href="http://lamport.azurewebsites.net/tla/book.html">Specifying Systems</a></p></blockquote><p>观千剑而后识器，看看其他人是如何写代码的对于入门来说也是很有用的，下面这两个 Github 项目中收集整理了很多 TLA+ 模型，如果想要提高水平可以仔细学习揣摩下：</p><blockquote><p><a target="_blank" rel="noopener" href="https://github.com/tlaplus/Examples">TLA+ Examples</a><br><a target="_blank" rel="noopener" href="https://github.com/tlaplus/DrTLAPlus">Dr. TLA+ Series</a></p></blockquote><h2 id="一些关键点及-TLA-的局限性"><a href="#一些关键点及-TLA-的局限性" class="headerlink" title="一些关键点及 TLA+ 的局限性"></a>一些关键点及 TLA+ 的局限性</h2><h3 id="定义什么是正确"><a href="#定义什么是正确" class="headerlink" title="定义什么是正确"></a>定义什么是正确</h3><p>形式化验证是用来验证算法是正确的，那什么叫“正确”呢？<strong>如何定义“正确”是形式化验证中最重要的问题之一</strong>。比较符合程序员习惯的方法是在 PlusCal 中加入 <code>assert</code> 来检查是否满足某些条件。不过更好的方法是使用不变量（Invariants）检查，如何正确的定义算法中需要检查的 Invariant 是十分重要的，如果检查条件的定义本身就是不完备的，那形式化验证的结果自然也是不完备的。</p><h3 id="合理定义原子操作"><a href="#合理定义原子操作" class="headerlink" title="合理定义原子操作"></a>合理定义原子操作</h3><p>PlusCal 中使用 Label 来定义原子操作，一个 Label 下若干条语句会被视为是一个原子操作，如果把本来不是原子操作的行为错误的定义为了原子操作，那最终得到的结果显然就会是不完备的。</p><p>如果把本来可以视为一个原子操作的行为定义为若干条原子操作，则会让验证的计算量大幅增加，导致验证所需时间变长。PlusCal 翻译成 TLA+ 后验证原理是穷举不同进程间执行时序的所有可能性，若原子操作或分支过多，会造成解空间的急剧膨胀。</p><h3 id="局限性"><a href="#局限性" class="headerlink" title="局限性"></a>局限性</h3><ol><li>TLA+ 并不是直接去验证算法的实现，而是验证算法实现抽象出来的 PlusCal 或 TLA+ 模型，这一步抽象的正确性只能由人工自行保证，没有任何方法可以证明二者是等价的。事实上二者绝大多数时候也是不等价的，比如程序中的数字都是会溢出的，而数学模型中的数字则不会。妄图对程序所有实现细节都去建模验证的尝试也是不可行的，因为这会导致验证的解空间变得极为巨大，基本上都是没有实际意义的。估计这也就是 Lamport 为什么不设计一个 C / Java 等语言直接翻译为 PlusCal 模型解释器的原因。</li><li>如前文所述，算法正确性的定义也是需要人工完成的，这一步某些时候也是比较困难的，精确的定义什么是正确的本身就很有挑战性。</li><li>需要人工建模也带来了软件开发过程中成倍的工作量增加，特别是在软件需要快速迭代开发时形式化验证方法基本是不可用的，因此实际上形式化验证手段一般也只用于一些变化很小，且开发周期很长的项目中。</li></ol>]]></content>
    
    
    <summary type="html">&lt;p&gt;形式化验证（Formal Verification）指一类使用数理逻辑方法来证明软件设计是正确的技术，据称是由 Edsger Dijkstra 于 1972 年最早提出，此方法一直是一种比较小众冷门的技术。形式化验证技术想要解决的核心问题是：软件总是可能存在 Bug 的，而测试始终无法涵盖所有可能性，特别是对于并发系统及分布式系统来说，就算单元测试达到了 100% 分支覆盖率，也不能肯定的说这个系统在线程安全，一致性等方面不会出问题。那如何更好的来验证我们的程序是否符合预期呢？形式化验证就旨在使用严谨的数学证明方法来证明某一算法是正确的。这样我们就可以拍着胸脯说，我的算法肯定是正确的，都证明过了:)&lt;/p&gt;</summary>
    
    
    
    <category term="软件之道" scheme="https://gaomf.cn/categories/%E8%BD%AF%E4%BB%B6%E4%B9%8B%E9%81%93/"/>
    
    
    <category term="Concurrent" scheme="https://gaomf.cn/tags/Concurrent/"/>
    
    <category term="TLA+" scheme="https://gaomf.cn/tags/TLA/"/>
    
  </entry>
  
  <entry>
    <title>如何学习一个新东西</title>
    <link href="https://gaomf.cn/2021/06/12/How_to_Learn_a_New_Thing/"/>
    <id>https://gaomf.cn/2021/06/12/How_to_Learn_a_New_Thing/</id>
    <published>2021-06-12T03:07:03.000Z</published>
    <updated>2021-06-12T03:46:44.311Z</updated>
    
    <content type="html"><![CDATA[<p>我们从小到大都在学习各种新东西，学的东西多了自然会对“如何学新东西”这一问题本身有一些方法论层面的思考，本文就来分享总结下自己的一些经验。</p><p>对于学习各种<strong>人为创造</strong>的东西基本都可以按相同的方法进行，不过对于学习自然科学的概念方法会有所不同，本文就不去讨论了。</p><p>学习一个新东西基本可以分为三个阶段：初步理解，即会用；深入理解，即懂原理；融会贯通。</p><span id="more"></span><h2 id="初步理解"><a href="#初步理解" class="headerlink" title="初步理解"></a>初步理解</h2><p>这一阶段的目的是学会如何使用这个新东西，即学习如何用轮子的阶段，对于只需要应用的情况来说达到这一阶段就够了。此阶段的核心就是搞清楚三个问题：是什么（What），为什么（Why），怎么用（How），这十分类似于 3W 法则，因为这本来就是人类自然思维过程的抽象总结。</p><h3 id="是什么"><a href="#是什么" class="headerlink" title="是什么"></a>是什么</h3><p>最基本的第一步，搞清楚这是一个什么东西。这一步说简单也简单，说复杂也复杂。简单在于只要随便看看介绍就会对这是什么有个初步感觉了；复杂在于要想给一个东西下一个精确的定义来描述它是什么会是极为复杂的。</p><p>要理解一个东西是什么往往伴随着理解它不是什么同步进行。</p><p>在学习新东西时一开始只需要对它是什么有个基本认识就好了，后续随着学习过程的深入自然会对此问题有越来越深入精确的认识。</p><h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>搞清楚为什么要创造出这么一个东西？这个东西的作用是什么？它可以用来解决什么问题？</p><p>对于某些东西来说要搞清楚此问题并不简单，特别是一些源于数学的抽象概念和方法。</p><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><p>学会如何用这个东西。一些基础小东西会相对较为单纯，其使用方法也自然很简单。然而很多时候一个东西会提供若干不同功能来满足不同需求与解决不同问题，各功能都会有自己不同的使用方法。且达到同样目的也可以选择不同优劣有异的功能组合。</p><p>一般而言一个东西的复杂度很大程度上取决于其提供功能的多样性。相对比较简单纯粹的东西就只有会用和不会用两种状态，而更多复杂的东西则存在连续的中间状态。</p><p>这一步通常会是一个逐步深化、逐步探索的过程，开始只会用其最基本的功能，随着使用的深入会发掘出越来越多的使用方法及功能来。</p><h2 id="深入理解"><a href="#深入理解" class="headerlink" title="深入理解"></a>深入理解</h2><p>即学习其内部实现原理，这一阶段也就是学习如何造轮子的阶段，由浅到深可以继续分为三步：</p><ol><li>理解这个东西是如何设计及实现出来的，它是如何工作的？</li><li>理解为什么这样做是正确及可行的？</li><li>理解为什么要这样设计，不这样做还可以怎么做？</li></ol><p>一般而言，一个相对较复杂的技术及概念都是基于一系列更基础的技术及概念组合而成的，要充分理解其实现原理就要先理解其用到的各种底层技术或概念。</p><p>实现原理与此东西的功能及使用方法是密切相关的，内部实现是为了支撑其外部功能，在不知道其功能与使用方法时是很难理解其实现原理的。</p><p>在这一点上是很容易走弯路的，就像大学的很多课程为什么会感觉无用和难学就是因为这些课程的设计不是从应用出发自顶向下而是从原理出发自底向上的。根据我个人的经验，自底向上的学习方式并不是完全不可行，然而学习过程会很痛苦和迷茫，往往也会事倍功半。从应用出发自顶向下的学习路线相对会自然很多，先会用，再去研究它是怎么工作的，这更加的符合人类认识事物的规律。</p><p>当然也不是说非要精通其使用方法后再去研究其实现原理，二者其实是一个相辅相成相互促进的关系，会用了再去研究其内部实现会自然很多；理解了其内部实现后会有助于更好的去应用。</p><h2 id="融会贯通"><a href="#融会贯通" class="headerlink" title="融会贯通"></a>融会贯通</h2><p>这一阶段主要是在一个更大的框架下来思考理解这个东西，以达到融会贯通的目的。可以从两个维度来入手。</p><h3 id="同类比较"><a href="#同类比较" class="headerlink" title="同类比较"></a>同类比较</h3><p>一般来说解决一个问题的方法都不止一个，因此可以进一步深入思考下这些问题：</p><ul><li>为了实现同样的目的及作用，还有什么其他方法？</li><li>这些方法间有什么优劣？什么时候改选择什么方法？</li><li>造成它们各自优劣的原因是什么？实现原理又有何共同点及区别？</li></ul><h3 id="发展脉络"><a href="#发展脉络" class="headerlink" title="发展脉络"></a>发展脉络</h3><p>人类发展至今基本所有东西都是渐进式发展的，没有太多东西是全新发展出来的，因此可以从时间的维度上来进行下思考：</p><ul><li>为了达到同样的目的，历史上有过什么其他的方法？</li><li>它们是如何一步步演化到当前这个样子的？</li><li>未来又会向什么方向演化？</li></ul>]]></content>
    
    
    <summary type="html">&lt;p&gt;我们从小到大都在学习各种新东西，学的东西多了自然会对“如何学新东西”这一问题本身有一些方法论层面的思考，本文就来分享总结下自己的一些经验。&lt;/p&gt;
&lt;p&gt;对于学习各种&lt;strong&gt;人为创造&lt;/strong&gt;的东西基本都可以按相同的方法进行，不过对于学习自然科学的概念方法会有所不同，本文就不去讨论了。&lt;/p&gt;
&lt;p&gt;学习一个新东西基本可以分为三个阶段：初步理解，即会用；深入理解，即懂原理；融会贯通。&lt;/p&gt;</summary>
    
    
    
    <category term="人生之思" scheme="https://gaomf.cn/categories/%E4%BA%BA%E7%94%9F%E4%B9%8B%E6%80%9D/"/>
    
    
    <category term="Methodology" scheme="https://gaomf.cn/tags/Methodology/"/>
    
  </entry>
  
  <entry>
    <title>Chia 技术架构简述</title>
    <link href="https://gaomf.cn/2021/05/16/Chia_Architecture_Brief/"/>
    <id>https://gaomf.cn/2021/05/16/Chia_Architecture_Brief/</id>
    <published>2021-05-16T09:33:00.000Z</published>
    <updated>2022-04-08T12:27:13.888Z</updated>
    
    <content type="html"><![CDATA[<p>Chia（起亚） 是最近极为火热的数字货币项目，对应的货币叫做 Chia Coin，简称 XCH。其核心算法为 PoST（Proof of Space and Time），以替代比特币中的 PoW（Proof of Work）。</p><p>使用 PoSpace 空间证明而非 PoW 工作量证明是 Chia 项目宣称的最大优点。据他们的开发者宣称，PoW 耗费太多能源了，不环保，我们来搞点更环保的东西吧，不用 PoW 了，改用 PoSpace，即谁有的硬盘空间多谁的投票权就更大。因此他们还把通常称为白皮书（White Paper）的文档改名叫做绿皮书（Green Paper）。</p><p>然而仔细想想这哪里环保了，把一堆硬盘搞来塞满毫无意义的数据比比特币矿机还要更邪恶吧……Chia 的官网上还可笑的宣称硬盘更不容易被垄断，因此个人还有小玩家可以更好的入场，简直是更荒谬的说法，哪个个人会去囤积一堆存不了有用数据的硬盘？</p><p>IPFS 好歹还可以存一些实际有用的数据，看起来还真能促进下社会发展，至于 Chia 简直是除了圈钱和泡沫看不到任何其他意义。不过抛开实际意义，由于最近也研究了下 Chia 的文档和代码，就单纯的来和大家分享下 Chia 的技术实现吧。</p><span id="more"></span><h2 id="软件架构"><a href="#软件架构" class="headerlink" title="软件架构"></a>软件架构</h2><p>Chia 的整体架构图如下：</p><p><img src="https://img.gaomf.cn/chia-network-architecture.png?x600"></p><p>整个系统中主要有 3 种类型的参与者：</p><ul><li>Farmer，农民</li><li>TimeLord，时间领主</li><li>Full Node，全能节点（中文翻译不确定）</li></ul><h3 id="Farmer"><a href="#Farmer" class="headerlink" title="Farmer"></a>Farmer</h3><p>绝大部分参与者都是农民 Farmer，如何成为农民也很简单，直接去下载个打包好的客户端运行就好了。</p><p>至于为什么叫 Farmer 呢？当然是为了凸显 Chia 的<em>绿色环保</em>喽，我们不是在浪费能源的挖矿，我们是在<em>环保</em>的种田！</p><p>Farmer 的工作也很简单，基本就是两步：</p><ol><li>Plotting，播种</li><li>Farming，摸奖</li></ol><p>Farmer 生成的 Plots file（P 盘文件） 可能会分布在很多台机器上，因此需要在这些机器上都部署上用来支持摸奖的服务，这个服务就被称为 Harvester 收割机。Farmer 接收到来自 TimeLord 的 Challenge（质询） 后，会将此 Challenge 转发到所连接的所有 Harvester 上。</p><h4 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h4><p>Plotting 的目的是在磁盘上生成一大堆 Plots file，根据其实现代码，这一过程可分为 4 步：</p><ol><li> Phase 1, forward propagation. 计算出所需的 7 张表及 f 函数集合，这一步实际上就已经生成了 PoSpace 所需的所有数据了，只是生成的临时文件还太大，需要后续来压缩下。f 函数的计算过程中会用到 Plot ID，Plot ID 直接决定了 Plots file 的内容；</li><li> Phase 2, backprogagation. 主要目的在于消除表中的无意义项（Dead entries），以减少磁盘空间占用；</li><li> Phase 3, compresses. 进一步压缩生成的临时文件 1，生成临时文件 2，临时文件 2 其实就是最终的 Plots file 了；这一步做了重排序，会使得生成的表中各项的顺序发生变化，不是按 PoSpace 要求的某种顺序。</li><li> Phase 4, write checkpoint table. 写入检查点表，其意义在于加快查找表的过程。</li></ol><p>最后，若最终路径（<code>--final_dir</code>）与临时文件 2 的路径（<code>--tmp2_dir</code>）是一样的，简单的把临时文件 2 做个 Rename 重命名即可；否则做一次数据拷贝生成最终 Plots file。</p><p>此处之所以要 Copy 或 Rename 一下而不是直接把临时文件 2 作为最终文件的主要原因是为了分离临时文件及最终文件的存储位置。</p><p>根据 Chia 的设计，Plots file 越多越好，因此显然要把它们存放在廉价的大容量存储系统，如本地机械盘或云端的低价存储中。然而此类系统通常随机读写能力不佳，甚至是直接不支持随机写入。可在生成临时文件 2 时是需要随机写入的，且写入的 IOPS 对生成文件的速度有显著影响，因此在通常实践中，会把临时文件写到 SSD 上。</p><p>Plotting 的逻辑是由 <code>DiskPlotter</code> 这个类来实现的。</p><h4 id="Farming"><a href="#Farming" class="headerlink" title="Farming"></a>Farming</h4><p>Farming 的过程就是对一系列 Challenges 的证明响应，每一轮证明过程都是以一个 256 bit 的 Challenge 为输入，输出是一个 PoSpace 结构，其中包括 Plots file 的公钥，Pool 的公钥， Proof 结果等。其中最重要的就是 Proof 结果。</p><p>生成一个区块的过程中会产生 64 次 Challenges，这一过程在客户端 Farming 的界面中可以看到：</p><p><img src="https://img.gaomf.cn/20210510-170238%402x.png?x600"></p><p>每一个这样的点被称为一个 Signage Point。</p><p>为减少 IO 次数及所需网络带宽，目前的实现中采用了一种类似于预筛选的方法，先用较少次数的读计算出一个 Quality 值，并根据特定算法评估此 Quality 对于当前 Signage Point 来说够不够好，如果够好的话再去获取完整 Proof 结果。获取 Proof &amp; Quality 的过程是由 Harvester 完成的，评估 Quality 质量则是 Farmer 的工作。</p><h4 id="Harvester"><a href="#Harvester" class="headerlink" title="Harvester"></a>Harvester</h4><p>Harvester 负责管理某台机器上的所有 Plots file，并接收来自 Farmer 的 Challenge，返回每个 Plots file 的 PoSpace 及 PoSpace Quality。</p><p>这部分代码是由 <code>DiskProver</code> 类实现的。</p><p>Challenge 的高 $k$ bit 表示 f7 要满足的一些性质，通过对 C1, C2, C3 表的一通查询最终可以确定 Table 7 中有几项满足要求，可能有若干项满足要求，也可能一项都没有，平均期望是存在 1 项满足要求。</p><p>这里有几项满足要求就意味着这个 Plots file 中存在多少个最终的 Proof 证明结果。</p><p>之后的查找过程示意如下：</p><p><img src="https://img.gaomf.cn/chia_plots_file_table.png"></p><p>不过要注意的是，从 Table 7 中的一项表项只能找到 Table 6 中对应的<strong>一项</strong>，这样依次找下去就可以得到 Table 1 中的 32 项，每项是由 2 个 $k$ bit 的整数构成的，因此最终结果就有 $k*64$ bit。对这 64 个数进行重新排序（排序规则是由 PoST 算法决定的），最终就可以生成一个长长的字符串，这就是 PoSpace 的证明结果。</p><p>至于 Quality 是怎么来的呢？Challenge 最低 5 bit 的含义是 Table 6 ～ Table 2 在生成 Quality 时应该选择左边的值还是右边的值，按此规则进行选取后 Table 7 中的一项就会对应得到 Table 1 中的一项，即 2 个整数。将 Challenge 与这两个整数简单的二进制连起来，并计算 SHA-256，得到的结果就是 Quality 值。</p><h3 id="Timelord"><a href="#Timelord" class="headerlink" title="Timelord"></a>Timelord</h3><p>Timelord 一般被翻译为时间领主，它负责向 Farmer 发起质询（Challenge）并计算 VDF，计算完成后打包成新的区块，实际上整个 Chia 链中的区块都是由 TimeLord 计算生成的。TimeLord 最终决定了哪个 Farmer 的某个 Plots file 赢得了当前区块，即摸中奖了可以获得 XCH 奖励。</p><p>那如何保证 TimeLord 是公平的而不是邪恶的始终选取自己的 plots file 呢？这就是由 Chia 的 PoST 算法决定的了。离 Challenge 越近（越优）的 PoSpace 会使得 TimeLord 计算 VDF 的速度越快。系统中不止有一个 TimeLord，而是有很多 TimeLord 在互相竞争，哪个 TimeLoad 先计算完成 VDF 成功打包区块，那整个链就会沿此区块继续延伸，其他在计算同一高度区块的 TimeLord 就会失败。</p><p>此过程与传统 Bitcoin 的运行模式基本一模一样，可以猜想，对于分支情况的处理也应该和比特币基本相同。然而一个显著区别是，Bitcoin 奖励的是矿工，即最终成功生成新区块的参与者，而在 Chia 中，TimeLord 是没有任何奖励的，完全是自愿劳动:) 被奖励的是 Farmer。</p><p>那无偿劳动为啥有人来干呢？根据某个 Chia 核心开发人员的说法是，当 TimeLord 好处多多，大家都会争着来干的，最显著的好处是，自己部署一个 TimeLord 与自己的 Harvester 离得近网络延迟小，避免自己由于网络延迟太大而成为炮灰。即由于网络延迟导致自己的 PoSpace 很久之后才被送到某个遥远的 TimeLord 上，导致根本没有机会被打包到区块中，即使自己的 PoSpace 比其他人更优。</p><p>TimeLord 是 CPU 密集型任务，目前的开源实现强制要求运行平台支持 AVX512-IFMA 指令集。如果某个 TimeLord 的运行速度能压倒性的快于其他 TimeLord，那它理论上是可以凭借算力而非磁盘空间来控制整个链的，因此按照 Chia 开发者的说法，要把运行得最快的 TimeLord 算法开源出来，而且使得 ASIC 的运算速度没法超过通用 CPU，这样才能避免邪恶 TimeLord 的出现。</p><h3 id="Full-Node"><a href="#Full-Node" class="headerlink" title="Full Node"></a>Full Node</h3><p>Full Node 的作用是广播中转各种消息，创建区块，保存和维护历史区块，与系统的其他参与者通信等。不同参与者之间的通信就是靠 Full Node 来完成的。</p><p>Full Node 间的一致性使用的是与比特币一样的 Gossip 协议。</p><h2 id="一些重要算法"><a href="#一些重要算法" class="headerlink" title="一些重要算法"></a>一些重要算法</h2><p>算法部分没有仔细研究，此处更多的是给出一些深入研究的链接。</p><h3 id="PoST-算法"><a href="#PoST-算法" class="headerlink" title="PoST 算法"></a>PoST 算法</h3><p>Chia 最重要的算法当然要数 PoST 算法了，PoST 算法是由两部分构成的，PoSpace + VDF。</p><p><a target="_blank" rel="noopener" href="https://www.chia.net/assets/Chia_Proof_of_Space_Construction_v1.1.pdf">PoSpace 的文档</a></p><p><a target="_blank" rel="noopener" href="https://eprint.iacr.org/2018/712.pdf">VDF 的文档</a></p><p>为什么只有 PoSpace 是不够的还需要 VDF 呢？因为整个区块链网络是个 P2P 网络，产生一个 Challenge 后需要去收集所有 Farmer 的 Proof，区块链设计的核心哲学就是没有邪恶的中心节点，那怎么确定哪个 Proof 是最优的呢？如果这个判断进行得很快，比如简单的比比差值，那所有的 TimeLoad 都可以马上宣称某个 Proof 为最优，此时区块如何增长就完全不可控了，所以 PoT 也是必不可少的。需要通过计算 VDF 的过程让全网能够就哪个 Proof 是最优的达成共识。</p><h3 id="一致性协议"><a href="#一致性协议" class="headerlink" title="一致性协议"></a>一致性协议</h3><p>一致性协议中主要介绍的是链的延伸过程，在 Chia 的绿皮书中对此有说明，不过目前有一份更新的 Google Doc:</p><p><a target="_blank" rel="noopener" href="https://docs.google.com/document/d/1tmRIb7lgi4QfKkNaxuKOBHRmwbVlGL4f7EsBDr_5xZE/edit">Chia Consensus Algorithm</a></p><h3 id="签名算法"><a href="#签名算法" class="headerlink" title="签名算法"></a>签名算法</h3><p>所有区块链技术的最底层基石都是密码学，特别是各种数字签名技术。Chia 中签名用的算法是 BLS12-381。</p><p>BLS 算法是 2003 年由斯坦福大学的 Dan <strong>B</strong>oneh，Ben <strong>L</strong>ynn 以及 Hovav <strong>S</strong>hacham 提出的一种基于 ECC 的数字签名算法，和 ECDSA 的用处是一样的。该方案是一个基于双线性映射且具有唯一确定性的签名方案。BLS的主要思想是待签名的消息散列到一个椭圆曲线上的一个点，并利用双线性映射 e 函数的交换性质，在不泄露私钥的情况下，验证签名。BLS的算法在签名合并，多签，m/n 多签有丰富的应用。</p><p>而 BLS12-381 则一种具体的 BLS 签名算法，此算法由 Sean Bowe 于 2017 年提出，最早被用于一个叫 Zcash 的数字货币项目中，现在不少其他区块链项目也用了此算法。</p><p>在 Chia 的实现中需要用到不止一对密钥，比如钱包的密钥，Farmer 用的农民密钥等。这些密钥不是独立的，而是由一个主私钥通过私钥派生算法得到的，对于 BLS12-381 算法来说怎么生成这些密钥可以参考这个：</p><p><a target="_blank" rel="noopener" href="https://eips.ethereum.org/EIPS/eip-2333">EIP-2333: BLS12-381 Key Generation</a></p><p>至于主私钥怎么来的呢，第一次启动 Chia 客户端时会创建一个由 24 个单词组成的助记词，这些助记词就是用来生成主私钥的。</p><p>Plotting 时会生成一个随机主私钥，通过它可以派生出一个本地私钥，这个本地私钥又可以导出一个本地公钥，最终，本地公钥与农民公钥（Farmer Public Key）融合，生成了绘图公钥（Plot Public Key），最后矿池公钥（Pool Public Key）和绘图公钥（Plot Public Key）会被组合到一起，并进行一次哈希，哈希的结果被称为绘图 ID（Plot ID）。</p><p>上述提及的绘图 ID，随机主私钥，农民公钥与矿池公钥均会被记录到 Plots file 的 Header 中。</p><p>生成区块时，需要用与 Plot file 匹配的矿池私钥（Pool Private Key）进行一次签名。</p><h2 id="开源项目代码结构"><a href="#开源项目代码结构" class="headerlink" title="开源项目代码结构"></a>开源项目代码结构</h2><p>Chia 的业务逻辑，网络，一致性算法等是用 Python 写的，即 <a target="_blank" rel="noopener" href="https://github.com/Chia-Network/chia-blockchain">chia-blockchain</a> 这个项目。这个项目也被视为 Chia 的主项目在 GitHub 上获得了最多的 Star。最终各平台上能运行的完整的程序也是在这个项目中发布 Release 版本的。</p><p>至于 GUI 部分是基于 Electron 开发的，对应项目为 <a target="_blank" rel="noopener" href="https://github.com/Chia-Network/chia-blockchain-gui">chia-blockchain-gui</a>。</p><p>核心的 PoST 算法则是 C++ 写的，分为两个项目：</p><ul><li><a target="_blank" rel="noopener" href="https://github.com/Chia-Network/chiapos">chiapos</a>，PoSpace 相关代码，包括 Plots file 的生成及验证；</li><li><a target="_blank" rel="noopener" href="https://github.com/Chia-Network/chiavdf">chiavdf</a>，TimeLord 上运行的 VDF 算法。</li></ul><p>Chia 中使用的 BLS12-381 数字签名算法的实现为：<a target="_blank" rel="noopener" href="https://github.com/Chia-Network/bls-signatures">bls-signatures</a></p><p>此外 Chia 还开发了一个叫 Chialisp 的智能合约语言，相关项目有：</p><ul><li><a target="_blank" rel="noopener" href="https://github.com/Chia-Network/clvm">clvm</a>，用 Python 写的 Chialisp 虚拟机；</li><li><a target="_blank" rel="noopener" href="https://github.com/Chia-Network/clvm_rs">clvm-rs</a>，用 Rust 写的 Chialisp 虚拟机；</li><li><a target="_blank" rel="noopener" href="https://github.com/Chia-Network/clvm_tools">clvm_tools</a>，一些支持工具。</li></ul><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://dgideas.net/2021/hard-drive-crisis-the-principles-and-technical-details-behind-chia-mining-i/">硬盘危机——Chia 挖矿背后的原理与技术细节（一）</a></p><p><a target="_blank" rel="noopener" href="https://www.chia.net/assets/ChiaGreenPaper.pdf">Chia Green Paper</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/366400067">Chia挖矿：深入浅出聊P盘（绘图 Plots）</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;Chia（起亚） 是最近极为火热的数字货币项目，对应的货币叫做 Chia Coin，简称 XCH。其核心算法为 PoST（Proof of Space and Time），以替代比特币中的 PoW（Proof of Work）。&lt;/p&gt;
&lt;p&gt;使用 PoSpace 空间证明而非 PoW 工作量证明是 Chia 项目宣称的最大优点。据他们的开发者宣称，PoW 耗费太多能源了，不环保，我们来搞点更环保的东西吧，不用 PoW 了，改用 PoSpace，即谁有的硬盘空间多谁的投票权就更大。因此他们还把通常称为白皮书（White Paper）的文档改名叫做绿皮书（Green Paper）。&lt;/p&gt;
&lt;p&gt;然而仔细想想这哪里环保了，把一堆硬盘搞来塞满毫无意义的数据比比特币矿机还要更邪恶吧……Chia 的官网上还可笑的宣称硬盘更不容易被垄断，因此个人还有小玩家可以更好的入场，简直是更荒谬的说法，哪个个人会去囤积一堆存不了有用数据的硬盘？&lt;/p&gt;
&lt;p&gt;IPFS 好歹还可以存一些实际有用的数据，看起来还真能促进下社会发展，至于 Chia 简直是除了圈钱和泡沫看不到任何其他意义。不过抛开实际意义，由于最近也研究了下 Chia 的文档和代码，就单纯的来和大家分享下 Chia 的技术实现吧。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="Blockchain" scheme="https://gaomf.cn/tags/Blockchain/"/>
    
    <category term="P2P" scheme="https://gaomf.cn/tags/P2P/"/>
    
    <category term="Cryptography" scheme="https://gaomf.cn/tags/Cryptography/"/>
    
    <category term="Consensus" scheme="https://gaomf.cn/tags/Consensus/"/>
    
    <category term="Storage" scheme="https://gaomf.cn/tags/Storage/"/>
    
  </entry>
  
  <entry>
    <title>C++ 中的 volatile，atomic 及 memory barrier</title>
    <link href="https://gaomf.cn/2020/09/11/Cpp_Volatile_Atomic_Memory_barrier/"/>
    <id>https://gaomf.cn/2020/09/11/Cpp_Volatile_Atomic_Memory_barrier/</id>
    <published>2020-09-11T08:46:28.000Z</published>
    <updated>2021-06-11T13:45:29.549Z</updated>
    
    <content type="html"><![CDATA[<p>C++ 中的 <code>volatile</code> 关键字，<code>std::atomic</code> 变量及手动插入内存屏障指令（Memory Barrier）均是为了避免内存访问过程中出现一些不符合预期的行为。这三者的作用有些相似之处，不过显然它们并不相同，本文就将对这三者的应用场景做一总结。</p><span id="more"></span><p>这三者应用场景的区别可以用一张表来概括：</p><table><thead><tr><th></th><th><code>volatile</code></th><th>Memory Barrier</th><th><code>atomic</code></th></tr></thead><tbody><tr><td>抑制编译器重排</td><td>Yes</td><td>Yes</td><td>Yes</td></tr><tr><td>抑制编译器优化</td><td>Yes</td><td>No</td><td>Yes</td></tr><tr><td>抑制 CPU 乱序</td><td>No</td><td>Yes</td><td>Yes</td></tr><tr><td>保证访问原子性</td><td>No</td><td>No</td><td>Yes</td></tr></tbody></table><p>下面来具体看一下每一条。</p><h3 id="抑制编译器重排"><a href="#抑制编译器重排" class="headerlink" title="抑制编译器重排"></a>抑制编译器重排</h3><p>所谓编译器重排，这里是指编译器在生成目标代码的过程中交换没有依赖关系的内存访问顺序的行为。</p><p>比如以下代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">*p_a = a;</span><br><span class="line">b = *p_b;</span><br></pre></td></tr></table></figure><p>编译器<strong>不保证</strong>在最终生成的汇编代码中对 <code>p_a</code> 内存的写入在对 <code>p_b</code> 内存的读取之前。</p><p>如果这个顺序是有意义的，就需要用一些手段来保证编译器不会进行错误的优化。具体来说可以通过以下三种方式来实现：</p><ul><li>把对应的变量声明为 <code>volatile</code> 的，C++ 标准保证对 <code>volatile</code> 变量间的访问编译器不会进行重排，不过仅仅是  <code>volatile</code> 变量之间， <code>volatile</code> 变量和其他变量间还是有可能会重排的；</li><li>在需要的地方手动添加合适的 Memory Barrier 指令，Memory Barrier 指令的语义保证了编译器不会进行错误的重排操作；</li><li>把对应变量声明为 <code>atomic</code> 的， 与 <code>volatile</code> 类似，C++ 标准也保证 <code>atomic</code> 变量间的访问编译器不会进行重排。不过 C++ 中不存在所谓的 “atomic pointer” 这种东西，如果需要对某个确定的地址进行 atomic 操作，需要靠一些技巧性的手段来实现，比如在那个地址上进行 placement new 操作强制生成一个 <code>atomic</code> 等；</li></ul><h3 id="抑制编译器优化"><a href="#抑制编译器优化" class="headerlink" title="抑制编译器优化"></a>抑制编译器优化</h3><p>此处的编译器优化特指编译器不生成其认为无意义的内存访问代码的优化行为，比如如下代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> a = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; ++i) &#123;</span><br><span class="line">    a += i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在较高优化级别下对变量 <code>a</code> 的内存访问基本都会被优化掉，<code>f()</code> 生成的汇编代码和一个空函数基本差不多。然而如果对 <code>a</code> 循环若干次的内存访问是有意义的，则需要做一些修改来抑制编译器的此优化行为。可以把对应变量声明为 <code>volatile</code> 或 <code>atomic</code> 的来实现此目的，C++ 标准保证对 <code>volatile</code> 或 <code>atomic</code> 内存的访问肯定会发生，不会被优化掉。</p><p>不过需要注意的是，这时候手动添加内存屏障指令是没有意义的，在上述代码的 <code>for</code> 循环中加入 <code>mfence</code> 指令后，仅仅是让循环没有被优化掉，然而每次循环中对变量 <code>a</code> 的赋值依然会被优化掉，结果就是连续执行了 1000 次 <code>mfence</code>。</p><h3 id="抑制-CPU-乱序"><a href="#抑制-CPU-乱序" class="headerlink" title="抑制 CPU 乱序"></a>抑制 CPU 乱序</h3><p>上面说到了编译器重排，那没有了编译器重排内存访问就会严格按照我们代码中的顺序执行了么？非也！现代 CPU 中的诸多特性均会影响这一行为。对于不同架构的 CPU 来说，其保证的内存存储模型是不一样的，比如 x86_64 就是所谓的 TSO（完全存储定序）模型，而很多 ARM 则是 RMO（宽松存储模型）。再加上多核间 Cache 一致性问题，多线程编程时会面临更多的挑战。</p><p>为了解决这些问题，从根本上来说只有通过插入所谓的 Memory Barrier 内存屏障指令来解决，这些指令会使得 CPU 保证特定的内存访问序及内存写入操作在多核间的可见性。然而由于不同处理器架构间的内存模型和具体 Memory Barrier 指令均不相同，需要在什么位置添加哪条指令并不具有通用性，因此 C++ 11 在此基础上做了一层抽象，引入了 <code>atomic</code> 类型及 Memory Order 的概念，有助于写出更通用的代码。从本质上看就是靠编译器来根据代码中指定的高层次 Memory Order 来自动选择是否需要插入特定处理器架构上低层次的内存屏障指令。</p><p>关于 Memory Order，内存模型，内存屏障等东西的原理和具体使用方法网上已经有很多写得不错的文章了，可以参考文末的几篇参考资料。</p><h3 id="保证访问原子性"><a href="#保证访问原子性" class="headerlink" title="保证访问原子性"></a>保证访问原子性</h3><p>所谓访问原子性就是 Read，Write 操作是否存在中间状态，具体如何实现原子性的访问与处理器指令集有很大关系，如果处理器本身就支持某些原子操作指令，如 Atomic Store， Atomic Load，Atomic Fetch Add，Atomic Compare And Swap（CAS）等，那只需要在代码生成时选择合适的指令即可，否则需要依赖锁来实现。C++ 中提供的可移植通用方法就是 <code>std::atomic</code>，<code>volatile</code> 及 Memory Barrier 均与此完全无关。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>从上面的比较中可以看出，<code>volatile</code>，<code>atomic</code> 及 Memory Barrier 的适用范围还是比较好区分的。</p><ul><li>如果需要原子性的访问支持，只能选择 <code>atomic</code>；</li><li>如果仅仅只是需要保证内存访问不会被编译器优化掉，优先考虑 <code>volatile</code>；</li><li>如果需要保证 Memory Order，也优先考虑 <code>atomic</code>，只有当不需要保证原子性，而且很明确要在哪插入内存屏障时才考虑手动插入 Memory Barrier。</li></ul><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/ishen/p/13200838.html">内存模型与c++中的memory order</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/43526907">volatile与内存屏障总结</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/41872203">X86/GCC memory fence的一些见解</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;C++ 中的 &lt;code&gt;volatile&lt;/code&gt; 关键字，&lt;code&gt;std::atomic&lt;/code&gt; 变量及手动插入内存屏障指令（Memory Barrier）均是为了避免内存访问过程中出现一些不符合预期的行为。这三者的作用有些相似之处，不过显然它们并不相同，本文就将对这三者的应用场景做一总结。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="ARM" scheme="https://gaomf.cn/tags/ARM/"/>
    
    <category term="Concurrent" scheme="https://gaomf.cn/tags/Concurrent/"/>
    
    <category term="C++" scheme="https://gaomf.cn/tags/C/"/>
    
    <category term="Compiler" scheme="https://gaomf.cn/tags/Compiler/"/>
    
    <category term="x86" scheme="https://gaomf.cn/tags/x86/"/>
    
  </entry>
  
  <entry>
    <title>动态库全局符号覆盖的大坑</title>
    <link href="https://gaomf.cn/2020/06/03/shared_library_global_symbol_override/"/>
    <id>https://gaomf.cn/2020/06/03/shared_library_global_symbol_override/</id>
    <published>2020-06-03T13:14:18.000Z</published>
    <updated>2021-06-11T13:45:29.578Z</updated>
    
    <content type="html"><![CDATA[<p>今天在调试时发现了一个奇怪的core：<code>double free or corruption (fasttop)</code>，从堆栈看是由于 <code>_dl_fini</code> 函数多次重复释放了某些 STL 容器导致的，此时就算在 <code>main</code> 函数中只保留个简单 <code>return 0</code> 也会出错，因此猜想肯定和某些全局变量有关。后面经过各种修改尝试，终于发现这是由于引用的 <code>.so</code> 动态库和主程序中定义了同名的全局 STL 容器导致的，此时的行为简直就是一个神坑，很有必要记录一下……</p><span id="more"></span><p>先说最终结论吧：</p><ul><li>多个动态库或者是动态库与主程序间可以有同名全局符号，包括全局变量和函数等，此时链接过程是不会出错的。</li><li>这些同名全局符号的地址是<strong>相同的</strong>！</li><li>链接过程中会从前往后依次查找符号，对于 <code>.so</code> 及 <code>.a</code> 来说，如果遇到相同的全局变量是不会报错的，此时 GCC 会默默的选择第一个，这种情况连 Warning 都不会有。这与多个 <code>.o</code> 是不同的，在多个 <code>.o</code> 中定义相同的全局变量无法正常链接。</li><li>以上行为的问题在于，绝大部分情况下各模块期望的行为都是调用自己的全局变量及函数，而不是调用其他模块的，因此大概率会造成运行时的各种异常。</li><li>尤有甚者，若全局变量并不是基本类型而是 <code>class</code>，那虽然此变量只有一个内存地址，然而<strong>其构造与析构函数会被调用多次</strong>，若其中有动态分配的内存，多次 <code>delete</code> 就会导致 <code>double free</code> 异常。</li><li>以上构造与析构行为是通过编译时向 <code>_init()</code> 及 <code>_fini()</code> 中添加 hook 函数实现的，构造顺序是链接顺序，析构顺序是其逆序。前文提到的 <code>_dl_fini()</code> 函数应该是 <code>_fini()</code> 的动态库版本。</li></ul><p>上面这些行为看上去已经很坑了吧，然而这并不是全部……以上行为仅适用于编译时直接指定需要链接库的情况，若是在程序运行过程中使用 <code>dlopen</code> 动态加载 <code>.so</code> 时行为不太一样；若通过 <code>LD_PRELOAD</code> 指定动态库那行为又不一样了……</p><p>使用 <code>dlopen</code> 加载时的行为可以简要归纳如下：</p><ul><li>主程序中的全局符号是<strong>永远都不会</strong>被加载进来的动态库给覆盖的，无论是变量还是函数。这与很多文章中说的不太一样，然而实际使用 GCC 9.3 测试的结果就是如此，估计是较新的 GCC 版本做了什么修改导致的。</li><li>多次调用 <code>dlopen</code> 加载多个动态库，若这些动态库间存在相同的全局符号，则它们之间是<strong>有可能</strong>相互覆盖的，这取决于 <code>dlopen</code> 的 <code>flag</code>。若使用 <code>RTLD_GLOBAL</code>，则后面加载进来的动态库会使用已有的全局符号；若使用 <code>RTLD_LOCAL</code>，则每个动态库间的符号是独立的。</li><li>上述行为中，对应全局变量的构造及析构每次都会进行，也就是后面加载进来的动态库会在之前内存的基础上再来构造一次，退出的时候也会析构多次。</li></ul><p>以上很多行为显然应该都不是预期行为的，那如何解决这些问题呢，大概有这些方法：</p><ul><li>创建 <code>.so</code> 时加上编译选项 <code>-Wl,-Bsymbolic</code>，这会强制采用本地的全局变量定义。</li><li>可以通过 <code>__attribute__ ((visibility(&quot;xxx&quot;)))</code> 来控制符号可见性，并通过编译选项 <code>-fvisibility=xxx</code> 来控制默认符号可见性。</li><li>将不需要导出的全局变量声明为 <code>static</code> 的。</li><li>最根本的做法，<strong>通过 namespace 等手段从根本上避免同名变量及函数的存在</strong>！</li></ul><hr><p>最后给出几个简单测试程序，可以对照着理解上面的各种行为。</p><p><code>my_calss.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span> &#123;</span></span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">   <span class="built_in">MyClass</span>(<span class="keyword">int</span> a) : <span class="built_in">a_</span>(a) &#123;</span><br><span class="line">     std::cout &lt;&lt; <span class="string">&quot;Construct! &quot;</span> &lt;&lt; a_ &lt;&lt; <span class="string">&quot; @ &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; std::endl;</span><br><span class="line">     <span class="built_in">g_fun</span>();</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">   ~<span class="built_in">MyClass</span>() &#123;</span><br><span class="line">     std::cout &lt;&lt; <span class="string">&quot;Destruct! &quot;</span> &lt;&lt; a_ &lt;&lt; <span class="string">&quot; @ &quot;</span> &lt;&lt; <span class="keyword">this</span> &lt;&lt; std::endl;</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">   <span class="keyword">int</span> a_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p><code>my_lib1.cc</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_class.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MyClass <span class="title">g_var</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>my_lib2.cc</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_class.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MyClass <span class="title">g_var</span><span class="params">(<span class="number">2</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>app1.cc</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_class.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MyClass <span class="title">g_var</span><span class="params">(<span class="number">10</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="built_in">g_fun</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>app2.cc</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;dlfcn.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_class.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MyClass <span class="title">g_var</span><span class="params">(<span class="number">12</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">dlopen</span>(<span class="string">&quot;./libmylib1.so&quot;</span>, RTLD_NOW);</span><br><span class="line">  <span class="built_in">dlopen</span>(<span class="string">&quot;./libmylib2.so&quot;</span>, RTLD_NOW);</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="built_in">g_fun</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>app3.cc</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;dlfcn.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;my_class.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function">MyClass <span class="title">g_var</span><span class="params">(<span class="number">12</span>)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">g_fun</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::cout &lt;&lt; __FILE__ &lt;&lt; <span class="string">&quot;:&quot;</span> &lt;&lt; __LINE__ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">dlopen</span>(<span class="string">&quot;./libmylib1.so&quot;</span>, RTLD_NOW | RTLD_GLOBAL);</span><br><span class="line">  <span class="built_in">dlopen</span>(<span class="string">&quot;./libmylib2.so&quot;</span>, RTLD_NOW | RTLD_GLOBAL);</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="built_in">g_fun</span>();</span><br><span class="line">  std::cout &lt;&lt; <span class="string">&quot;----------&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Makefile</code>:</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">mylib1: my_class.h my_lib1.cc</span></span><br><span class="line">    g++ -fPIC -shared -o libmylib1.so my_lib1.cc</span><br><span class="line"></span><br><span class="line"><span class="section">mylib2: my_class.h my_lib2.cc</span></span><br><span class="line">    g++ -fPIC -shared -o libmylib2.so my_lib2.cc</span><br><span class="line"></span><br><span class="line"><span class="section">app1: app1.cc my_class.h mylib1 mylib2</span></span><br><span class="line">    g++ -L./ -lmylib1 -lmylib2 -o app1 app1.cc</span><br><span class="line"></span><br><span class="line"><span class="section">app2: app2.cc my_class.h</span></span><br><span class="line">    g++ -ldl -o app2 app2.cc</span><br><span class="line"></span><br><span class="line"><span class="section">app3: app3.cc my_class.h</span></span><br><span class="line">    g++ -ldl -o app3 app3.cc</span><br><span class="line"></span><br><span class="line"><span class="section">all: app1 app2 app3</span></span><br></pre></td></tr></table></figure><hr><p>测试程序运行结果为：</p><p><code>app1</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">./app1</span></span><br><span class="line">Construct! 2 @ 0x404194</span><br><span class="line">app1.cc:6</span><br><span class="line">Construct! 1 @ 0x404194</span><br><span class="line">app1.cc:6</span><br><span class="line">Construct! 10 @ 0x404194</span><br><span class="line">app1.cc:6</span><br><span class="line">----------</span><br><span class="line">app1.cc:6</span><br><span class="line">----------</span><br><span class="line">Destruct! 10 @ 0x404194</span><br><span class="line">Destruct! 10 @ 0x404194</span><br><span class="line">Destruct! 10 @ 0x404194</span><br></pre></td></tr></table></figure><p><code>app2</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">./app2</span></span><br><span class="line">Construct! 12 @ 0x404194</span><br><span class="line">app2.cc:9</span><br><span class="line">Construct! 1 @ 0x7fd81b9f106c</span><br><span class="line">my_lib1.cc:7</span><br><span class="line">Construct! 2 @ 0x7fd81b9ec06c</span><br><span class="line">my_lib2.cc:7</span><br><span class="line">----------</span><br><span class="line">app2.cc:9</span><br><span class="line">----------</span><br><span class="line">Destruct! 2 @ 0x7fd81b9ec06c</span><br><span class="line">Destruct! 1 @ 0x7fd81b9f106c</span><br><span class="line">Destruct! 12 @ 0x404194</span><br></pre></td></tr></table></figure><p><code>app3</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">./app3</span></span><br><span class="line">Construct! 12 @ 0x404194</span><br><span class="line">app3.cc:9</span><br><span class="line">Construct! 1 @ 0x7efd3799d06c</span><br><span class="line">my_lib1.cc:7</span><br><span class="line">Construct! 2 @ 0x7efd3799d06c</span><br><span class="line">my_lib1.cc:7</span><br><span class="line">----------</span><br><span class="line">app3.cc:9</span><br><span class="line">----------</span><br><span class="line">Destruct! 2 @ 0x7efd3799d06c</span><br><span class="line">Destruct! 2 @ 0x7efd3799d06c</span><br><span class="line">Destruct! 12 @ 0x404194</span><br></pre></td></tr></table></figure><hr><p>本文只是一个简单的总结，关于此问题的更多深入讨论可以参考以下文章：</p><blockquote><p><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/aix/library/au-aix-symbol-visibility/index.html">控制共享库的符号可见性  第 1 部分 - 符号可见性简介</a><br><a target="_blank" rel="noopener" href="http://kouucocu.lofter.com/post/1cdb8c4b_50f6306">浅谈动态库符号的私有化与全局化</a><br><a target="_blank" rel="noopener" href="http://codemacro.com/2014/11/04/linux-dynamic-library/">linux动态库的种种要点</a><br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36529418">Linux动态链接库so版本兼容</a><br><a target="_blank" rel="noopener" href="http://codemacro.com/2014/09/15/inside-static-library/">浅析静态库链接原理</a><br><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/383f9cd4c67e">全局符号</a><br><a target="_blank" rel="noopener" href="https://www.cnblogs.com/suncoolcat/p/3398170.html">Linux下全局符号覆盖问题</a><br><a target="_blank" rel="noopener" href="https://www.technovelty.org/c/what-exactly-does-bsymblic-do.html">What exactly does -Bsymblic do?</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;今天在调试时发现了一个奇怪的core：&lt;code&gt;double free or corruption (fasttop)&lt;/code&gt;，从堆栈看是由于 &lt;code&gt;_dl_fini&lt;/code&gt; 函数多次重复释放了某些 STL 容器导致的，此时就算在 &lt;code&gt;main&lt;/code&gt; 函数中只保留个简单 &lt;code&gt;return 0&lt;/code&gt; 也会出错，因此猜想肯定和某些全局变量有关。后面经过各种修改尝试，终于发现这是由于引用的 &lt;code&gt;.so&lt;/code&gt; 动态库和主程序中定义了同名的全局 STL 容器导致的，此时的行为简直就是一个神坑，很有必要记录一下……&lt;/p&gt;</summary>
    
    
    
    <category term="软件之道" scheme="https://gaomf.cn/categories/%E8%BD%AF%E4%BB%B6%E4%B9%8B%E9%81%93/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="C++" scheme="https://gaomf.cn/tags/C/"/>
    
    <category term="Compiler" scheme="https://gaomf.cn/tags/Compiler/"/>
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
    <category term="Debug" scheme="https://gaomf.cn/tags/Debug/"/>
    
  </entry>
  
  <entry>
    <title>如何从 coredump 文件中获取被优化掉的局部变量真实值</title>
    <link href="https://gaomf.cn/2019/12/24/coredump_optimized_value/"/>
    <id>https://gaomf.cn/2019/12/24/coredump_optimized_value/</id>
    <published>2019-12-24T12:56:28.000Z</published>
    <updated>2021-06-11T13:45:29.579Z</updated>
    
    <content type="html"><![CDATA[<p>在 GCC  <code>-O3</code> 优化级别下，很多局部变量是会被优化掉的，此时只能通过人工分析反汇编代码来获取所需信息，而这么做的前提是保存下来的寄存器中的值是准确的。绝大部分情况下 coredump 是由于 segment fault 或 assert 触发的，segment fault 情况下 Kernel 保存下来的 registers 信息是准确的，GDB 中直接用 <code>info registers</code> 就可以看到。然而若是由 assert 触发，由于 assert 会进行多层函数调用后最终执行 <code>raise()</code>，错误现场的寄存器信息是不准确的，这时候就需要一些其他手段来解决此问题。下面用一个具体例子来说明此问题。</p><span id="more"></span><p>测试程序代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">int</span> <span class="keyword">final</span> = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fun</span><span class="params">(<span class="keyword">int</span> a)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> b = a + <span class="number">100</span>;</span><br><span class="line">  <span class="keyword">final</span> = b;</span><br><span class="line">  <span class="keyword">if</span> (b &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="built_in">assert</span>(<span class="literal">false</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    std::cout &lt;&lt; b;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> n = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">fun</span>(<span class="built_in">rand</span>()) == <span class="number">1</span>) &#123;</span><br><span class="line">      n++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">100000</span>) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行此程序肯定会发生 assert failed，我们用 gdb 来看下调用栈：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Program terminated with signal SIGABRT, Aborted.</span><br><span class="line"><span class="meta">#</span><span class="bash">0  0x00007fac9f2f31f7 <span class="keyword">in</span> raise () from /lib64/libc.so.6</span></span><br><span class="line"><span class="meta">gef&gt;</span><span class="bash"> bt</span></span><br><span class="line"><span class="meta">#</span><span class="bash">0  0x00007fac9f2f31f7 <span class="keyword">in</span> raise () from /lib64/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1  0x00007fac9f2f48e8 <span class="keyword">in</span> abort () from /lib64/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">2  0x00007fac9f2ec266 <span class="keyword">in</span> __assert_fail_base () from /lib64/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">3  0x00007fac9f2ec312 <span class="keyword">in</span> __assert_fail () from /lib64/libc.so.6</span></span><br><span class="line"><span class="meta">#</span><span class="bash">4  0x0000000000400d5e <span class="keyword">in</span> fun (a=&lt;optimized out&gt;)</span></span><br><span class="line"><span class="meta">#</span><span class="bash">5  main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;)</span></span><br></pre></td></tr></table></figure><p>切换到 <code>fun()</code> 的栈帧：</p><figure class="highlight sh"><figcaption><span>e</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">gef&gt; f 4</span><br><span class="line"><span class="comment">#4  0x0000000000400de0 in fun (a=&lt;optimized out&gt;)</span></span><br><span class="line">245    assert(<span class="literal">false</span>);</span><br><span class="line">gef&gt; p a</span><br><span class="line"><span class="variable">$1</span> = &lt;optimized out&gt;</span><br><span class="line">gef&gt; p b</span><br><span class="line"><span class="variable">$2</span> = &lt;optimized out&gt;</span><br></pre></td></tr></table></figure><p>可以看到 <code>a</code> 与 <code>b</code> 都被优化掉了，到底是哪个值触发了 assert 就不能直接确定了。当然并不是就彻底没办法知道了，来看下 <code>fun()</code> 函数的反汇编：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">gef&gt; disassemble</span><br><span class="line">Dump of assembler code for function main(<span class="keyword">int</span>, char**):</span><br><span class="line">   <span class="number">0x0000000000400d10</span> &lt;+<span class="number">0</span>&gt;:<span class="keyword">push</span>   <span class="built_in">rbx</span></span><br><span class="line">   <span class="number">0x0000000000400d11</span> &lt;+<span class="number">1</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">ebx</span>,<span class="number">0x186a1</span></span><br><span class="line">   <span class="number">0x0000000000400d16</span> &lt;+<span class="number">6</span>&gt;:<span class="keyword">nop</span>    <span class="built_in">WORD</span> <span class="built_in">PTR</span> <span class="built_in">cs</span>:[<span class="built_in">rax</span>+<span class="built_in">rax</span>*<span class="number">1</span>+<span class="number">0x0</span>]</span><br><span class="line">   <span class="number">0x0000000000400d20</span> &lt;+<span class="number">16</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400c70</span> &lt;rand@plt&gt;</span><br><span class="line">   <span class="number">0x0000000000400d25</span> &lt;+<span class="number">21</span>&gt;:<span class="keyword">lea</span>    <span class="built_in">esi</span>,[<span class="built_in">rax</span>+<span class="number">0x64</span>]</span><br><span class="line">   <span class="number">0x0000000000400d28</span> &lt;+<span class="number">24</span>&gt;:<span class="keyword">test</span>   <span class="built_in">esi</span>,<span class="built_in">esi</span></span><br><span class="line">   <span class="number">0x0000000000400d2a</span> &lt;+<span class="number">26</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rip</span>+<span class="number">0x201570</span>],<span class="built_in">esi</span>        # <span class="number">0x6022a0</span> &lt;final&gt;</span><br><span class="line">   <span class="number">0x0000000000400d30</span> &lt;+<span class="number">32</span>&gt;:<span class="keyword">jg</span>     <span class="number">0x400d45</span> &lt;main(<span class="keyword">int</span>, char**)+<span class="number">53</span>&gt;</span><br><span class="line">   <span class="number">0x0000000000400d32</span> &lt;+<span class="number">34</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edi</span>,<span class="number">0x602080</span></span><br><span class="line">   <span class="number">0x0000000000400d37</span> &lt;+<span class="number">39</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400cd0</span> &lt;_ZNSolsEi@plt&gt;</span><br><span class="line">   <span class="number">0x0000000000400d3c</span> &lt;+<span class="number">44</span>&gt;:<span class="keyword">sub</span>    <span class="built_in">ebx</span>,<span class="number">0x1</span></span><br><span class="line">   <span class="number">0x0000000000400d3f</span> &lt;+<span class="number">47</span>&gt;:<span class="keyword">jne</span>    <span class="number">0x400d20</span> &lt;main(<span class="keyword">int</span>, char**)+<span class="number">16</span>&gt;</span><br><span class="line">   <span class="number">0x0000000000400d41</span> &lt;+<span class="number">49</span>&gt;:<span class="keyword">xor</span>    <span class="built_in">eax</span>,<span class="built_in">eax</span></span><br><span class="line">   <span class="number">0x0000000000400d43</span> &lt;+<span class="number">51</span>&gt;:<span class="keyword">pop</span>    <span class="built_in">rbx</span></span><br><span class="line">   <span class="number">0x0000000000400d44</span> &lt;+<span class="number">52</span>&gt;:<span class="keyword">ret</span></span><br><span class="line">   <span class="number">0x0000000000400d45</span> &lt;+<span class="number">53</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">ecx</span>,<span class="number">0x400fc6</span></span><br><span class="line">   <span class="number">0x0000000000400d4a</span> &lt;+<span class="number">58</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edx</span>,<span class="number">0xf5</span></span><br><span class="line">   <span class="number">0x0000000000400d4f</span> &lt;+<span class="number">63</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">esi</span>,<span class="number">0x400f70</span></span><br><span class="line">   <span class="number">0x0000000000400d54</span> &lt;+<span class="number">68</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edi</span>,<span class="number">0x400fc0</span></span><br><span class="line">   <span class="number">0x0000000000400d59</span> &lt;+<span class="number">73</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400c80</span> &lt;__assert_fail@plt&gt;</span><br></pre></td></tr></table></figure><p>在 <code>-O3</code> 优化下 <code>fun()</code> 直接被内联到 <code>main()</code> 里面了，不过这不影响基本分析，重点关注 <code>&lt;+16&gt;</code> ~ <code>&lt;+32&gt;</code> 这几行，这就对应 <code>fun()</code> 的前几行逻辑，<code>if (b &gt; 0)</code> 是通过 <code>test</code> + <code>jg</code> 来实现的，<code>b</code> 的值此时就是 <code>%esi</code> 寄存器中的值。看下 gdb 分析出来的当前栈帧的寄存器值：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">gef&gt; info registers</span><br><span class="line"><span class="built_in">rax</span>            <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">rbx</span>            <span class="number">0x186a1</span>             <span class="number">0x186a1</span></span><br><span class="line"><span class="built_in">rcx</span>            <span class="number">0x7fac9f2f31f7</span>      <span class="number">0x7fac9f2f31f7</span></span><br><span class="line"><span class="built_in">rdx</span>            <span class="number">0x6</span>                 <span class="number">0x6</span></span><br><span class="line"><span class="built_in">rsi</span>            <span class="number">0x4cc5</span>              <span class="number">0x4cc5</span></span><br><span class="line"><span class="built_in">rdi</span>            <span class="number">0x4cc5</span>              <span class="number">0x4cc5</span></span><br><span class="line"><span class="built_in">rbp</span>            <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">rsp</span>            <span class="number">0x7fff091e0410</span>      <span class="number">0x7fff091e0410</span></span><br><span class="line"><span class="built_in">r8</span>             <span class="number">0x1</span>                 <span class="number">0x1</span></span><br><span class="line"><span class="built_in">r9</span>             <span class="number">0xfeff092d63646b68</span>  <span class="number">0xfeff092d63646b68</span></span><br><span class="line"><span class="built_in">r10</span>            <span class="number">0x8</span>                 <span class="number">0x8</span></span><br><span class="line"><span class="built_in">r11</span>            <span class="number">0x206</span>               <span class="number">0x206</span></span><br><span class="line"><span class="built_in">r12</span>            <span class="number">0x400daf</span>            <span class="number">0x400daf</span></span><br><span class="line"><span class="built_in">r13</span>            <span class="number">0x7fff091e04f0</span>      <span class="number">0x7fff091e04f0</span></span><br><span class="line"><span class="built_in">r14</span>            <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">r15</span>            <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">rip</span>            <span class="number">0x400d5e</span>            <span class="number">0x400d5e</span></span><br><span class="line">eflags         <span class="number">0x206</span>               [ PF IF ]</span><br><span class="line"><span class="built_in">cs</span>             <span class="number">0x33</span>                <span class="number">0x33</span></span><br><span class="line"><span class="built_in">ss</span>             <span class="number">0x2b</span>                <span class="number">0x2b</span></span><br><span class="line"><span class="built_in">ds</span>             <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">es</span>             <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">fs</span>             <span class="number">0x0</span>                 <span class="number">0x0</span></span><br><span class="line"><span class="built_in">gs</span>             <span class="number">0x0</span>                 <span class="number">0x0</span></span><br></pre></td></tr></table></figure><p>是不是其中 <code>%rsi</code> 的值就是我们需要的 <code>b</code> 了呢？非也！注意到 <code>&lt;+68&gt;</code> 行，在调用 <code>__assert_fail()</code> 前 <code>%esi</code> 又被重新赋值用于传递参数了，且由于 <code>%esi</code> 属于 caller save 的寄存器，在 <code>__assert_fail()</code> 内有可能会被再次改写。因此 <strong>使用 GDB 分析 coredump 文件不同栈帧的 register 信息时，只有为数不多的几个 callee save 寄存器的值是可靠的，其他的都是不可靠的。</strong> 那如何才能得到可靠的寄存器值呢？一般来说只有靠我们自己保存了，一个简单思路是只要在调用 <code>__assert_fail()</code> 前把所有寄存器的值保存到一个全局数组中就可以了。</p><p>在 <code>assert()</code> 前添加如下一段内联汇编代码即可实现此目的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">__asm__ __volatile__(<span class="string">&quot;movq $0, %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rax, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rbx, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rcx, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rdx, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rsi, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rdi, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rbp, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%rsp, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r8, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r9, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r10, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r11, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r12, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r13, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r14, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;movq %%r15, (%0, %%r15, 8);\n\t&quot;</span></span><br><span class="line">                     <span class="string">&quot;incq %%r15;\n\t&quot;</span></span><br><span class="line">                        :</span><br><span class="line">                        : <span class="string">&quot;r&quot;</span> (registers_data)</span><br><span class="line">                        : <span class="string">&quot;%r15&quot;</span>);</span><br></pre></td></tr></table></figure><p>再来看下此时的反汇编代码：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">gef&gt; disassemble</span><br><span class="line">Dump of assembler code for function main(<span class="keyword">int</span>, char**):</span><br><span class="line">   <span class="number">0x0000000000400d10</span> &lt;+<span class="number">0</span>&gt;:<span class="keyword">push</span>   <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d12</span> &lt;+<span class="number">2</span>&gt;:<span class="keyword">push</span>   <span class="built_in">rbx</span></span><br><span class="line">   <span class="number">0x0000000000400d13</span> &lt;+<span class="number">3</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">ebx</span>,<span class="number">0x186a1</span></span><br><span class="line">   <span class="number">0x0000000000400d18</span> &lt;+<span class="number">8</span>&gt;:<span class="keyword">sub</span>    <span class="built_in">rsp</span>,<span class="number">0x8</span></span><br><span class="line">   <span class="number">0x0000000000400d1c</span> &lt;+<span class="number">12</span>&gt;:<span class="keyword">nop</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="number">0x0</span>]</span><br><span class="line">   <span class="number">0x0000000000400d20</span> &lt;+<span class="number">16</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400c70</span> &lt;rand@plt&gt;</span><br><span class="line">   <span class="number">0x0000000000400d25</span> &lt;+<span class="number">21</span>&gt;:<span class="keyword">lea</span>    <span class="built_in">esi</span>,[<span class="built_in">rax</span>+<span class="number">0x64</span>]</span><br><span class="line">   <span class="number">0x0000000000400d28</span> &lt;+<span class="number">24</span>&gt;:<span class="keyword">test</span>   <span class="built_in">esi</span>,<span class="built_in">esi</span></span><br><span class="line">   <span class="number">0x0000000000400d2a</span> &lt;+<span class="number">26</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">DWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rip</span>+<span class="number">0x201570</span>],<span class="built_in">esi</span>        # <span class="number">0x6022a0</span> &lt;final&gt;</span><br><span class="line">   <span class="number">0x0000000000400d30</span> &lt;+<span class="number">32</span>&gt;:<span class="keyword">jg</span>     <span class="number">0x400d4b</span> &lt;main(<span class="keyword">int</span>, char**)+<span class="number">59</span>&gt;</span><br><span class="line">   <span class="number">0x0000000000400d32</span> &lt;+<span class="number">34</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edi</span>,<span class="number">0x602080</span></span><br><span class="line">   <span class="number">0x0000000000400d37</span> &lt;+<span class="number">39</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400cd0</span> &lt;_ZNSolsEi@plt&gt;</span><br><span class="line">   <span class="number">0x0000000000400d3c</span> &lt;+<span class="number">44</span>&gt;:<span class="keyword">sub</span>    <span class="built_in">ebx</span>,<span class="number">0x1</span></span><br><span class="line">   <span class="number">0x0000000000400d3f</span> &lt;+<span class="number">47</span>&gt;:<span class="keyword">jne</span>    <span class="number">0x400d20</span> &lt;main(<span class="keyword">int</span>, char**)+<span class="number">16</span>&gt;</span><br><span class="line">   <span class="number">0x0000000000400d41</span> &lt;+<span class="number">49</span>&gt;:<span class="keyword">add</span>    <span class="built_in">rsp</span>,<span class="number">0x8</span></span><br><span class="line">   <span class="number">0x0000000000400d45</span> &lt;+<span class="number">53</span>&gt;:<span class="keyword">xor</span>    <span class="built_in">eax</span>,<span class="built_in">eax</span></span><br><span class="line">   <span class="number">0x0000000000400d47</span> &lt;+<span class="number">55</span>&gt;:<span class="keyword">pop</span>    <span class="built_in">rbx</span></span><br><span class="line">   <span class="number">0x0000000000400d48</span> &lt;+<span class="number">56</span>&gt;:<span class="keyword">pop</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d4a</span> &lt;+<span class="number">58</span>&gt;:<span class="keyword">ret</span></span><br><span class="line">   <span class="number">0x0000000000400d4b</span> &lt;+<span class="number">59</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">eax</span>,<span class="number">0x6021a0</span></span><br><span class="line">   <span class="number">0x0000000000400d50</span> &lt;+<span class="number">64</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">r15</span>,<span class="number">0x0</span></span><br><span class="line">   <span class="number">0x0000000000400d57</span> &lt;+<span class="number">71</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rax</span></span><br><span class="line">   <span class="number">0x0000000000400d5b</span> &lt;+<span class="number">75</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d5e</span> &lt;+<span class="number">78</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rbx</span></span><br><span class="line">   <span class="number">0x0000000000400d62</span> &lt;+<span class="number">82</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d65</span> &lt;+<span class="number">85</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rcx</span></span><br><span class="line">   <span class="number">0x0000000000400d69</span> &lt;+<span class="number">89</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d6c</span> &lt;+<span class="number">92</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rdx</span></span><br><span class="line">   <span class="number">0x0000000000400d70</span> &lt;+<span class="number">96</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d73</span> &lt;+<span class="number">99</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rsi</span></span><br><span class="line">   <span class="number">0x0000000000400d77</span> &lt;+<span class="number">103</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d7a</span> &lt;+<span class="number">106</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rdi</span></span><br><span class="line">   <span class="number">0x0000000000400d7e</span> &lt;+<span class="number">110</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d81</span> &lt;+<span class="number">113</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rbp</span></span><br><span class="line">   <span class="number">0x0000000000400d85</span> &lt;+<span class="number">117</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d88</span> &lt;+<span class="number">120</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">rsp</span></span><br><span class="line">   <span class="number">0x0000000000400d8c</span> &lt;+<span class="number">124</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d8f</span> &lt;+<span class="number">127</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r8</span></span><br><span class="line">   <span class="number">0x0000000000400d93</span> &lt;+<span class="number">131</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d96</span> &lt;+<span class="number">134</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r9</span></span><br><span class="line">   <span class="number">0x0000000000400d9a</span> &lt;+<span class="number">138</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400d9d</span> &lt;+<span class="number">141</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r10</span></span><br><span class="line">   <span class="number">0x0000000000400da1</span> &lt;+<span class="number">145</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400da4</span> &lt;+<span class="number">148</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r11</span></span><br><span class="line">   <span class="number">0x0000000000400da8</span> &lt;+<span class="number">152</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400dab</span> &lt;+<span class="number">155</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r12</span></span><br><span class="line">   <span class="number">0x0000000000400daf</span> &lt;+<span class="number">159</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400db2</span> &lt;+<span class="number">162</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r13</span></span><br><span class="line">   <span class="number">0x0000000000400db6</span> &lt;+<span class="number">166</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400db9</span> &lt;+<span class="number">169</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r14</span></span><br><span class="line">   <span class="number">0x0000000000400dbd</span> &lt;+<span class="number">173</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400dc0</span> &lt;+<span class="number">176</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">QWORD</span> <span class="built_in">PTR</span> [<span class="built_in">rax</span>+<span class="built_in">r15</span>*<span class="number">8</span>],<span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400dc4</span> &lt;+<span class="number">180</span>&gt;:<span class="keyword">inc</span>    <span class="built_in">r15</span></span><br><span class="line">   <span class="number">0x0000000000400dc7</span> &lt;+<span class="number">183</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">ecx</span>,<span class="number">0x4010c6</span></span><br><span class="line">   <span class="number">0x0000000000400dcc</span> &lt;+<span class="number">188</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edx</span>,<span class="number">0xf5</span></span><br><span class="line">   <span class="number">0x0000000000400dd1</span> &lt;+<span class="number">193</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">esi</span>,<span class="number">0x401070</span></span><br><span class="line">   <span class="number">0x0000000000400dd6</span> &lt;+<span class="number">198</span>&gt;:<span class="keyword">mov</span>    <span class="built_in">edi</span>,<span class="number">0x4010c0</span></span><br><span class="line">   <span class="number">0x0000000000400ddb</span> &lt;+<span class="number">203</span>&gt;:<span class="keyword">call</span>   <span class="number">0x400c80</span> &lt;__assert_fail@plt&gt;</span><br></pre></td></tr></table></figure><p><code>&lt;+59&gt;</code> ~ <code>&lt;+180&gt;</code> 行就是我们新加的逻辑，可以看到这段代码紧接在 <code>&lt;+32&gt;</code> 行之后，理论上分析的确是可以保存准确的寄存器信息。来看下实际效果：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">gef&gt;</span><span class="bash"> p registers_data</span></span><br><span class="line"><span class="meta">$</span><span class="bash">1 = &#123;0x6021a0, 0x186a1, 0x7f872ad260d4, 0x7f872ad260c8, 0x6b8b45cb, 0x7f872ad266e0, 0x0, 0x7ffd6d53a660, 0x7f872ad260c8, 0x7f872ad26140, 0x7ffd6d53a370, 0x7f872a9a38b0, 0x400e2f, 0x7ffd6d53a750, 0x0, 0xf, 0x0 &lt;repeats 16 <span class="built_in">times</span>&gt;&#125;</span></span><br><span class="line"><span class="meta">gef&gt;</span><span class="bash"> p final</span></span><br><span class="line"><span class="meta">$</span><span class="bash">2 = 0x6b8b45cb</span></span><br></pre></td></tr></table></figure><p><code>registers_data[4]</code> 与 <code>final</code> 的值完全相同，而从源代码和反汇编 <code>&lt;+26&gt;</code> 行可以看到，<code>final</code> 中保存的就是 <code>b</code> 的真实值。</p><hr><blockquote><p>参考资料：<br><a target="_blank" rel="noopener" href="https://undo.io/resources/value-optimized-out-reverse-debugging-rescue/">Value optimized out. Reverse debugging to the rescue!</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;在 GCC  &lt;code&gt;-O3&lt;/code&gt; 优化级别下，很多局部变量是会被优化掉的，此时只能通过人工分析反汇编代码来获取所需信息，而这么做的前提是保存下来的寄存器中的值是准确的。绝大部分情况下 coredump 是由于 segment fault 或 assert 触发的，segment fault 情况下 Kernel 保存下来的 registers 信息是准确的，GDB 中直接用 &lt;code&gt;info registers&lt;/code&gt; 就可以看到。然而若是由 assert 触发，由于 assert 会进行多层函数调用后最终执行 &lt;code&gt;raise()&lt;/code&gt;，错误现场的寄存器信息是不准确的，这时候就需要一些其他手段来解决此问题。下面用一个具体例子来说明此问题。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="Top" scheme="https://gaomf.cn/tags/Top/"/>
    
    <category term="x86" scheme="https://gaomf.cn/tags/x86/"/>
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
    <category term="Debug" scheme="https://gaomf.cn/tags/Debug/"/>
    
    <category term="GDB" scheme="https://gaomf.cn/tags/GDB/"/>
    
  </entry>
  
  <entry>
    <title>使用 perf 进行性能分析时如何获取准确的调用栈</title>
    <link href="https://gaomf.cn/2019/10/30/perf_stack_traceback/"/>
    <id>https://gaomf.cn/2019/10/30/perf_stack_traceback/</id>
    <published>2019-10-30T15:09:37.000Z</published>
    <updated>2021-12-22T15:18:25.365Z</updated>
    
    <content type="html"><![CDATA[<p><code>perf</code> 是 Linux 下重要的性能分析工具，<code>perf</code> 可以通过采样获取很多性能指标，其中最常用的是获取 CPU Cycles，即程序各部分代码运行所需的时间，进而确定性能瓶颈在哪。不过在实际使用过程中发现，简单的使用<code>perf record -g</code> 获取到的调用栈是有问题的，存在大量 <code>[Unknown]</code> 函数，从 <code>perf report</code> 的结果来看这些部分对应地址大部分都是非法地址，且生成的火焰图中存在很多明显与代码矛盾的调用关系。</p><span id="more"></span><p>最初怀疑是优化级别的问题，然而尝试使用 <code>Og</code> 或 <code>O0</code> 优化依然存在此问题，仔细阅读 <code>perf record</code> 的手册后发现，<code>perf</code> 同时支持 3 种栈回溯方式：<code>fp</code>, <code>dwarf</code>, <code>lbr</code>，可以通过 <code>--call-graph</code> 参数指定，而 <code>-g</code> 就相当于 <code>--call-graph fp</code>.</p><h3 id="栈回溯方式"><a href="#栈回溯方式" class="headerlink" title="栈回溯方式"></a>栈回溯方式</h3><p> <code>fp</code> 就是 Frame Pointer，即 x86 中的 <code>EBP</code> 寄存器，<code>fp</code> 指向当前栈帧栈底地址，此地址保存着上一栈帧的 <code>EBP</code> 值，具体可参考<a target="_blank" rel="noopener" href="https://www.cs.rutgers.edu/~pxk/419/notes/frames.html">此文章</a>的介绍，根据 <code>fp</code> 就可以逐级回溯调用栈。然而这一特性是会被优化掉的，而且这还是 GCC 的默认行为，在不手动指定 <code> -fno-omit-frame-pointer</code> 时默认都会进行此优化，此时 <code>EBP</code> 被当作一般的通用寄存器使用，以此为依据进行栈回溯显然是错误的。不过尝试指定 <code>-fno-omit-frame-pointer</code> 后依然没法获取到正确的调用栈，根据 GCC 手册的<a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html">说明</a>，指定了此选项后也并不保证所有函数调用都会使用 <code>fp</code>…… 看来只有放弃使用 <code>fp</code> 进行回溯了。</p><p><code>dwarf</code> 是一种调试文件格式，GCC 编译时附加的 <code>-g</code> 参数生成的就是 <code>dwarf</code> 格式的调试信息，其中包括了栈回溯所需的全部信息，使用 <code>libunwind</code> 即可展开这些信息。<code>dwarf</code> 的进一步介绍可参考 <a target="_blank" rel="noopener" href="http://cwndmiao.github.io/programming%20tools/2013/11/26/Dwarf/">“关于DWARF”</a>，值得一提的是，GDB 进行栈回溯时使用的正是 <code>dwarf</code> 调试信息。实际测试表明使用 <code>dwarf</code> 可以很好的获取到准确的调用栈。</p><p>最后 <code>perf</code> 还支持通过 <code>lbr</code> 获取调用栈，<code>lbr</code> 即 Last Branch Records，是较新的 Intel CPU 中提供的一组硬件寄存器，其作用是记录之前若干次分支跳转的地址，主要目的就是用来支持 <code>perf</code> 这类性能分析工具，其详细说明可参考 <a target="_blank" rel="noopener" href="https://lwn.net/Articles/680985/">“An introduction to last branch records”</a> &amp; <a target="_blank" rel="noopener" href="https://lwn.net/Articles/680996/">“Advanced usage of last branch records”</a>。此方法是性能与准确性最高的手段，然而它存在一个很大的局限性，由于硬件 Ring Buffer 寄存器的大小是有限的，<code>lbr</code> 能记录的栈深度也是有限的，具体值取决于特定 CPU 实现，一般就是 32 层，若超过此限制会得到错误的调用栈。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>实际测试下以上 3 种栈回溯方式得到的结果，测试程序是一个调用深度为 50 的简单程序，从 <code>f0()</code> 依次调用至 <code>f50()</code>。</p><p><b><code>--call-graph fp</code></b>：</p><p><img src="https://img.gaomf.cn/perf_test_fp.svg"></p><p><b><code>--call-graph lbr</code></b>：</p><p><img src="https://img.gaomf.cn/perf_test_lbr.svg"></p><p><b><code>--call-graph dwarf</code></b>：</p><p><img src="https://img.gaomf.cn/perf_test_dwarf.svg"></p><p>可以看到，的确只有 <code>dwarf</code> 获取到了正确的调用栈。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table><thead><tr><th></th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><code>fp</code></td><td>None</td><td>1. 默认 <code>fp</code> 被优化掉了根本不可用。</td></tr><tr><td><code>lbr</code></td><td>1. 高效准确</td><td>1. 需要较新的 Intel CPU 才有此功能；2. 能记录的调用栈深度有限。</td></tr><tr><td><code>dwarf</code></td><td>1. 准确</td><td>1. 开销相对较大；2. 需要编译时附加了调试信息。</td></tr></tbody></table><hr><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="http://www.brendangregg.com/perf.html">perf Examples</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;perf&lt;/code&gt; 是 Linux 下重要的性能分析工具，&lt;code&gt;perf&lt;/code&gt; 可以通过采样获取很多性能指标，其中最常用的是获取 CPU Cycles，即程序各部分代码运行所需的时间，进而确定性能瓶颈在哪。不过在实际使用过程中发现，简单的使用&lt;code&gt;perf record -g&lt;/code&gt; 获取到的调用栈是有问题的，存在大量 &lt;code&gt;[Unknown]&lt;/code&gt; 函数，从 &lt;code&gt;perf report&lt;/code&gt; 的结果来看这些部分对应地址大部分都是非法地址，且生成的火焰图中存在很多明显与代码矛盾的调用关系。&lt;/p&gt;</summary>
    
    
    
    <category term="工具之术" scheme="https://gaomf.cn/categories/%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%9C%AF/"/>
    
    
    <category term="x86" scheme="https://gaomf.cn/tags/x86/"/>
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
    <category term="Debug" scheme="https://gaomf.cn/tags/Debug/"/>
    
  </entry>
  
  <entry>
    <title>PVE上部署OpenWRT发生网络中断的解决方法</title>
    <link href="https://gaomf.cn/2019/07/28/PVE_OpenWRT_Network_Broken/"/>
    <id>https://gaomf.cn/2019/07/28/PVE_OpenWRT_Network_Broken/</id>
    <published>2019-07-28T03:27:09.000Z</published>
    <updated>2021-06-11T13:45:29.562Z</updated>
    
    <content type="html"><![CDATA[<p>在旧笔记本上使用Proxmox搭建了一个OpenWRT软路由，正常使用都很稳定，然而当PC使用百度网盘，迅雷等工具进行全速率下载时偶尔会出现网络中断问题，此时Proxmox宿主机的网络会全部断掉，即PVE自己的Web管理界面也无法登录。查看终端，此时会不断打印<code>Detected Hardware Unit Hang</code>的错误提示。</p><span id="more"></span><p>Google一下这个错误提示，还是有不少类似问题的：</p><blockquote><p><a target="_blank" rel="noopener" href="https://jhartman.pl/2018/08/06/proxmox-enp0s31f6-detected-hardware-unit-hang/">Proxmox: enp0s31f6: Detected Hardware Unit Hang</a></p><p><a target="_blank" rel="noopener" href="https://ovear.info/post/356">解决FreeNAS under KVM使用Virtio网卡导致宿主机网卡Hang的问题</a></p><p><a target="_blank" rel="noopener" href="https://serverfault.com/questions/616485/e1000e-reset-adapter-unexpectedly-detected-hardware-unit-hang">e1000e Reset adapter unexpectedly / Detected Hardware Unit Hang</a></p><p><a target="_blank" rel="noopener" href="https://superuser.com/questions/1270723/how-to-fix-eth0-detected-hardware-unit-hang-in-debian-9">How to fix “eth0: Detected Hardware Unit Hang” in Debian 9?</a></p><p><a target="_blank" rel="noopener" href="https://forum.proxmox.com/threads/proxmox-node-freezes.44618/">Proxmox Node freezes</a></p></blockquote><p>基本所有文章都提到此问题与<code>TCP checksum offload</code>特性有关，解决方案就是关掉<code>checksum offload</code>。具体方法是使用<code>ethtool</code>工具：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ethtool -K enp0s25 tx off rx off</span><br></pre></td></tr></table></figure><p>如果要重启后永久生效的话将此命令写入<code>/etc/network/if-up.d/ethtool2</code>文件中并为此文件加上<code>x</code>权限即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">ethtool -K enp0s25 tx off rx off</span><br></pre></td></tr></table></figure><hr><p>除此之外上述第2篇文章的情况和我遇到的很像，里面提到这与<code>Virtio</code>虚拟化有很大关系，而我使用的也正是<code>Vritio</code>，根据作者的说法，更应该在OpenWRT而不是Proxmox中关闭<code>checksum offload</code>。然而实际试了下却发现一个蛋疼的问题，OpenWRT中是无法把<code>tx checksum offload</code>给关掉的……</p><p>此外作者还提到，将网卡的虚拟化方式从<code>Virtio</code>改为<code>E1000</code>也可以解决此问题，不过会有CPU占用率上升的副作用。</p><hr><p>综合以上几种方法，我最后采用的解决办法是：禁用Proxmox宿主机上的<code>TCP checksum offload</code>，并将OpenWRT使用的网卡虚拟化方式改为<code>E1000</code>。实际测试下来没有再发生网卡hang的问题，满速率下载（250Mbps左右）时CPU占用率50%左右，比之前使用<code>Virtio</code>时CPU占用率要高10%左右，还是可以接受的。</p><hr><p>问题算是解决了，最后顺带去进一步学习了下相关的知识，首先是<code>TCP checksum offload</code>，此技术的作用是将计算TCP  checksum的工作由CPU软件实现改为由NIC设备（即网卡等）硬件实现，以此达到节约CPU资源的目的。</p><blockquote><p><a target="_blank" rel="noopener" href="https://www2.cs.duke.edu/ari/trapeze/freenix/node7.html">Checksum Offloading</a></p><p><a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/en/ssw_aix_71/performance/tcp_checksum_offload.html">TCP checksum offload</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/sinat_20184565/article/details/82979778">UDP的checksum计算与硬件Offload</a></p></blockquote><p>另外就是<code>Virtio</code>与<code>E1000</code>，这是两种不同的网络虚拟化技术，<code>Virtio</code>是半虚拟化而<code>E1000</code>是全虚拟化。对于全虚拟化方案来说，虚拟机是完全感知不到自己是运行在一个虚拟环境中的；而半虚拟化则是虚拟机知道自己就是运行在一个虚拟环境中，此时IO驱动就可以做一些针对性的修改优化，以此降低虚拟化层进行转换带来的开销及性能损失。显而易见，半虚拟化技术的隔离度是没有全虚拟化好的，而且要是虚拟机驱动有问题会导致宿主机也出问题。这就是为什么在使用<code>Virtio</code>时，OpenWRT网络出现问题会导致整个Proxmox的网络都不能用了的原因。除了这两种虚拟化方式外，还有些更为先进的虚拟化技术，如<code>SR-IVO</code>等，有兴趣的话可以看看下面这篇文章的总结：</p><blockquote><p><a target="_blank" rel="noopener" href="https://blog.51cto.com/xiaoli110/1558984">KVM虚拟化网络优化技术总结</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;在旧笔记本上使用Proxmox搭建了一个OpenWRT软路由，正常使用都很稳定，然而当PC使用百度网盘，迅雷等工具进行全速率下载时偶尔会出现网络中断问题，此时Proxmox宿主机的网络会全部断掉，即PVE自己的Web管理界面也无法登录。查看终端，此时会不断打印&lt;code&gt;Detected Hardware Unit Hang&lt;/code&gt;的错误提示。&lt;/p&gt;</summary>
    
    
    
    <category term="工具之术" scheme="https://gaomf.cn/categories/%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%9C%AF/"/>
    
    
    <category term="Network" scheme="https://gaomf.cn/tags/Network/"/>
    
    <category term="Virtualization" scheme="https://gaomf.cn/tags/Virtualization/"/>
    
  </entry>
  
  <entry>
    <title>用于嵌入式车载安全预警的交通标志检测若干关键技术研究与验证</title>
    <link href="https://gaomf.cn/2019/02/24/Thesis_of_Master/"/>
    <id>https://gaomf.cn/2019/02/24/Thesis_of_Master/</id>
    <published>2019-02-24T13:32:12.000Z</published>
    <updated>2021-06-11T13:45:29.584Z</updated>
    
    <content type="html"><![CDATA[<p>转眼间毕业已经要一年了，今天在整理电脑文件的时候翻出了当初写的硕士毕业论文，在知网上搜搜也<a target="_blank" rel="noopener" href="http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&dbname=CMFD201802&filename=1018186759.nh">找得到了</a>。想想硕士期间做过的东西也太杂了，电机控制、Android 开发、嵌入式。。。最后确定了这个毕业论文的题目后只有1年不到的时间可以做了，这期间还要复习准备找工作，不过最后做出来的东西还算是自己基本满意的，这估计也是我在学术上的顶峰了……</p><span id="more"></span><p>为纪念下我离Academy最近的时刻，这里把我这篇论文的摘要及pdf版本的全文贴一下吧。</p><p>全文下载链接：<a target="_blank" rel="noopener" href="https://img.gaomf.cn/%E7%94%A8%E4%BA%8E%E5%B5%8C%E5%85%A5%E5%BC%8F%E8%BD%A6%E8%BD%BD%E5%AE%89%E5%85%A8%E9%A2%84%E8%AD%A6%E7%9A%84%E4%BA%A4%E9%80%9A%E6%A0%87%E5%BF%97%E6%A3%80%E6%B5%8B%E8%8B%A5%E5%B9%B2%E5%85%B3%E9%94%AE%E6%8A%80%E6%9C%AF%E7%A0%94%E7%A9%B6%E4%B8%8E%E9%AA%8C%E8%AF%81_%E9%AB%98%E6%98%8E%E9%A3%9E.pdf">用于嵌入式车载安全预警的交通标志检测若干关键技术研究与验证</a></p><p>论文摘要：</p><p>车载安全预警系统可及时为驾驶员提供必要的行车安全预警信息以提高驾驶安全性,其包含若干子系统,如交通标志识别、超速预警等,而交通标志检测则是支撑诸多子系统的重要基础技术之一;本文就针对交通标志检测中基于颜色分割的定位算法及多线程任务调度策略这两项关键技术进行了研究,提出了适用于性能有限嵌入式系统的混合颜色分割策略及混合切换任务调度策略,并通过搭建嵌入式原型样机在实际道路环境中验证了方法的有效性。此外为更好的验证及评估交通标志检测算法的效果,本文建立了中国道路交通标志视频数据集,并将此数据集公开发布以供其他研究人员使用,这也是此领域目前唯一的中国公开数据集。目前主流成熟的交通标志检测定位方法基本均是基于颜色及几何形状局部特征的,本文在此框架下对用于车载安全预警的交通标志检测中最为重要的红色及黄色分割方法展开了深入研究,针对已有主流颜色分割方法的不足提出了混合颜色分割策略,此策略通过若干线性分类器的组合实现了对红色及黄色准确高效的分割,分割效果优于目前常用的各方法且其算法执行速度与最简单的RGB阈值法相似,可保证安全预警算法在性能有限的小型嵌入式车载设备上依然有较好的实时性;在颜色分割基础上本文采用经典的Hough变换实现了对红色圆形交通标志的检测定位并在数据集上评估了算法的效果。本文通过对交通标志检测识别问题进行建模分析提出可用采样间隔时间作为定量衡量此类系统实时性的指标,进而针对目前广泛使用的多核CPU提出了理论最优的理想多线程任务调度算法,此算法可显著降低采样间隔时间以提高系统实时性;不过理想任务调度算法实际无法实现,因此本文进一步提出了实际可实现的混合切换任务调度策略及动态更新参数估计策略;通过控制系统模型数值仿真及实际嵌入式原型样机上的测试验证均表明本文提出的方法可有效优化采样间隔时间分布以此提高系统实时性。本文同时开发了基于Qt的算法验证平台软件及基于Intel Joule模块的嵌入式原型样机,并在其上验证了上述各方法的有效性,最后在校园环境及城市道路上分别进行了静态及动态系统集成测试;测试结果表明本文提出的方法可在小型嵌入式设备上满足系统实时性要求,在天气光照条件较好时检出率也相对较高,不过算法鲁棒性依然需要加强。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;转眼间毕业已经要一年了，今天在整理电脑文件的时候翻出了当初写的硕士毕业论文，在知网上搜搜也&lt;a target=&quot;_blank&quot; rel=&quot;noopener&quot; href=&quot;http://kns.cnki.net/KCMS/detail/detail.aspx?dbcode=CMFD&amp;dbname=CMFD201802&amp;filename=1018186759.nh&quot;&gt;找得到了&lt;/a&gt;。想想硕士期间做过的东西也太杂了，电机控制、Android 开发、嵌入式。。。最后确定了这个毕业论文的题目后只有1年不到的时间可以做了，这期间还要复习准备找工作，不过最后做出来的东西还算是自己基本满意的，这估计也是我在学术上的顶峰了……&lt;/p&gt;</summary>
    
    
    
    <category term="科研之路" scheme="https://gaomf.cn/categories/%E7%A7%91%E7%A0%94%E4%B9%8B%E8%B7%AF/"/>
    
    
    <category term="Concurrent" scheme="https://gaomf.cn/tags/Concurrent/"/>
    
    <category term="OpenCV" scheme="https://gaomf.cn/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>深入分析Docker hello-world镜像</title>
    <link href="https://gaomf.cn/2019/02/15/Deep_Into_Dokcer_Helloworld/"/>
    <id>https://gaomf.cn/2019/02/15/Deep_Into_Dokcer_Helloworld/</id>
    <published>2019-02-15T14:46:25.000Z</published>
    <updated>2021-06-12T02:07:20.799Z</updated>
    
    <content type="html"><![CDATA[<p>学习Docker时一般刚开始接触的第一个docker image就是<code>hello-world</code>，这个image运行起来的效果也很简单直接，仅仅是在屏幕上输出一段Docker的使用说明就结束了。这个镜像虽然简单，然而仔细分析下还是涉及不少底层机制的。</p><span id="more"></span><p>我之所以会对这个镜像感兴趣，是发现它的大小仅仅只有1.84kB，这实在是太小了，写一个<code>printf(&quot;Hello Wolrd\n&quot;);</code>的程序编译出来大小就远超1.84kB了，所以很好奇这个镜像是如何构建出来的。</p><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>Docker的镜像构建过程是由其镜像描述文件Dockerfile决定的，所以就先找到其Dockerfile来看看。<code>hello-world</code>用于<code>AMD64</code>架构的Dockerfile可以在<a target="_blank" rel="noopener" href="https://github.com/docker-library/hello-world/blob/b715c35271f1d18832480bde75fe17b93db26414/amd64/hello-world/Dockerfile">Github上</a>找到，只有简单的3行：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> scratch</span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> hello /</span></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/hello&quot;</span>]</span></span><br></pre></td></tr></table></figure><p>第1行导入了一个名为<code>scratch</code>的东西，这并不是一个真正的image，可以把它视为是所有image的最底层虚拟镜像，类似于一个基本抽象类，Docker官方对其的说明<a target="_blank" rel="noopener" href="https://hub.docker.com/_/scratch">如下</a>：</p><blockquote><p>This image is most useful in the context of building base images (such as <a target="_blank" rel="noopener" href="https://registry.hub.docker.com/_/debian/"><code>debian</code></a> and <a target="_blank" rel="noopener" href="https://registry.hub.docker.com/_/busybox/"><code>busybox</code></a>) or super minimal images (that contain only a single binary and whatever it requires, such as <a target="_blank" rel="noopener" href="https://registry.hub.docker.com/_/hello-world/"><code>hello-world</code></a>).</p><p>As of Docker 1.5.0 (specifically, <a target="_blank" rel="noopener" href="https://github.com/docker/docker/pull/8827"><code>docker/docker#8827</code></a>), <code>FROM scratch</code> is a no-op in the <code>Dockerfile</code>, and will not create an extra layer in your image (so a previously 2-layer image will be a 1-layer image instead).</p><p>……</p><p>You can use Docker’s reserved, minimal image, <code>scratch</code>, as a starting point for building containers. Using the <code>scratch</code> “image” signals to the build process that you want the next command in the <code>Dockerfile</code> to be the first filesystem layer in your image.</p></blockquote><p>后面两行的含义也很直接，把一个名为hello的程序copy到根目录下，在运行image的时候运行此程序。下面就来看下这个如此小的hello world程序是如何实现的。</p><h2 id="主程序"><a href="#主程序" class="headerlink" title="主程序"></a>主程序</h2><p>hello.c文件的源码也在同一个<a target="_blank" rel="noopener" href="https://github.com/docker-library/hello-world/blob/master/hello.c">Github仓库中</a>，省略掉过长的字符串常量后很简单：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">char</span> message[] =</span><br><span class="line">    <span class="string">&quot;Hello World!&quot;</span></span><br><span class="line">    <span class="string">&quot;\n&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> _start() &#123;</span><br><span class="line">    syscall(SYS_write, <span class="number">1</span>, message, <span class="keyword">sizeof</span>(message) - <span class="number">1</span>);</span><br><span class="line">    syscall(SYS_exit, <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个最简版本的Hello World和C语言教科书中第一个Hello World是有不小差别的。首先是程序入口点上，众所周知正常C/C++程序的入口点是<code>main()</code>，然而这里使用的是<code>_start()</code>。</p><p>我们的程序是运行在Linux系统上的，程序的加载与运行必然是由OS发起的，<strong>对于Linux来说，OS层面的程序入口点就是<code>_start()</code>而不是<code>main()</code> 函数</strong>，一个程序要能正常运行在<code>main()</code>之前是有一些准备工作要做的，比如建立程序运行环境（初始化.bss全局变量等）；在<code>main()</code>返回之后也有些收尾工作要处理，比如调用<code>exit()</code>通知系统等。这些工作正常情况下是由语言标准库来完成的，也就是所谓的Runtime运行环境，对于C语言来说就是<code>crt0.o</code>。大部分程序的<code>_start()</code>就位于其中，在建立好运行环境后<code>_start()</code>会调用<code>main()</code>跳转到用户定义的入口点处。当<code>main()</code>返回后程序又将回到<code>ctr0.o</code>中，最终调用<code>exit()</code>通知OS回收进程资源。</p><p>这里为了缩小程序体积和简单起见，没有使用标准的<code>ctr0.o</code> Runtime，事实上这一个简单的程序也不需要什么Runtime。程序最后直接通过<code>syscall</code>函数调用了<code>SYS_exit</code>系统调用结束了自身的运行。</p><p>将字符串输出到屏幕上也没有使用标准库中的<code>printf()</code>，同样是直接调用了<code>SYS_write</code>这个系统调用，其第一个参数显式的写为了1，其实就是<code>STDOUT_FILENO</code>，Linux系统在<code>unistd.h</code>中定义了<code>stdin</code>, <code>stdout</code>, <code>stderr</code>这几个标准文件描述符。</p><p>可以看到，这样一个程序是可以不依赖于任何其他的库在Linux上独立运行的，为了实现不链接C标准库的目的，需要使用一些特殊的编译选项。从编译这个<code>hello-world</code>程序使用的<a target="_blank" rel="noopener" href="https://github.com/docker-library/hello-world/blob/master/Makefile">Makefile</a>中可以找到使用的编译选项为：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CFLAGS := -static -Os -nostartfiles -fno-asynchronous-unwind-tables</span><br></pre></td></tr></table></figure><ul><li><code>-static</code>表示静态链接，虽然对这个程序来说无所谓动态链接还是静态链接……</li><li><code>-Os</code>表示为空间进行<code>-O2</code>级别的优化，专门用于减少目标文件大小；</li><li><code>-nostartfiles</code>是关键编译选项，此选项表示不使用标准C语言运行库（即<code>crt0.o</code>），也不链接C标准库；</li><li><code>-fno-asynchronous-unwind-tables</code>选项也是用于减少代码空间的，其大概含义是不产生C++异常处理机制中使用的<code>.eh_frame</code>段，关于什么是<code>unwind-tables</code>和<code>.eh_frame</code>是个比这篇文章复杂多了的问题，文末有几篇参考资料，之后有空可以深入学习下C++的底层机制……</li></ul><p>进行了以上诸多特殊优化处理后，终于可以得到一个只有1k多的可以正常运行于Linux上的Hello World程序了。</p><hr><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/29694564/what-is-the-use-of-start-in-c">What is the use of _start() in C?</a></p><p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/43050089/when-is-the-gcc-flag-nostartfiles-used">When is the gcc flag -nostartfiles used?</a></p><p><a target="_blank" rel="noopener" href="https://software.intel.com/en-us/blogs/2013/01/17/x86-gcc-code-size-optimizations">GCC x86 code size optimizations</a></p><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/catch/p/3619379.html">c++ 异常处理（2）</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;学习Docker时一般刚开始接触的第一个docker image就是&lt;code&gt;hello-world&lt;/code&gt;，这个image运行起来的效果也很简单直接，仅仅是在屏幕上输出一段Docker的使用说明就结束了。这个镜像虽然简单，然而仔细分析下还是涉及不少底层机制的。&lt;/p&gt;</summary>
    
    
    
    <category term="软件之道" scheme="https://gaomf.cn/categories/%E8%BD%AF%E4%BB%B6%E4%B9%8B%E9%81%93/"/>
    
    
    <category term="Compiler" scheme="https://gaomf.cn/tags/Compiler/"/>
    
    <category term="C" scheme="https://gaomf.cn/tags/C/"/>
    
    <category term="Runtime" scheme="https://gaomf.cn/tags/Runtime/"/>
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
    <category term="Docker" scheme="https://gaomf.cn/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>sudo不需要输入密码的方法</title>
    <link href="https://gaomf.cn/2018/11/17/Sudo_No_Passwd/"/>
    <id>https://gaomf.cn/2018/11/17/Sudo_No_Passwd/</id>
    <published>2018-11-17T09:20:09.000Z</published>
    <updated>2021-06-11T13:45:29.574Z</updated>
    
    <content type="html"><![CDATA[<p>正常情况下，使用<code>sudo</code>命令是需要输入密码的，连续输入多条<code>sudo</code>只用输一次密码就行，不过若干分钟后又需要输入密码了。对于自己使用的本地桌面环境来说，其实是可以配置成<code>sudo</code>免输入密码的，这样可以减少一些麻烦。</p><span id="more"></span><p>以<code>Ubuntu 18.04</code>为例说明设置方法，其他发行版可能会有区别。<code>Ubuntu Desktop</code>默认已经将安装系统时配置的用户加入了<code>admin</code>用户组，且<code>admin</code>用户组中的用户都是有<code>sudo</code>权限的，因此无需修改<code>sudo</code>用户组。若需要将某用户添加到<code>sudo</code>用户组中，可参考文末链接。</p><p>输入<code>su -</code>命令切换到<code>root</code>下，修改<code>/etc/sudoers</code>文件，找到：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Allow members of group sudo to execute any command</span></span><br><span class="line">%sudoALL=(ALL:ALL) ALL</span><br></pre></td></tr></table></figure><p>修改为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Allow members of group sudo to execute any command</span></span><br><span class="line">%sudoALL=(ALL:ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure><p>即可。</p><p>这样就可以允许<code>sudo</code>用户组中的用户免密码执行<code>sudo</code>命令了。</p><hr><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/5d02428f313d">免密码使用sudo和su</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;正常情况下，使用&lt;code&gt;sudo&lt;/code&gt;命令是需要输入密码的，连续输入多条&lt;code&gt;sudo&lt;/code&gt;只用输一次密码就行，不过若干分钟后又需要输入密码了。对于自己使用的本地桌面环境来说，其实是可以配置成&lt;code&gt;sudo&lt;/code&gt;免输入密码的，这样可以减少一些麻烦。&lt;/p&gt;</summary>
    
    
    
    <category term="工具之术" scheme="https://gaomf.cn/categories/%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%9C%AF/"/>
    
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>为Hexo博客Yelee主题添加Gitment评论系统</title>
    <link href="https://gaomf.cn/2018/11/04/Hexo_Yelee_Gitment/"/>
    <id>https://gaomf.cn/2018/11/04/Hexo_Yelee_Gitment/</id>
    <published>2018-11-04T13:36:31.000Z</published>
    <updated>2021-06-12T02:50:49.370Z</updated>
    
    <content type="html"><![CDATA[<p>本来博客使用的是多说作为评论系统，前两年多说停止服务了换成了友言，用了没多久友言又要求备案不能用了……后面由于工作繁忙也就没管这个了。前段时间发现Gitment这个基于Github Issue的评论系统不错，这两天终于有空把它给加上了。</p><span id="more"></span><p>我使用的主题是基于<a target="_blank" rel="noopener" href="https://github.com/MOxFIVE/hexo-theme-yelee">Yelee</a>做了些修改得到的，Yelee又是基于<a target="_blank" rel="noopener" href="https://github.com/litten/hexo-theme-yilia">Yilia</a>的，添加Gitment的过程可以参考这篇文章：</p><blockquote><p><a target="_blank" rel="noopener" href="https://sogrey.github.io/article/Hexo-%E6%B7%BB%E5%8A%A0-Gitment-%E8%AF%84%E8%AE%BA/">Hexo 添加 Gitment 评论</a></p></blockquote><p>Yiila主题也添加了Gitment支持，其<a target="_blank" rel="noopener" href="https://github.com/litten/hexo-theme-yilia/commit/af58957e14a00b3da03e4026c56d34cdf7eda9b4">Commit</a>也是很有参考价值的。</p><p>与以上教程有区别的是，无需安装Gitment npm插件，添加修改的代码我也改了下，有兴趣的话可以看这个<a target="_blank" rel="noopener" href="https://github.com/g199209/BlogTheme/commit/bc591586bd737f0f24a08c54f36f6e10372050c6">Commit</a>。</p><p>其中Gitment的CSS &amp; JS文件改为了本地压缩后的版本，评论框的显示效果也调整了下。</p><p>终于评论系统又可以用啦，之后就该静心学学技术提高下自己的水平了……</p><blockquote><p>Update:</p><p>2021-06-12: Gitment 的 Github OAuth 是依赖于外部服务器的，目前公共的挂得差不多了，需要自己搭一个，参考下文：</p><p><a target="_blank" rel="noopener" href="https://sherry0429.github.io/2019/02/12/gitment%E4%BF%AE%E5%A4%8D/">gitment修复[object ProgressEvent]</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;本来博客使用的是多说作为评论系统，前两年多说停止服务了换成了友言，用了没多久友言又要求备案不能用了……后面由于工作繁忙也就没管这个了。前段时间发现Gitment这个基于Github Issue的评论系统不错，这两天终于有空把它给加上了。&lt;/p&gt;</summary>
    
    
    
    <category term="工具之术" scheme="https://gaomf.cn/categories/%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%9C%AF/"/>
    
    
    <category term="Blog" scheme="https://gaomf.cn/tags/Blog/"/>
    
  </entry>
  
  <entry>
    <title>sizeof 获取 extern 数组长度</title>
    <link href="https://gaomf.cn/2018/06/30/sizeof_extern_array/"/>
    <id>https://gaomf.cn/2018/06/30/sizeof_extern_array/</id>
    <published>2018-06-30T08:52:12.000Z</published>
    <updated>2021-06-11T13:45:29.574Z</updated>
    
    <content type="html"><![CDATA[<p>sizeof是获取数组元素个数的常用运算符，然而前几天使用时发现，对于extern类型的数组，sizeof的使用上是有些需要考虑的问题的。</p><span id="more"></span><p>假设系统中有3个文件：</p><p><code>file1.c</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br></pre></td></tr></table></figure><p><code>header1.h</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> <span class="built_in">array</span>[];</span><br></pre></td></tr></table></figure><p><code>main.c</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;header1.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// This is WRONG!</span></span><br><span class="line">    <span class="keyword">size_t</span> elements_in_array = <span class="keyword">sizeof</span>(<span class="built_in">array</span>) / <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>main.c</code>中期望通过<code>sizeof</code>运算符获取<code>array</code>中元素个数，然而这么做是错误的，编译时无法通过，错误提示类似<code>incomplete type not allowed</code>这类。</p><p>造成这一问题的原因在于，**<code>sizeof</code>是在编译时计算的，而C/C++的编译是以文件为基本单位的**。在编译<code>main.c</code>文件时，编译器是不可能知道定义在<code>file1.c</code>文件中<code>array</code>数组具体信息的，只根据<code>header1.h</code>文件中的声明是无法确定<code>array</code>的具体大小的，因此，就算某些编译器编译时不报错，得到的结果也是不正确的。</p><p>分析清楚原因后来看下解决方案，基本解决方法有4种：</p><ol><li>避免使用匿名长度的数组声明，使用宏定义预先确定数组大小；</li><li>定义一个辅助变量用于保存数组大小信息，将其定义赋值放在定义<code>array</code>数组的同一个文件中；</li><li>使用特殊元素表示数组结束，就像字符串结尾的<code>&#39;\0&#39;</code>一样，这样就可以在运行阶段动态确定数组大小；</li><li>将数组的定义放到使用它的源文件中。</li></ol><p>这几种方法都有其缺点：</p><ol><li>使用<code>sizeof</code>就是不想固定数组长度，因为使用宏定义固定数组长度不够灵活，要是想添加数组元素也要同时修改宏定义，否则尽管编译不会报错，然而运行时新添加的元素其实是无效的，这会导致将来维护时一些潜在Bug发生的可能性增加；</li><li>需要一个额外的存储空间，且由于这是一个变量，每次使用数组长度时都需要访问内存，编译器也无法对数组长度作出任何假设，进而影响编译优化，理论上说这可能会导致运行时一些微小的效率损失；</li><li>需要修改上层逻辑，缺乏通用性；</li><li>大部分情况下，使用非<code>static</code>全局变量的原因就是多个源文件需要使用这个变量，这时显然无法做到这一点，多次重复定义链接时会出错的。</li></ol><p>实际使用中，需要根据具体问题具体分析采用哪种方法最恰当，一般而言不经常变化的数组就使用宏定义确定其大小，会经常变化的第2种方法最常用，此时还可以用一些宏定义简化编程，以上代码可修改为：</p><p><code>file1.c</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;header1.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> <span class="built_in">array</span>[] = &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line"></span><br><span class="line">ELEMENTS_IN_DEF(<span class="built_in">array</span>)</span><br></pre></td></tr></table></figure><p><code>header1.h</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span>  ELEMENTS_IN(array)            __elements_in_##array</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span>  ELEMENTS_IN_DEF(array)        size_t __elements_in_##array = sizeof(array) / sizeof(array[0]);</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span>  ELEMENTS_IN_DECLARE(array)    extern size_t __elements_in_##array;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> <span class="built_in">array</span>[];</span><br><span class="line">ELEMENTS_IN_DECLARE(<span class="built_in">array</span>)</span><br></pre></td></tr></table></figure><p><code>main.c</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;header1.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">fun</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> elements_in_array = ELEMENTS_IN(<span class="built_in">array</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>参考资料：</p><p><a target="_blank" rel="noopener" href="http://c-faq.com/decl/extarraysize.html">comp.lang.c FAQ list · Question 1.24</a></p><p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/23230114/c-how-to-determine-sizeofarray-sizeofstruct-for-external-array">C: How to determine sizeof(array) / sizeof(struct) for external array?</a></p><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ranhui_xia/article/details/39502665">sizeof extern数组</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;sizeof是获取数组元素个数的常用运算符，然而前几天使用时发现，对于extern类型的数组，sizeof的使用上是有些需要考虑的问题的。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="C" scheme="https://gaomf.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>多歧路，今安在？</title>
    <link href="https://gaomf.cn/2018/06/03/The_Road/"/>
    <id>https://gaomf.cn/2018/06/03/The_Road/</id>
    <published>2018-06-03T08:59:01.000Z</published>
    <updated>2021-06-11T13:45:29.579Z</updated>
    
    <content type="html"><![CDATA[<p>好久没写博客了，翻看自己的博客，上次更新已是半年多前了，这大半年来忙于找工作，毕业设计，毕业答辩、入职……入职前两个月也是各种忙碌，现在对手头的工作也熟悉一些了，于是乎在低头做事的空暇时也需要抬起头来看看路了。</p><span id="more"></span><p>自从找工作拿到几个Offer可以选择时就开始各种纠结与困惑了，大疆、阿里、Intel、华为、拼多多、乐鑫、网易……有幸能拿到这么些优秀公司的Offer，然而每一家公司都同时有吸引我和令我踌躇的地方，鱼和熊掌终不可兼得，选择也变得十分困难。虽然最终选择了大疆，然而这一选择并不是那么顺理成章，当时在犹豫，本以为选了之后就不会困惑了，现在才发觉，困惑的东西并不会随着时间推移而自然而然的变得清晰起来。</p><p>人生有很多选择，选择和努力哪个更重要呢？这个问题的标准答案在准备面试时都背得滚瓜烂熟了，选择与努力互为因果，选择是为了决定之后努力的方向，努力是为了将来能有更多选择。然而，记住了所谓的标准答案并无济于事，该困惑的时候还是一样困惑。</p><p>其实想想，所有困惑的根源都来自于两点：不知道自己真正想要的是什么；不知道未来会是怎样。</p><p>与其说是不知道自己想要什么，不如说是不知道自己愿意放弃什么，选择之所以困难，是因为选择与放弃总是如影相随的，选择了此就注定要放弃彼。人总是什么都想要的，但事实是我们注定要放弃大多数东西的，人生在不断的做出选择，同时也是在不断放弃。然而，我究竟愿意放弃什么呢？愿意选择什么呢？这并不是那么确定的啊……什么都不想放弃，也就注定什么都无法得到。</p><p>上面那点也许还能随着年岁与阅历的增长思考得越来越清楚，那对未来不可知的迷茫更是让人觉得无能为力。生命的精彩源于不可知，生命的痛苦也源于不可知。时代的洪流滚滚前进，顺之者昌逆之者亡，然而时代的车轮碾向何方又有谁知？</p><p>可供选的路总是越来越少的，我们都终有一日会无路可选，到那时，认命也罢，不认也罢，是非成败转头空，唯余夕阳照青山。在我们还有得可选的时候，还是多想想吧，就算是一条咸鱼也还是要挣扎下看看的。虽然路最终总是越走越窄的，还是要努力下让它窄得不要那么快吧，毕竟啊，谁又能说自己走的一定是那条自己想要同时又不会被时代湮没的道路呢？</p><p>瞎扯了这么多似乎还是多想清楚了那么一丝东西吧，脚踏实地亦要仰望星空，不要让天天加班和生活琐事的忙碌成为一种错觉蒙蔽了双眼。自己的未来何在，尽管想不清还是要去找的吧，在坚信自己找到之前，努力让未来的路宽广一些，努力让自己不要失去有选择的能力，虽然选择是困难和纠结的，然而没选择的走投无路是更大的悲哀。</p><p>然而，要维持像学校里那样站在四通八达的十字路口近乎是不可能完成的事，两条路经常是越来越远的，刚开始时尚有可能跳过去，越到后面越难跳过去了吧。所以啊，还是要尽快想清楚自己想去哪条路上才行啊，然而，谁知道哪时候能想清楚呢……不过在想清楚自己要跳去哪条路上之前，还是要多练练自己跳跃的能力，培养些通用的技能，让自己还是有路可跳有路可选吧。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;好久没写博客了，翻看自己的博客，上次更新已是半年多前了，这大半年来忙于找工作，毕业设计，毕业答辩、入职……入职前两个月也是各种忙碌，现在对手头的工作也熟悉一些了，于是乎在低头做事的空暇时也需要抬起头来看看路了。&lt;/p&gt;</summary>
    
    
    
    <category term="人生之思" scheme="https://gaomf.cn/categories/%E4%BA%BA%E7%94%9F%E4%B9%8B%E6%80%9D/"/>
    
    
  </entry>
  
  <entry>
    <title>SSH反向穿透访问内网主机</title>
    <link href="https://gaomf.cn/2017/11/04/SSH_Forwarding/"/>
    <id>https://gaomf.cn/2017/11/04/SSH_Forwarding/</id>
    <published>2017-11-03T16:16:00.000Z</published>
    <updated>2021-06-11T13:45:29.564Z</updated>
    
    <content type="html"><![CDATA[<p>学校的网络位于无数重NAT内网中，而且还有各种VPN，所以想要从外网访问十分困难，之前试过各种方法都没成功。今天偶然看到了SSH反向穿透的方法，因为我访问内网服务器主要也是需要SSH连接功能，故此方法可以很好的满足我的需求。此处记录下配置方法。</p><span id="more"></span><p>SSH反向穿透需要有一台有公网IP的服务器作为桥梁，此处将位于多重NAT网络中需要访问的主机称为Target，而将有固定IP的中转服务器称为Server。SSH反向穿透的原理是，Target主动建立与Server间的SSH连接，利用SSH的端口转发功能，将访问Server某端口的数据包转发到Target SSH端口（22端口）上，以此实现间接登陆Target的目的。</p><p>假设Server上的转发端口为<code>6766</code>，使用如下命令在Target上建立与Server间的反向隧道：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 22 -fN -R 6766:localhost:22 userServer@Server</span><br></pre></td></tr></table></figure><p><code>-R</code>用于定义反向隧道，<code>-fN</code>用于在建立SSH连接后SSH进入后台运行。</p><p>之后需要在Server上打开<code>sshd</code>的<code>GatewayPorts</code>功能，这样才能实现只登录一次即可连接上Target。修改<code>/etc/ssh/sshd_config</code>文件，添加下面这行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GatewayPorts clientspecified</span><br></pre></td></tr></table></figure><p>重启<code>sshd</code>服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh restart</span><br></pre></td></tr></table></figure><p>此时就可以在任意一个终端上使用<code>ssh -p 6766 userTarget@Server</code>登录到Target上了，需要注意的是，此时使用的用户名、密码、秘钥都应该是Target而不是Server的，只有IP地址或者是域名是Server的。</p><p>最后一个问题是，如何保持这个SSH反向隧道的稳定存在，并且实现若Target意外重启后能自动再次建立此反向隧道。解决方法是使用<code>autossh</code>，并且把它作为一个服务自动启动。</p><p>先安装<code>autossh</code>，之后在<code>/etc/init.d</code>下建立一个名为<code>autossh</code>的文件：（以下操作以Ubuntu为例，其他发行版可能会有区别）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">/usr/bin/autossh -p 22 -M 6777 -fN -R *:6766:localhost:22 userServer@Server -i id_rsa</span><br></pre></td></tr></table></figure><p><code>-M</code>参数指定了一个监控端口，和端口转发无关，使用一个无用的端口即可；<code>-i</code>指定了一个密钥，此处用RSA密钥的方式登陆Server。</p><p>保存此文件，并添加执行权限：<code>chmod +x autossh</code>；注册服务：<code>update-rc.d autossh enable</code>；最后启动服务：<code>service autossh start</code>。</p><p>可使用<code>sysv-rc-conf</code>工具查看<code>autossh</code>服务的开机自启动情况。这样将其作为服务配置好后，就可以实现稳定的SSH反向穿透了，终于可以实现从任何地方自由访问内网主机的目的了~~</p><p>最后顺便提一下，SSH转发其实可以承载其他更多的网络服务，这个之后有空再来研究~</p><hr><blockquote><p>参考资料：<br><a target="_blank" rel="noopener" href="http://network.51cto.com/art/201505/477144.htm">如何通过SSH反向隧道，访问NAT后面的Linux服务器?</a><br><a target="_blank" rel="noopener" href="http://arondight.me/2016/02/17/%E4%BD%BF%E7%94%A8SSH%E5%8F%8D%E5%90%91%E9%9A%A7%E9%81%93%E8%BF%9B%E8%A1%8C%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/">使用SSH反向隧道进行内网穿透</a><br><a target="_blank" rel="noopener" href="https://marshal.ohtly.com/2017/01/26/Reverse-SSH-Tunneling-with-Autossh/">使用autossh实现反向SSH隧道</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/yuanchao99/article/details/9111269">ubuntu service的添加和删除</a><br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/37438630/how-to-use-systemctl-in-ubuntu-14-04">How to use systemctl in Ubuntu 14.04</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;学校的网络位于无数重NAT内网中，而且还有各种VPN，所以想要从外网访问十分困难，之前试过各种方法都没成功。今天偶然看到了SSH反向穿透的方法，因为我访问内网服务器主要也是需要SSH连接功能，故此方法可以很好的满足我的需求。此处记录下配置方法。&lt;/p&gt;</summary>
    
    
    
    <category term="工具之术" scheme="https://gaomf.cn/categories/%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%9C%AF/"/>
    
    
    <category term="Linux" scheme="https://gaomf.cn/tags/Linux/"/>
    
    <category term="Network" scheme="https://gaomf.cn/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>C语言关键词restrict的应用</title>
    <link href="https://gaomf.cn/2017/10/25/C_restrict/"/>
    <id>https://gaomf.cn/2017/10/25/C_restrict/</id>
    <published>2017-10-25T08:22:00.000Z</published>
    <updated>2021-06-11T13:45:29.551Z</updated>
    
    <content type="html"><![CDATA[<p><code>restrict</code>是C99标准中新增的关键词，只能用于修饰指针（函数指针除外），其含义为：<strong>此指针是访问其指向对象的唯一初始方法</strong>。使用此关键词的意义在于：<strong>有助于编译器进行代码优化</strong>。</p><span id="more"></span><p><code>restrict</code>是一个类型限定词，在C99标准(ISO/IEC 9899:1999)的”6.7.3.1 Formal definition of restrict”中给出其定义，基本语法为<code>xxx * restrict var</code>，其中<code>xxx</code>是指针指向的变量类型。需要注意的是，只有指向所谓”object types”的指针才能用<code>restrict</code>修饰，而”object types”的定义应该是除了函数指针外所有类型的指针。另外，对于函数参数来说，由于数组和指针的等价性，函数参数为数组时也可以用<code>restrict</code>修饰，此时<code>restrict</code>放在<code>[]</code>中，如：<code>void fun(int par[restrict])</code>。</p><p>上面也说到，使用<code>restrict</code>的意义在于便于编译器优化，此处使用<code>restrict</code>最常用的一个例子进行说明：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span> * a, <span class="keyword">int</span> * b)</span> </span>&#123;</span><br><span class="line">    *a = <span class="number">5</span>;</span><br><span class="line">    *b = <span class="number">6</span>;</span><br><span class="line">    <span class="keyword">return</span> *a + *b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rfoo</span><span class="params">(<span class="keyword">int</span> * <span class="keyword">restrict</span> a, <span class="keyword">int</span> * <span class="keyword">restrict</span> b)</span> </span>&#123;</span><br><span class="line">    *a = <span class="number">5</span>;</span><br><span class="line">    *b = <span class="number">6</span>;</span><br><span class="line">    <span class="keyword">return</span> *a + *b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><!---workaround highlight bugs*---><p>对于<code>foo</code>函数，编译器是不能假设<code>a</code>和<code>b</code>指向的区域是不同的，它们有可能指向同一内存区域，故此时编译得到的汇编代码为：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">movl<span class="number">4</span>(%esp), %eax</span><br><span class="line">movl<span class="number">8</span>(%esp), %edx</span><br><span class="line">movl<span class="number">$5</span>, (%eax)</span><br><span class="line">movl<span class="number">$6</span>, (%edx)</span><br><span class="line">movl(%eax), %eax</span><br><span class="line">addl<span class="number">$6</span>, %eax</span><br><span class="line"><span class="keyword">ret</span></span><br></pre></td></tr></table></figure><p>可以看到，在进行最后一步加法运算前，需要再读一遍<code>*a</code>的值，以保证结果的正确性，因为若<code>a==b</code>的话，此时<code>*a == 6</code>而不是<code>*a == 5</code>；此时这段程序返回的是12而不是11。</p><p>然而，我们如果能确保<code>a != b</code>，那以上代码是可以进一步优化的，<code>restrict</code>关键词就用于把这一信息提供给编译器，此时的<code>rfoo</code>函数编译结果如下：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">movl<span class="number">4</span>(%esp), %eax</span><br><span class="line">movl<span class="number">$5</span>, (%eax)</span><br><span class="line">movl<span class="number">8</span>(%esp), %eax</span><br><span class="line">movl<span class="number">$6</span>, (%eax)</span><br><span class="line">movl<span class="number">$11</span>, %eax</span><br><span class="line"><span class="keyword">ret</span></span><br></pre></td></tr></table></figure><p>这段代码中直接返回了编译器预先计算出来的结果11，与<code>foo</code>相比减少了一次加法运算，且不需要进行<code>movl    (%eax), %eax</code>这一步骤。（虽然由于Cache的存在，这一指令也不一定会进行内存访问）</p><blockquote><p>以上汇编代码使用GCC 4.9.3编译得到，编译参数为：<code>-O3 -S -std=gnu11</code>，结果和参考资料中给出的汇编代码稍有区别，不知为何参数传递使用的是栈而不是寄存器……</p></blockquote><p>从以上例子中可以看到，若一个指针是访问某内存区域的唯一方法，那可以为其加上<code>restrict</code>限定符，这有利于编译器进行代码优化生成效率更高的程序。</p><hr><blockquote><p>参考资料：<br><a target="_blank" rel="noopener" href="http://en.cppreference.com/w/c/language/restrict">restrict type qualifier</a><br><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/41653775?sort=created">如何理解C语言关键字restrict？</a><br><a target="_blank" rel="noopener" href="http://blog.csdn.net/lovekatherine/article/details/1891806pub">C99中的restrict关键字</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;restrict&lt;/code&gt;是C99标准中新增的关键词，只能用于修饰指针（函数指针除外），其含义为：&lt;strong&gt;此指针是访问其指向对象的唯一初始方法&lt;/strong&gt;。使用此关键词的意义在于：&lt;strong&gt;有助于编译器进行代码优化&lt;/strong&gt;。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="C" scheme="https://gaomf.cn/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Linux kernel中的min和max宏</title>
    <link href="https://gaomf.cn/2017/10/08/Kernel_min_max_macro/"/>
    <id>https://gaomf.cn/2017/10/08/Kernel_min_max_macro/</id>
    <published>2017-10-08T08:38:00.000Z</published>
    <updated>2021-06-11T13:45:29.557Z</updated>
    
    <content type="html"><![CDATA[<p><code>min</code>和<code>max</code>是两个很常用的操作，一般都是用宏实现的，不过想要写出一个很完善的宏定义还是要考虑很多问题的，本文就来分析下Linux Kernel中的实现方法。文中仅考虑<code>min</code>，<code>max</code>的结构与其完全相同，只要修改下大于小于号即可。</p><span id="more"></span><p>宏定义中要将整体和变量都加上括号的意义此处就不多说了，据此我们可以写出一个最基本的形式：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> min(a, b) ((a) &lt; (b) ? (a) : (b))</span></span><br></pre></td></tr></table></figure><p>然而这种写法是有副作用的，考虑<code>min(a++, b)</code>这样的用法，其展开后的形式为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">((a++) &lt; (b) ? (a++) : (b++))</span><br></pre></td></tr></table></figure><p>当<code>a&lt;b</code>时，<code>a++</code>会被执行两次，这显然不是我们所希望的，为了解决这一问题，我们可以使用下面这个稍显复杂的宏定义：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> min(a, b) (&#123; \</span></span><br><span class="line"><span class="meta">typeof(a) __min1__ = (a);  \</span></span><br><span class="line"><span class="meta">typeof(b) __min2__ = (b);  \</span></span><br><span class="line"><span class="meta">(void)(&amp;__min1__ == &amp;__min2__);  \</span></span><br><span class="line"><span class="meta">__min1__ &lt; __min2__ ? __min1__ : __min2__;&#125;)</span></span><br></pre></td></tr></table></figure><p>这里用到了GCC的一个扩展特性，形如<code>(&#123; ... &#125;)</code>这样的代码块会被视为一条语句，其计算结果是<code>&#123; ... &#125;</code>中最后一条语句的计算结果。故上述宏定义展开后的结果就是第5行返回的结果。注意，这个扩展特性不是所有编译器都有的，如果用VS编译上述代码，是无法通过编译的。<br>这个宏定义中，先根据<code>a</code>, <code>b</code>的类型生成了两个局部变量<code>__min1__</code>和<code>__min2__</code>，之后比较其大小，返回较小的一个，这样就保证了宏参数只会被执行一次，避免了上述副作用。另外，第4行代码其实是没有实际作用的，其意义在于，若<code>__min1__</code>和<code>__min2__</code>的类型不同，比较其地址时编译器会给出一个Warning，这样可以避免一些潜在的错误发生。</p><p>以上宏定义就是网上普遍流传的Linux Kernel中的实现方法，然而，我实际阅读了当前<code>4.12.7</code>版本的Kernel源代码，发现实际的实现方法要更复杂一些。在引入实际的实现方法前，我们先思考一下以上宏定义还存在什么漏洞。</p><p>考虑以下代码段：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> __min1__ = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> __min2__ = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">int</span> min_val = min(__min1__--, __min2__++);</span><br></pre></td></tr></table></figure><p>期望得到的结果应该是<code>__min1__ = 9</code>, <code>__min2__ = 21</code>, <code>min_val = 10</code>。然而实际情况是，<code>__min1__ = 10</code>, <code>__min2__ = 20</code>，<code>min_val</code>的值则是不确定的。造成这一结果的原因在于输入参数和宏定义内部使用的局部变量重名了，这样就会导致在宏定义的语句块内，外层同名变量的作用域被内层局部变量的作用域所屏蔽，展开后的代码就成了这样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> main_val = (&#123;typeof(__min1__--) __min1__ = (__min1__--); <span class="comment">/* 省略 */</span> &#125;)</span><br></pre></td></tr></table></figure><p>这就类似于<code>int a = a</code>这样的语句，执行完后<code>a</code>的值是不确定的，且因为展开后<code>__min1__</code>成了宏体内的局部变量，<code>__min1__--</code>的自减操作对于外层变量来说也是无效的。</p><p>知道问题的原因后解决方法就很清晰了，只要避免重名就可以了，其实上述宏定义中使用<code>__min1__</code>这样的名字也是为了避免重名，然而，靠起特殊的名字这种方法不是那么的优雅，故实际新版的Linux Kernel中使用了编译器产生的唯一名称来解决这一问题：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Indirect macros required for expanded argument pasting, eg. __LINE__. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ___PASTE(a,b) a##b</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __PASTE(a,b) ___PASTE(a,b)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __COUNTER__)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * min()/max()/clamp() macros that also do</span></span><br><span class="line"><span class="comment"> * strict type-checking.. See the</span></span><br><span class="line"><span class="comment"> * &quot;unnecessary&quot; pointer comparison.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> __min(t1, t2, min1, min2, x, y) (&#123;\</span></span><br><span class="line"><span class="meta">t1 min1 = (x);\</span></span><br><span class="line"><span class="meta">t2 min2 = (y);\</span></span><br><span class="line"><span class="meta">(void) (&amp;min1 == &amp;min2);\</span></span><br><span class="line"><span class="meta">min1 &lt; min2 ? min1 : min2; &#125;)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> min(x, y)\</span></span><br><span class="line"><span class="meta">__min(typeof(x), typeof(y),\</span></span><br><span class="line"><span class="meta">      __UNIQUE_ID(min1_), __UNIQUE_ID(min2_),\</span></span><br><span class="line"><span class="meta">      x, y)</span></span><br></pre></td></tr></table></figure><p>可以看到这是一个多重的宏嵌套结构，主要区别就在于<code>__UNIQUE_ID(min1_)</code>上，<code>__UNIQUE_ID</code>可以生成一个唯一的名字。唯一性是由编译器提供的<code>__COUNTER__</code>宏保证的，这也是GCC的一个扩展，<a target="_blank" rel="noopener" href="https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html">GCC文档中</a>对其的说明如下：</p><blockquote><p>This macro expands to sequential integral values starting from 0. In conjunction with the ## operator, this provides a convenient means to generate unique identifiers.</p></blockquote><p>简而言之，<code>__COUNTER__</code>会被展开为一个从0开始的整数，且每次调用后其值都会加一，这也就保证了其唯一性。</p><p>至于<code>__PASTE</code>宏这是用来实现两个token连接的，之所以要两重宏定义和宏的嵌套展开规则有关，可以参考我之前写的<a href="/2017/10/06/C_Macro/">总结文章</a>。调用<code>__UNIQUE_ID(min1_)</code>后产生的就是形如<code>__UNIQUE_ID_min1_0</code>这样的变量名，这就确保了此名称不会和传入变量的名称重复了。当然，我们还是可以通过刻意构造这样一个特殊名称来实现冲突的，只是程序是程序员自己写的，相信也没有程序员这么无聊……故我们只需要保证正常情况下不会发生冲突即可。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;code&gt;min&lt;/code&gt;和&lt;code&gt;max&lt;/code&gt;是两个很常用的操作，一般都是用宏实现的，不过想要写出一个很完善的宏定义还是要考虑很多问题的，本文就来分析下Linux Kernel中的实现方法。文中仅考虑&lt;code&gt;min&lt;/code&gt;，&lt;code&gt;max&lt;/code&gt;的结构与其完全相同，只要修改下大于小于号即可。&lt;/p&gt;</summary>
    
    
    
    <category term="编程之法" scheme="https://gaomf.cn/categories/%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%B3%95/"/>
    
    
    <category term="C" scheme="https://gaomf.cn/tags/C/"/>
    
    <category term="Kernel" scheme="https://gaomf.cn/tags/Kernel/"/>
    
  </entry>
  
</feed>
